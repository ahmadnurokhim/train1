{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwF2B1_gVgQM"
   },
   "source": [
    "# Note\n",
    "For continous training only run the \"for cont'\" cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJSAGCSOd2To"
   },
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 381,
     "status": "ok",
     "timestamp": 1654182338444,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "cTEojBogHuAQ",
    "outputId": "2bc37e82-20eb-49a5-e745-d13ebff60a2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/train1/training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "MAIN_PATH = os.getcwd()\n",
    "TRAINING_PATH = os.path.join(MAIN_PATH, \"training\")\n",
    "DATA_PATH = os.path.join(MAIN_PATH, \"data\")\n",
    "CONFIG_PATH = os.path.join(DATA_PATH, \"pipeline.config\")\n",
    "LABEL_MAP_PATH = os.path.join(DATA_PATH, \"label_map.pbtxt\")\n",
    "TRAIN_DATA_PATH = os.path.join(DATA_PATH, \"train.record\")\n",
    "VAL_DATA_PATH = os.path.join(DATA_PATH, \"validation.record\")\n",
    "TEST_DATA_PATH = os.path.join(DATA_PATH, \"test.record\")\n",
    "\n",
    "print(TRAINING_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "urls = ['https://dl.dropboxusercontent.com/s/9f5suk5oo5u7yyi/test.record',\n",
    "        'https://dl.dropboxusercontent.com/s/tqvtgswib6r4f8u/validation.record',\n",
    "        'https://dl.dropboxusercontent.com/s/6kgr2pwi7kgtmwb/train.record']\n",
    "names = [\"test.record\",\n",
    "        \"validation.record\",\n",
    "        \"train.record\"]\n",
    "\n",
    "for url, name in zip(urls, names):\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    open(os.path.join(DATA_PATH, name), 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldFNUUgIXUYj"
   },
   "source": [
    "## Clone the TensorFlow Model Garden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1654182343201,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "gVoGBfbhePZF",
    "outputId": "00071925-01bb-4d6f-babc-086111c62ba9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/train1\n",
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 74201, done.\u001b[K\n",
      "remote: Counting objects: 100% (287/287), done.\u001b[K\n",
      "remote: Compressing objects: 100% (181/181), done.\u001b[K\n",
      "remote: Total 74201 (delta 129), reused 235 (delta 97), pack-reused 73914\u001b[K\n",
<<<<<<< HEAD
      "Receiving objects: 100% (74201/74201), 580.22 MiB | 30.60 MiB/s, done.\n",
=======
      "Receiving objects: 100% (74201/74201), 580.22 MiB | 27.40 MiB/s, done.\n",
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
      "Resolving deltas: 100% (52568/52568), done.\n"
     ]
    }
   ],
   "source": [
    "# (For cont')\n",
    "%cd {MAIN_PATH}\n",
    "!git clone https://github.com/ahmadnurokhim/models.git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGaPKO0R_CYk"
   },
   "source": [
    "## TF Object Detection API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owhIVGjB-yAJ"
   },
   "source": [
    "### Compile/install the TF Object Detection API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3IwuD-NXo9l"
   },
   "source": [
    "CD to the models/research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1654182344628,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "lJ6tPMATeWDi",
    "outputId": "4f28f095-dc37-443b-946f-358918fd0814"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/train1/models/research\n"
     ]
    }
   ],
   "source": [
    "# (For cont')\n",
    "%cd {MAIN_PATH}/models/research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3ba50LW_xRd"
   },
   "source": [
    "### Install the protoc files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libprotobuf-dev libprotobuf-lite17 libprotobuf17 libprotoc17\n",
      "The following NEW packages will be installed:\n",
      "  libprotobuf-dev libprotobuf-lite17 libprotobuf17 libprotoc17\n",
      "  protobuf-compiler\n",
      "0 upgraded, 5 newly installed, 0 to remove and 15 not upgraded.\n",
      "Need to get 2758 kB of archives.\n",
      "After this operation, 16.9 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libprotobuf-lite17 amd64 3.6.1.3-2ubuntu5 [132 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 libprotobuf17 amd64 3.6.1.3-2ubuntu5 [798 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal/main amd64 libprotoc17 amd64 3.6.1.3-2ubuntu5 [646 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal/main amd64 libprotobuf-dev amd64 3.6.1.3-2ubuntu5 [1155 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu focal/universe amd64 protobuf-compiler amd64 3.6.1.3-2ubuntu5 [27.6 kB]\n",
<<<<<<< HEAD
      "Fetched 2758 kB in 1s (2136 kB/s)            \u001b[0m\u001b[33m\n",
=======
      "Fetched 2758 kB in 0s (6067 kB/s)       \u001b[0m\u001b[33m\n",
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libprotobuf-lite17:amd64.\n",
      "(Reading database ... 21502 files and directories currently installed.)\n",
      "Preparing to unpack .../libprotobuf-lite17_3.6.1.3-2ubuntu5_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  5%]\u001b[49m\u001b[39m [##........................................................] \u001b8Unpacking libprotobuf-lite17:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 10%]\u001b[49m\u001b[39m [#####.....................................................] \u001b8Selecting previously unselected package libprotobuf17:amd64.\n",
      "Preparing to unpack .../libprotobuf17_3.6.1.3-2ubuntu5_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 14%]\u001b[49m\u001b[39m [########..................................................] \u001b8Unpacking libprotobuf17:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 19%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Selecting previously unselected package libprotoc17:amd64.\n",
      "Preparing to unpack .../libprotoc17_3.6.1.3-2ubuntu5_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 24%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Unpacking libprotoc17:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 29%]\u001b[49m\u001b[39m [################..........................................] \u001b8Selecting previously unselected package libprotobuf-dev:amd64.\n",
      "Preparing to unpack .../libprotobuf-dev_3.6.1.3-2ubuntu5_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Unpacking libprotobuf-dev:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [######################....................................] \u001b8Selecting previously unselected package protobuf-compiler.\n",
      "Preparing to unpack .../protobuf-compiler_3.6.1.3-2ubuntu5_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 43%]\u001b[49m\u001b[39m [########################..................................] \u001b8Unpacking protobuf-compiler (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 48%]\u001b[49m\u001b[39m [###########################...............................] \u001b8Setting up libprotobuf-lite17:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 52%]\u001b[49m\u001b[39m [##############################............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 57%]\u001b[49m\u001b[39m [#################################.........................] \u001b8Setting up libprotobuf17:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [###################################.......................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 67%]\u001b[49m\u001b[39m [######################################....................] \u001b8Setting up libprotoc17:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 71%]\u001b[49m\u001b[39m [#########################################.................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 76%]\u001b[49m\u001b[39m [############################################..............] \u001b8Setting up protobuf-compiler (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 81%]\u001b[49m\u001b[39m [##############################################............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 86%]\u001b[49m\u001b[39m [#################################################.........] \u001b8Setting up libprotobuf-dev:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 90%]\u001b[49m\u001b[39m [####################################################......] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 95%]\u001b[49m\u001b[39m [#######################################################...] \u001b8Processing triggers for libc-bin (2.31-0ubuntu9.7) ...\n",
      "\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "!apt install protobuf-compiler -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1654182345692,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "2VCOalHYfYhh"
   },
   "outputs": [],
   "source": [
    "# (For cont')\n",
    "\n",
    "!protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1g8ZdQoWWN2_"
   },
   "source": [
    "(For cont') \\\n",
    "\\\n",
    "To avoid DNN library not found problem, open the object_detection/packages/tf2/setup.py and make sure to add these lines or you can just run the next cell\n",
    "```\n",
    "    'tensorflow==2.8.0',\n",
    "    'tf-models-official==2.8.0',\n",
    "    'tensorflow_io==0.23.1',\n",
    "    'keras==2.8.0',\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10979,
     "status": "ok",
     "timestamp": 1654182358394,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "t-hzXOqV-Opt",
    "outputId": "e0801f6c-9220-483f-f8f2-f585be4a2c69",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-models-official\n",
      "  Downloading tf_models_official-2.9.2-py2.py3-none-any.whl (2.1 MB)\n",
<<<<<<< HEAD
      "\u001b[K     |████████████████████████████████| 2.1 MB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kaggle>=1.3.9\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 7.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-hub>=0.6.0\n",
      "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "\u001b[K     |████████████████████████████████| 108 kB 66.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /usr/lib/python3/dist-packages (from tf-models-official) (1.14.0)\n",
      "Collecting pycocotools\n",
      "  Downloading pycocotools-2.0.4.tar.gz (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 67.2 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-models-official) (5.9.1)\n",
      "Collecting tensorflow-text~=2.9.0\n",
      "  Downloading tensorflow_text-2.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.6 MB 38.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
      "  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
      "\u001b[K     |████████████████████████████████| 662 kB 51.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.19.1\n",
      "  Downloading scipy-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 41.6 MB 54.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 2.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorflow~=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official) (2.9.1)\n",
      "Collecting pandas>=0.22.0\n",
      "  Downloading pandas-1.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7 MB 39.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tf-slim>=1.1.0\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "\u001b[K     |████████████████████████████████| 352 kB 50.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-datasets\n",
      "  Downloading tensorflow_datasets-4.6.0-py3-none-any.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 55.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
      "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 12.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Cython\n",
      "  Using cached Cython-0.29.30-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
      "Collecting tensorflow-model-optimization>=0.4.1\n",
      "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
      "\u001b[K     |████████████████████████████████| 237 kB 60.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacrebleu\n",
      "  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\n",
      "\u001b[K     |████████████████████████████████| 92 kB 13.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Pillow\n",
      "  Downloading Pillow-9.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 58.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 64.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gin-config\n",
      "  Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 9.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting oauth2client\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 7.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 47.8 MB 28.3 MB/s eta 0:00:01     |█████████████████████████████▏  | 43.5 MB 28.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tf-models-official) (1.22.4)\n",
      "Collecting google-api-python-client>=1.6.7\n",
      "  Downloading google_api_python_client-2.49.0-py2.py3-none-any.whl (8.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.5 MB 41.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.17.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 65.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 53.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi in /usr/lib/python3/dist-packages (from kaggle>=1.3.9->tf-models-official) (2019.11.28)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.8.2)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.22.0)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 8.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting python-slugify\n",
      "  Downloading python_slugify-6.1.2-py2.py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: urllib3 in /usr/lib/python3/dist-packages (from kaggle>=1.3.9->tf-models-official) (1.25.8)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-hub>=0.6.0->tf-models-official) (3.19.4)\n",
      "Collecting scikit-learn>=0.21.3\n",
      "  Downloading scikit_learn-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 31.2 MB 67.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (0.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.14.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (62.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (4.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (0.26.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (2.9.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.0.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (14.0.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (21.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.46.3)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (2.9.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (3.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.1.2)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.12)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.22.0->tf-models-official) (2022.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dill\n",
      "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 6.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official) (5.7.1)\n",
      "Collecting etils[epath]\n",
      "  Downloading etils-0.6.0-py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 9.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.8.0-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 8.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Collecting dm-tree~=0.1.1\n",
      "  Downloading dm_tree-0.1.7-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (142 kB)\n",
      "\u001b[K     |████████████████████████████████| 142 kB 61.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting portalocker\n",
      "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting tabulate>=0.8.9\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting regex\n",
      "  Downloading regex-2022.6.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\n",
      "\u001b[K     |████████████████████████████████| 764 kB 37.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting colorama\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official) (0.2.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official) (0.4.8)\n",
      "Collecting httplib2>=0.9.1\n",
      "  Downloading httplib2-0.20.4-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 7.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-httplib2>=0.1.0\n",
      "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (2.6.6)\n",
      "Collecting uritemplate<5,>=3.0.1\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Downloading google_api_core-2.8.1-py3-none-any.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 17.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typeguard>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 56.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
      "\u001b[K     |████████████████████████████████| 930 kB 57.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->tf-models-official) (3.0.9)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 8.6 MB/s  eta 0:00:01\n",
=======
      "\u001b[K     |████████████████████████████████| 2.1 MB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tf-models-official) (1.22.4)\n",
      "Collecting google-api-python-client>=1.6.7\n",
      "  Downloading google_api_python_client-2.49.0-py2.py3-none-any.whl (8.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.5 MB 43.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
      "  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
      "\u001b[K     |████████████████████████████████| 662 kB 25.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.17.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 34.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-hub>=0.6.0\n",
      "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "\u001b[K     |████████████████████████████████| 108 kB 67.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
      "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
      "\u001b[K     |████████████████████████████████| 237 kB 58.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 56.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-models-official) (5.9.1)\n",
      "Collecting tensorflow-datasets\n",
      "  Downloading tensorflow_datasets-4.6.0-py3-none-any.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 81.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacrebleu\n",
      "  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\n",
      "\u001b[K     |████████████████████████████████| 92 kB 23.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Pillow\n",
      "  Downloading Pillow-9.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 61.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorflow~=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official) (2.9.1)\n",
      "Collecting pycocotools\n",
      "  Downloading pycocotools-2.0.4.tar.gz (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 64.6 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting oauth2client\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 13.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kaggle>=1.3.9\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 12.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Cython\n",
      "  Using cached Cython-0.29.30-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
      "Collecting pandas>=0.22.0\n",
      "  Downloading pandas-1.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7 MB 35.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 62.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
      "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 24.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gin-config\n",
      "  Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 18.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-text~=2.9.0\n",
      "  Downloading tensorflow_text-2.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.6 MB 19.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /usr/lib/python3/dist-packages (from tf-models-official) (1.14.0)\n",
      "Collecting tf-slim>=1.1.0\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "\u001b[K     |████████████████████████████████| 352 kB 63.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 6.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.19.1\n",
      "  Downloading scipy-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 41.6 MB 58.2 MB/s eta 0:00:01    |██████▎                         | 8.2 MB 58.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 47.8 MB 56.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Downloading google_api_core-2.8.1-py3-none-any.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 63.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (2.6.6)\n",
      "Collecting httplib2<1dev,>=0.15.0\n",
      "  Downloading httplib2-0.20.4-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 15.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-httplib2>=0.1.0\n",
      "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting uritemplate<5,>=3.0.1\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->tf-models-official) (21.3)\n",
      "Collecting typeguard>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-hub>=0.6.0->tf-models-official) (3.19.4)\n",
      "Collecting dm-tree~=0.1.1\n",
      "  Downloading dm_tree-0.1.7-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (142 kB)\n",
      "\u001b[K     |████████████████████████████████| 142 kB 61.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->tf-models-official) (3.0.9)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 46.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
      "\u001b[K     |████████████████████████████████| 930 kB 41.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->tf-models-official) (2.8.2)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official) (1.1.0)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official) (1.0.0)\n",
      "Collecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 13.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.8.0-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 16.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 17.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official) (5.7.1)\n",
      "Collecting etils[epath]\n",
      "  Downloading etils-0.6.0-py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 17.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/lib/python3/dist-packages (from tensorflow-datasets->tf-models-official) (2.22.0)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting regex\n",
      "  Downloading regex-2022.6.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\n",
      "\u001b[K     |████████████████████████████████| 764 kB 42.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting portalocker\n",
      "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting tabulate>=0.8.9\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.46.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (0.26.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (4.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (3.6.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (0.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (14.0.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (2.9.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (2.9.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.6.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (0.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (62.3.2)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.12)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (2.9.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official) (4.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official) (0.2.8)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from kaggle>=1.3.9->tf-models-official) (2019.11.28)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-6.1.2-py2.py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: urllib3 in /usr/lib/python3/dist-packages (from kaggle>=1.3.9->tf-models-official) (1.25.8)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.22.0->tf-models-official) (2022.1)\n",
      "Collecting scikit-learn>=0.21.3\n",
      "  Downloading scikit_learn-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 31.2 MB 41.2 MB/s eta 0:00:01     |█████████████████████████▊      | 25.0 MB 41.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting googleapis-common-protos<2.0dev,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.56.2-py2.py3-none-any.whl (211 kB)\n",
      "\u001b[K     |████████████████████████████████| 211 kB 45.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (5.1.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official) (3.8.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (1.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (0.34.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (3.3.7)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (2.1.2)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 17.5 MB/s eta 0:00:01\n",
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
<<<<<<< HEAD
      "\u001b[K     |████████████████████████████████| 306 kB 53.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (0.6.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (0.34.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (2.1.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (3.3.7)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official) (3.8.0)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.56.2-py2.py3-none-any.whl (211 kB)\n",
      "\u001b[K     |████████████████████████████████| 211 kB 53.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (5.1.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (4.11.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (3.2.0)\n",
      "Building wheels for collected packages: kaggle, pycocotools, seqeval, py-cpuinfo, promise\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73032 sha256=da27424fed96d4e0cf564a61b19139818cb5fef13f9f0df743796551126f7a92\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/da/11/144cc25aebdaeb4931b231e25fd34b394e6a5725cbb2f50106\n",
      "  Building wheel for pycocotools (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.4-cp38-cp38-linux_x86_64.whl size=418782 sha256=eae63cc73da1e2d7da9e1675d6c6a3251574ed4811147d145ebac35478fc9dd3\n",
      "  Stored in directory: /root/.cache/pip/wheels/dd/e2/43/3e93cd653b3346b3d702bb0509bc611189f95d60407bff1484\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16166 sha256=74fb03597ae60cbe0d19eee33859c7e3d27ee196ae1c5342f3157d0a051d4ea6\n",
=======
      "\u001b[K     |████████████████████████████████| 306 kB 34.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (4.11.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (3.2.0)\n",
      "Building wheels for collected packages: pycocotools, kaggle, py-cpuinfo, seqeval, promise\n",
      "  Building wheel for pycocotools (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.4-cp38-cp38-linux_x86_64.whl size=418791 sha256=8219430fc3cb840b69ad592e356440b61724386b2a9976fa0e1e0914378fb238\n",
      "  Stored in directory: /root/.cache/pip/wheels/dd/e2/43/3e93cd653b3346b3d702bb0509bc611189f95d60407bff1484\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73032 sha256=dba40c6718468a3e2e18ddfb91c67f28be1e7907048fe5efdd8a0f7ba3aeff76\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/da/11/144cc25aebdaeb4931b231e25fd34b394e6a5725cbb2f50106\n",
      "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22242 sha256=d9138e2e4559f8f658f4ee9b1f1c7653194dcfe4bfffbda63da54f1d78ee6190\n",
      "  Stored in directory: /root/.cache/pip/wheels/57/cb/6d/bab2257f26c5be4a96ff65c3d2a7122c96529b73773ee37f36\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16166 sha256=e7107ef4c6df036b461909dd18b1784a507fc2e59be6fdca096bcde565aba496\n",
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
      "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
      "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22242 sha256=23adaa4fac5de0f25869948f2fdc985d1d149af6ee64747d8bda75a98cda017f\n",
      "  Stored in directory: /root/.cache/pip/wheels/57/cb/6d/bab2257f26c5be4a96ff65c3d2a7122c96529b73773ee37f36\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
<<<<<<< HEAD
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21485 sha256=aeed3d7b04f2ee9460838fd11197a24a652cc58b50584ace59e24df158a88a86\n",
=======
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21485 sha256=9e684472c093db2bda5f423508cbd41f0394b18fe62e1522a260cade56ca6bee\n",
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
      "  Stored in directory: /root/.cache/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "Successfully built kaggle pycocotools seqeval py-cpuinfo promise\n",
      "Installing collected packages: tqdm, text-unidecode, python-slugify, kaggle, tensorflow-hub, kiwisolver, cycler, fonttools, Pillow, matplotlib, pycocotools, tensorflow-text, pyyaml, scipy, threadpoolctl, joblib, scikit-learn, seqeval, pandas, tf-slim, dill, toml, etils, googleapis-common-protos, tensorflow-metadata, promise, tensorflow-datasets, py-cpuinfo, Cython, dm-tree, tensorflow-model-optimization, portalocker, tabulate, regex, colorama, sacrebleu, sentencepiece, gin-config, httplib2, oauth2client, opencv-python-headless, google-auth-httplib2, uritemplate, google-api-core, google-api-python-client, typeguard, tensorflow-addons, tf-models-official\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
=======
      "Installing collected packages: googleapis-common-protos, google-api-core, httplib2, google-auth-httplib2, uritemplate, google-api-python-client, pyyaml, typeguard, tensorflow-addons, tensorflow-hub, dm-tree, tensorflow-model-optimization, cycler, Pillow, kiwisolver, fonttools, matplotlib, promise, dill, toml, tensorflow-metadata, tqdm, etils, tensorflow-datasets, colorama, regex, portalocker, tabulate, sacrebleu, pycocotools, oauth2client, text-unidecode, python-slugify, kaggle, Cython, pandas, sentencepiece, py-cpuinfo, gin-config, tensorflow-text, tf-slim, threadpoolctl, joblib, scipy, scikit-learn, seqeval, opencv-python-headless, tf-models-official\n",
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
      "Successfully installed Cython-0.29.30 Pillow-9.1.1 colorama-0.4.4 cycler-0.11.0 dill-0.3.5.1 dm-tree-0.1.7 etils-0.6.0 fonttools-4.33.3 gin-config-0.5.0 google-api-core-2.8.1 google-api-python-client-2.49.0 google-auth-httplib2-0.1.0 googleapis-common-protos-1.56.2 httplib2-0.20.4 joblib-1.1.0 kaggle-1.5.12 kiwisolver-1.4.2 matplotlib-3.5.2 oauth2client-4.1.3 opencv-python-headless-4.5.5.64 pandas-1.4.2 portalocker-2.4.0 promise-2.3 py-cpuinfo-8.0.0 pycocotools-2.0.4 python-slugify-6.1.2 pyyaml-5.4.1 regex-2022.6.2 sacrebleu-2.1.0 scikit-learn-1.1.1 scipy-1.8.1 sentencepiece-0.1.96 seqeval-1.2.2 tabulate-0.8.9 tensorflow-addons-0.17.0 tensorflow-datasets-4.6.0 tensorflow-hub-0.12.0 tensorflow-metadata-1.8.0 tensorflow-model-optimization-0.7.2 tensorflow-text-2.9.0 text-unidecode-1.3 tf-models-official-2.9.2 tf-slim-1.1.0 threadpoolctl-3.1.0 toml-0.10.2 tqdm-4.64.0 typeguard-2.13.3 uritemplate-4.1.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tensorflow_io\n",
      "  Downloading tensorflow_io-0.26.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem==0.26.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_io) (0.26.0)\n",
      "Installing collected packages: tensorflow-io\n",
      "Successfully installed tensorflow-io-0.26.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (2.9.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorflow==2.8.0\n",
    "#!pip install tf-models-official==2.8.0\n",
    "#!pip install tensorflow_io==0.23.1\n",
    "#!pip install keras==2.8.0\n",
    "!pip install tf-models-official\n",
    "!pip install tensorflow_io\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 642,
     "status": "ok",
     "timestamp": 1654182359025,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "7VDFzo4bfZx8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /root/train1/models/research\n",
      "Collecting avro-python3\n",
      "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
      "Collecting apache-beam\n",
      "  Downloading apache_beam-2.39.0-cp38-cp38-manylinux2010_x86_64.whl (12.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.3 MB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (9.1.1)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.9 MB)\n",
<<<<<<< HEAD
      "\u001b[K     |████████████████████████████████| 6.9 MB 59.6 MB/s eta 0:00:01\n",
=======
      "\u001b[K     |████████████████████████████████| 6.9 MB 65.4 MB/s eta 0:00:01\n",
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (3.5.2)\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.29.30)\n",
      "Collecting contextlib2\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: tf-slim in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from object-detection==0.1) (1.14.0)\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.0.4)\n",
      "Collecting lvis\n",
      "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.8.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: tf-models-official>=2.5.1 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.9.2)\n",
      "Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.26.0)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.9.0)\n",
      "Collecting pyparsing==2.4.7\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
<<<<<<< HEAD
      "\u001b[K     |████████████████████████████████| 67 kB 17.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyarrow<8.0.0,>=0.15.1\n",
      "  Downloading pyarrow-7.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.7 MB 33.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
      "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (4.2.0)\n",
      "Collecting cloudpickle<3,>=2.0.0\n",
      "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.14.3 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.22.4)\n",
      "Collecting crcmod<2.0,>=1.7\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "\u001b[K     |████████████████████████████████| 89 kB 23.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fastavro<2,>=0.23.6\n",
      "  Downloading fastavro-1.4.12-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 46.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2022.1)\n",
      "Collecting pymongo<4.0.0,>=3.8.0\n",
      "  Downloading pymongo-3.12.3-cp38-cp38-manylinux2014_x86_64.whl (546 kB)\n",
      "\u001b[K     |████████████████████████████████| 546 kB 50.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting proto-plus<2,>=1.7.1\n",
      "  Downloading proto_plus-1.20.5-py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 10.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.19.4)\n",
      "Collecting requests<3.0.0,>=2.24.0\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 5.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting httplib2<0.20.0,>=0.8\n",
      "  Downloading httplib2-0.19.1-py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 11.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.46.3)\n",
      "Collecting orjson<4.0\n",
      "  Downloading orjson-3.7.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (256 kB)\n",
      "\u001b[K     |████████████████████████████████| 256 kB 53.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 62.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydot<2,>=1.2.0\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->object-detection==0.1) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->object-detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->object-detection==0.1) (4.33.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->object-detection==0.1) (0.11.0)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from tf-slim->object-detection==0.1) (1.0.0)\n",
      "Collecting opencv-python>=4.1.0.25\n",
      "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 60.5 MB 52.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.17.0)\n",
      "Requirement already satisfied: seqeval in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.1)\n",
      "Requirement already satisfied: gin-config in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
      "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0)\n",
      "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.5.5.64)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.96)\n",
      "Requirement already satisfied: tensorflow~=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.9.1)\n",
      "Requirement already satisfied: tensorflow-text~=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.9.0)\n",
      "Requirement already satisfied: pyyaml<6.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.1)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.49.0)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (8.0.0)\n",
      "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.1.0)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.7.2)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
=======
      "\u001b[K     |████████████████████████████████| 67 kB 16.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
      "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (4.2.0)\n",
      "Collecting httplib2<0.20.0,>=0.8\n",
      "  Downloading httplib2-0.19.1-py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 13.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.46.3)\n",
      "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2022.1)\n",
      "Collecting requests<3.0.0,>=2.24.0\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 5.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
      "  Downloading pymongo-3.12.3-cp38-cp38-manylinux2014_x86_64.whl (546 kB)\n",
      "\u001b[K     |████████████████████████████████| 546 kB 116.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 66.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cloudpickle<3,>=2.0.0\n",
      "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
      "Collecting crcmod<2.0,>=1.7\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "\u001b[K     |████████████████████████████████| 89 kB 24.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.19.4)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.8.2)\n",
      "Collecting fastavro<2,>=0.23.6\n",
      "  Downloading fastavro-1.4.12-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 58.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting proto-plus<2,>=1.7.1\n",
      "  Downloading proto_plus-1.20.5-py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 11.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyarrow<8.0.0,>=0.15.1\n",
      "  Downloading pyarrow-7.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.7 MB 28.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.23.0,>=1.14.3 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.22.4)\n",
      "Collecting pydot<2,>=1.2.0\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting orjson<4.0\n",
      "  Downloading orjson-3.7.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (256 kB)\n",
      "\u001b[K     |████████████████████████████████| 256 kB 84.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->object-detection==0.1) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->object-detection==0.1) (4.33.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->object-detection==0.1) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->object-detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from tf-slim->object-detection==0.1) (1.0.0)\n",
      "Collecting opencv-python>=4.1.0.25\n",
      "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 60.5 MB 456 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: seqeval in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.7.2)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.1)\n",
      "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.5.5.64)\n",
      "Requirement already satisfied: pyyaml<6.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.1)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.49.0)\n",
      "Requirement already satisfied: tensorflow~=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.9.1)\n",
      "Requirement already satisfied: tensorflow-text~=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.9.0)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
      "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0)\n",
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.17.0)\n",
      "Requirement already satisfied: gin-config in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: oauth2client in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
      "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.1.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.96)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (8.0.0)\n",
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.26.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_io->object-detection==0.1) (0.26.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docopt\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.8)\n",
      "Collecting charset-normalizer~=2.0.0; python_version >= \"3\"\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.25.8)\n",
<<<<<<< HEAD
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.13.3)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.1)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.7.1)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
      "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.6.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.6.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.9.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (62.3.2)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.9.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.6.6)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.8.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.2)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2.4.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.8/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.4.4)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.56.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.34.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.1.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
      "Building wheels for collected packages: object-detection, avro-python3, crcmod, dill, docopt\n"
=======
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.1)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.8.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.6.6)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.9.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (62.3.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.7.1)\n",
      "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.6.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.13.3)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2.4.0)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.8/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.4.4)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.34.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.2)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
      "Building wheels for collected packages: object-detection, avro-python3, dill, crcmod, docopt\n"
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for object-detection (setup.py) ... \u001b[?25ldone\n",
<<<<<<< HEAD
      "\u001b[?25h  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1693568 sha256=298770672daff4291d9e30abc15ed55eb39c0967e952a30cb5b2ed97128389d0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-m9juhbqr/wheels/63/a7/0e/470621870b3a152ee838e90ee41621c4a103254383f3be3d97\n",
      "  Building wheel for avro-python3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43992 sha256=d7aec39c848ded726166e1936634a55eeae27cd429f0a7c7954314139f95795a\n",
      "  Stored in directory: /root/.cache/pip/wheels/bb/73/e9/d273421f5723c4bf544dcf9eb097bda94421ef8d3252699f0a\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for crcmod: filename=crcmod-1.7-cp38-cp38-linux_x86_64.whl size=36003 sha256=a217ab998d5e1e0d3b628868697c4042ce5cbf83772e890a57c1feb1974e0184\n",
      "  Stored in directory: /root/.cache/pip/wheels/ca/5a/02/f3acf982a026f3319fb3e798a8dca2d48fafee7761788562e9\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78543 sha256=0ed930910737ac542d2e50d794678e2ac0c18fd9810a45e852d3315c7ac2b68a\n",
=======
      "\u001b[?25h  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1693568 sha256=f39ae9bb8c119698afbba35e14af68a2793fd7d731b8fba0689f61981c6dc676\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-7c5emqty/wheels/63/a7/0e/470621870b3a152ee838e90ee41621c4a103254383f3be3d97\n",
      "  Building wheel for avro-python3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43992 sha256=6cf50d43576b029db20262306f10060a6f940966a4026ed20c6fd0d7e1262800\n",
      "  Stored in directory: /root/.cache/pip/wheels/bb/73/e9/d273421f5723c4bf544dcf9eb097bda94421ef8d3252699f0a\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78543 sha256=6ddbd83aa46e452955549b6c8ddcd9a3dbf84c5cda16b17fa9abff213b5f27b6\n",
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
      "  Stored in directory: /root/.cache/pip/wheels/07/35/78/e9004fa30578734db7f10e7a211605f3f0778d2bdde38a239d\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for crcmod: filename=crcmod-1.7-cp38-cp38-linux_x86_64.whl size=35989 sha256=f93792424b2c4732f86ac0ed77669b9342e43cbfb959c66b1e98c4787a43f187\n",
      "  Stored in directory: /root/.cache/pip/wheels/ca/5a/02/f3acf982a026f3319fb3e798a8dca2d48fafee7761788562e9\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
<<<<<<< HEAD
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=36cdc8b88d24883e22f8fce7287494223f26d59bd25d756a0922ead7151a96ff\n",
      "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
      "Successfully built object-detection avro-python3 crcmod dill docopt\n",
      "Installing collected packages: avro-python3, pyarrow, docopt, charset-normalizer, requests, hdfs, cloudpickle, crcmod, fastavro, pymongo, proto-plus, pyparsing, httplib2, orjson, dill, pydot, apache-beam, lxml, contextlib2, opencv-python, lvis, object-detection\n",
=======
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=8239fd80a0694189fd98d2b876e1d95f95fe659fef8314bbb94aeba9caa5295f\n",
      "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
      "Successfully built object-detection avro-python3 dill crcmod docopt\n",
      "Installing collected packages: avro-python3, docopt, charset-normalizer, requests, hdfs, pyparsing, httplib2, pymongo, dill, cloudpickle, crcmod, fastavro, proto-plus, pyarrow, pydot, orjson, apache-beam, lxml, contextlib2, opencv-python, lvis, object-detection\n",
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.22.0\n",
      "    Uninstalling requests-2.22.0:\n",
      "      Successfully uninstalled requests-2.22.0\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.9\n",
      "    Uninstalling pyparsing-3.0.9:\n",
      "      Successfully uninstalled pyparsing-3.0.9\n",
      "  Attempting uninstall: httplib2\n",
      "    Found existing installation: httplib2 0.20.4\n",
      "    Uninstalling httplib2-0.20.4:\n",
      "      Successfully uninstalled httplib2-0.20.4\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.5.1\n",
      "    Uninstalling dill-0.3.5.1:\n",
      "      Successfully uninstalled dill-0.3.5.1\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "jupyterlab 3.4.2 requires tornado>=6.1.0, but you'll have tornado 5.1.1 which is incompatible.\n",
      "jupyter-server 1.17.0 requires tornado>=6.1.0, but you'll have tornado 5.1.1 which is incompatible.\n",
      "ipykernel 6.13.0 requires tornado>=6.1, but you'll have tornado 5.1.1 which is incompatible.\u001b[0m\n",
      "Successfully installed apache-beam-2.39.0 avro-python3-1.10.2 charset-normalizer-2.0.12 cloudpickle-2.1.0 contextlib2-21.6.0 crcmod-1.7 dill-0.3.1.1 docopt-0.6.2 fastavro-1.4.12 hdfs-2.7.0 httplib2-0.19.1 lvis-0.5.3 lxml-4.9.0 object-detection-0.1 opencv-python-4.5.5.64 orjson-3.7.1 proto-plus-1.20.5 pyarrow-7.0.0 pydot-1.4.2 pymongo-3.12.3 pyparsing-2.4.7 requests-2.27.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# (For cont')\n",
    "\n",
    "!cp object_detection/packages/tf2/setup.py .\n",
    "!python -m pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7S6YquyWg_HW"
   },
   "source": [
    "### Test the TF Object Detection installation API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30628,
     "status": "ok",
     "timestamp": 1654182396978,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "cDB1YYuqhJcp",
    "outputId": "cfe9f44c-8a7a-4ca4-e3c6-fb611b108f3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tests under Python 3.8.10: /usr/local/bin/python\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
<<<<<<< HEAD
      "2022-06-04 12:15:55.571735: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-04 12:15:56.725578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22340 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-06-04 12:15:56.727285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22340 MB memory:  -> device: 1, name: NVIDIA RTX A5000, pci bus id: 0000:82:00.0, compute capability: 8.6\n",
      "/usr/local/lib/python3.8/dist-packages/object_detection/builders/model_builder.py:1102: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
      "W0604 12:15:57.273956 140019516405568 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.93s\n",
      "I0604 12:15:57.492414 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.93s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.48s\n",
      "I0604 12:15:57.972113 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.48s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.35s\n",
      "I0604 12:15:58.317851 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.35s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.2s\n",
      "I0604 12:15:58.522015 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.2s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.45s\n",
      "I0604 12:15:59.967412 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.45s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I0604 12:15:59.968438 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "I0604 12:15:59.988090 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "I0604 12:16:00.000308 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "I0604 12:16:00.012933 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.08s\n",
      "I0604 12:16:00.092483 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
      "I0604 12:16:00.168124 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.08s\n",
      "I0604 12:16:00.247474 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.08s\n",
      "I0604 12:16:00.325862 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.08s\n",
      "I0604 12:16:00.402322 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "I0604 12:16:00.424865 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I0604 12:16:00.701574 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I0604 12:16:00.701725 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
      "I0604 12:16:00.701776 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 3\n",
      "I0604 12:16:00.703637 140019516405568 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 12:16:00.716587 140019516405568 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 12:16:00.716663 140019516405568 efficientnet_model.py:143] round_filter input=16 output=16\n"
=======
      "2022-06-04 14:50:16.581583: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-04 14:50:17.647486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22340 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-06-04 14:50:17.648521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22340 MB memory:  -> device: 1, name: NVIDIA RTX A5000, pci bus id: 0000:82:00.0, compute capability: 8.6\n",
      "/usr/local/lib/python3.8/dist-packages/object_detection/builders/model_builder.py:1102: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
      "W0604 14:50:18.214096 139855472297792 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.85s\n",
      "I0604 14:50:18.428827 139855472297792 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.85s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.49s\n",
      "I0604 14:50:18.918046 139855472297792 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.49s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.33s\n",
      "I0604 14:50:19.253311 139855472297792 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.33s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.2s\n",
      "I0604 14:50:19.454860 139855472297792 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.2s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.39s\n",
      "I0604 14:50:20.848423 139855472297792 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.39s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I0604 14:50:20.849446 139855472297792 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "I0604 14:50:20.869208 139855472297792 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "I0604 14:50:20.881507 139855472297792 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "I0604 14:50:20.893865 139855472297792 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.08s\n",
      "I0604 14:50:20.973080 139855472297792 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
      "I0604 14:50:21.048522 139855472297792 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.08s\n",
      "I0604 14:50:21.127273 139855472297792 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.08s\n",
      "I0604 14:50:21.204825 139855472297792 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.08s\n",
      "I0604 14:50:21.280984 139855472297792 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "I0604 14:50:21.304141 139855472297792 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I0604 14:50:21.594931 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I0604 14:50:21.595080 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
      "I0604 14:50:21.595148 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 3\n",
      "I0604 14:50:21.597040 139855472297792 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 14:50:21.610486 139855472297792 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 14:50:21.610562 139855472297792 efficientnet_model.py:143] round_filter input=16 output=16\n"
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "I0604 12:16:00.762233 140019516405568 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0604 12:16:00.762325 140019516405568 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 12:16:00.875456 140019516405568 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 12:16:00.875553 140019516405568 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0604 12:16:00.989835 140019516405568 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0604 12:16:00.989939 140019516405568 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0604 12:16:01.162424 140019516405568 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0604 12:16:01.162549 140019516405568 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0604 12:16:01.335368 140019516405568 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0604 12:16:01.335484 140019516405568 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0604 12:16:01.573688 140019516405568 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0604 12:16:01.573861 140019516405568 efficientnet_model.py:143] round_filter input=320 output=320\n",
      "I0604 12:16:01.627964 140019516405568 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
      "I0604 12:16:01.652861 140019516405568 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 12:16:01.699382 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I0604 12:16:01.699489 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
      "I0604 12:16:01.699537 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 4\n",
      "I0604 12:16:01.701040 140019516405568 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 12:16:01.713015 140019516405568 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 12:16:01.713084 140019516405568 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0604 12:16:01.803715 140019516405568 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0604 12:16:01.803803 140019516405568 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 12:16:01.975205 140019516405568 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 12:16:01.975326 140019516405568 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0604 12:16:02.146262 140019516405568 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0604 12:16:02.146374 140019516405568 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0604 12:16:02.374913 140019516405568 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0604 12:16:02.375050 140019516405568 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0604 12:16:02.606195 140019516405568 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0604 12:16:02.606341 140019516405568 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0604 12:16:02.895252 140019516405568 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0604 12:16:02.895394 140019516405568 efficientnet_model.py:143] round_filter input=320 output=320\n",
      "I0604 12:16:03.008480 140019516405568 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
      "I0604 12:16:03.029739 140019516405568 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 12:16:03.084149 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0604 12:16:03.084279 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
      "I0604 12:16:03.084354 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 5\n",
      "I0604 12:16:03.085741 140019516405568 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 12:16:03.097837 140019516405568 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 12:16:03.097906 140019516405568 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0604 12:16:03.189528 140019516405568 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0604 12:16:03.189637 140019516405568 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 12:16:03.362607 140019516405568 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 12:16:03.362747 140019516405568 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0604 12:16:03.536120 140019516405568 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0604 12:16:03.536242 140019516405568 efficientnet_model.py:143] round_filter input=80 output=88\n",
      "I0604 12:16:03.766072 140019516405568 efficientnet_model.py:143] round_filter input=80 output=88\n",
      "I0604 12:16:03.766196 140019516405568 efficientnet_model.py:143] round_filter input=112 output=120\n"
=======
      "I0604 14:50:21.655138 139855472297792 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0604 14:50:21.655242 139855472297792 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 14:50:21.769338 139855472297792 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 14:50:21.769464 139855472297792 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0604 14:50:21.881621 139855472297792 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0604 14:50:21.881755 139855472297792 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0604 14:50:22.052593 139855472297792 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0604 14:50:22.052728 139855472297792 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0604 14:50:22.223200 139855472297792 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0604 14:50:22.223333 139855472297792 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0604 14:50:22.454600 139855472297792 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0604 14:50:22.454762 139855472297792 efficientnet_model.py:143] round_filter input=320 output=320\n",
      "I0604 14:50:22.509750 139855472297792 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
      "I0604 14:50:22.534848 139855472297792 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 14:50:22.579530 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I0604 14:50:22.579624 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
      "I0604 14:50:22.579721 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 4\n",
      "I0604 14:50:22.581063 139855472297792 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 14:50:22.592766 139855472297792 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 14:50:22.592833 139855472297792 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0604 14:50:22.681724 139855472297792 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0604 14:50:22.681810 139855472297792 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 14:50:22.851416 139855472297792 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 14:50:22.851533 139855472297792 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0604 14:50:23.021883 139855472297792 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0604 14:50:23.021996 139855472297792 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0604 14:50:23.247833 139855472297792 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0604 14:50:23.247954 139855472297792 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0604 14:50:23.477601 139855472297792 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0604 14:50:23.477746 139855472297792 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0604 14:50:23.763724 139855472297792 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0604 14:50:23.763858 139855472297792 efficientnet_model.py:143] round_filter input=320 output=320\n",
      "I0604 14:50:23.881772 139855472297792 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
      "I0604 14:50:23.902877 139855472297792 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 14:50:23.958644 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0604 14:50:23.958766 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
      "I0604 14:50:23.958860 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 5\n",
      "I0604 14:50:23.960233 139855472297792 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 14:50:23.972098 139855472297792 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 14:50:23.972167 139855472297792 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0604 14:50:24.062228 139855472297792 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0604 14:50:24.062331 139855472297792 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 14:50:24.230946 139855472297792 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 14:50:24.231068 139855472297792 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0604 14:50:24.401050 139855472297792 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0604 14:50:24.401181 139855472297792 efficientnet_model.py:143] round_filter input=80 output=88\n",
      "I0604 14:50:24.627950 139855472297792 efficientnet_model.py:143] round_filter input=80 output=88\n",
      "I0604 14:50:24.628078 139855472297792 efficientnet_model.py:143] round_filter input=112 output=120\n"
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "I0604 12:16:04.139407 140019516405568 efficientnet_model.py:143] round_filter input=112 output=120\n",
      "I0604 12:16:04.139548 140019516405568 efficientnet_model.py:143] round_filter input=192 output=208\n",
      "I0604 12:16:04.439208 140019516405568 efficientnet_model.py:143] round_filter input=192 output=208\n",
      "I0604 12:16:04.439340 140019516405568 efficientnet_model.py:143] round_filter input=320 output=352\n",
      "I0604 12:16:04.555382 140019516405568 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
      "I0604 12:16:04.578605 140019516405568 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 12:16:04.632550 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0604 12:16:04.632664 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
      "I0604 12:16:04.632739 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 6\n",
      "I0604 12:16:04.634289 140019516405568 efficientnet_model.py:143] round_filter input=32 output=40\n",
      "I0604 12:16:04.649108 140019516405568 efficientnet_model.py:143] round_filter input=32 output=40\n",
      "I0604 12:16:04.649248 140019516405568 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 12:16:04.741867 140019516405568 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 12:16:04.741992 140019516405568 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0604 12:16:04.913329 140019516405568 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0604 12:16:04.913451 140019516405568 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0604 12:16:05.084046 140019516405568 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0604 12:16:05.084174 140019516405568 efficientnet_model.py:143] round_filter input=80 output=96\n",
      "I0604 12:16:05.371321 140019516405568 efficientnet_model.py:143] round_filter input=80 output=96\n",
      "I0604 12:16:05.371455 140019516405568 efficientnet_model.py:143] round_filter input=112 output=136\n",
      "I0604 12:16:05.663168 140019516405568 efficientnet_model.py:143] round_filter input=112 output=136\n",
      "I0604 12:16:05.663302 140019516405568 efficientnet_model.py:143] round_filter input=192 output=232\n",
      "I0604 12:16:06.008544 140019516405568 efficientnet_model.py:143] round_filter input=192 output=232\n",
      "I0604 12:16:06.008680 140019516405568 efficientnet_model.py:143] round_filter input=320 output=384\n",
      "I0604 12:16:06.122856 140019516405568 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
      "I0604 12:16:06.144393 140019516405568 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 12:16:06.207113 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I0604 12:16:06.207247 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
      "I0604 12:16:06.207301 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 7\n",
      "I0604 12:16:06.208726 140019516405568 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0604 12:16:06.221300 140019516405568 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0604 12:16:06.221388 140019516405568 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 12:16:06.313993 140019516405568 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 12:16:06.314121 140019516405568 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0604 12:16:06.544176 140019516405568 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0604 12:16:06.544313 140019516405568 efficientnet_model.py:143] round_filter input=40 output=56\n",
      "I0604 12:16:06.776473 140019516405568 efficientnet_model.py:143] round_filter input=40 output=56\n",
      "I0604 12:16:06.776615 140019516405568 efficientnet_model.py:143] round_filter input=80 output=112\n",
      "I0604 12:16:07.124933 140019516405568 efficientnet_model.py:143] round_filter input=80 output=112\n",
      "I0604 12:16:07.125083 140019516405568 efficientnet_model.py:143] round_filter input=112 output=160\n",
      "I0604 12:16:07.475575 140019516405568 efficientnet_model.py:143] round_filter input=112 output=160\n",
      "I0604 12:16:07.475762 140019516405568 efficientnet_model.py:143] round_filter input=192 output=272\n",
      "I0604 12:16:07.947630 140019516405568 efficientnet_model.py:143] round_filter input=192 output=272\n",
      "I0604 12:16:07.947815 140019516405568 efficientnet_model.py:143] round_filter input=320 output=448\n",
      "I0604 12:16:08.062626 140019516405568 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
      "I0604 12:16:08.084455 140019516405568 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n"
=======
      "I0604 14:50:25.005819 139855472297792 efficientnet_model.py:143] round_filter input=112 output=120\n",
      "I0604 14:50:25.005991 139855472297792 efficientnet_model.py:143] round_filter input=192 output=208\n",
      "I0604 14:50:25.292777 139855472297792 efficientnet_model.py:143] round_filter input=192 output=208\n",
      "I0604 14:50:25.292930 139855472297792 efficientnet_model.py:143] round_filter input=320 output=352\n",
      "I0604 14:50:25.409934 139855472297792 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
      "I0604 14:50:25.433202 139855472297792 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 14:50:25.487290 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0604 14:50:25.487408 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
      "I0604 14:50:25.487458 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 6\n",
      "I0604 14:50:25.488848 139855472297792 efficientnet_model.py:143] round_filter input=32 output=40\n",
      "I0604 14:50:25.502131 139855472297792 efficientnet_model.py:143] round_filter input=32 output=40\n",
      "I0604 14:50:25.502206 139855472297792 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 14:50:25.592741 139855472297792 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 14:50:25.592854 139855472297792 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0604 14:50:25.763098 139855472297792 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0604 14:50:25.763229 139855472297792 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0604 14:50:25.932997 139855472297792 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0604 14:50:25.933123 139855472297792 efficientnet_model.py:143] round_filter input=80 output=96\n",
      "I0604 14:50:26.219841 139855472297792 efficientnet_model.py:143] round_filter input=80 output=96\n",
      "I0604 14:50:26.219995 139855472297792 efficientnet_model.py:143] round_filter input=112 output=136\n",
      "I0604 14:50:26.506964 139855472297792 efficientnet_model.py:143] round_filter input=112 output=136\n",
      "I0604 14:50:26.507099 139855472297792 efficientnet_model.py:143] round_filter input=192 output=232\n",
      "I0604 14:50:26.850596 139855472297792 efficientnet_model.py:143] round_filter input=192 output=232\n",
      "I0604 14:50:26.850751 139855472297792 efficientnet_model.py:143] round_filter input=320 output=384\n",
      "I0604 14:50:26.963936 139855472297792 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
      "I0604 14:50:26.985494 139855472297792 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 14:50:27.044946 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I0604 14:50:27.045080 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
      "I0604 14:50:27.045126 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 7\n",
      "I0604 14:50:27.046502 139855472297792 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0604 14:50:27.058658 139855472297792 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0604 14:50:27.058743 139855472297792 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 14:50:27.149238 139855472297792 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 14:50:27.149350 139855472297792 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0604 14:50:27.379409 139855472297792 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0604 14:50:27.379543 139855472297792 efficientnet_model.py:143] round_filter input=40 output=56\n",
      "I0604 14:50:27.607167 139855472297792 efficientnet_model.py:143] round_filter input=40 output=56\n",
      "I0604 14:50:27.607295 139855472297792 efficientnet_model.py:143] round_filter input=80 output=112\n",
      "I0604 14:50:27.953712 139855472297792 efficientnet_model.py:143] round_filter input=80 output=112\n",
      "I0604 14:50:27.953886 139855472297792 efficientnet_model.py:143] round_filter input=112 output=160\n",
      "I0604 14:50:28.301154 139855472297792 efficientnet_model.py:143] round_filter input=112 output=160\n",
      "I0604 14:50:28.301300 139855472297792 efficientnet_model.py:143] round_filter input=192 output=272\n",
      "I0604 14:50:28.766801 139855472297792 efficientnet_model.py:143] round_filter input=192 output=272\n",
      "I0604 14:50:28.766968 139855472297792 efficientnet_model.py:143] round_filter input=320 output=448\n",
      "I0604 14:50:28.880516 139855472297792 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
      "I0604 14:50:28.903036 139855472297792 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n"
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "I0604 12:16:08.431102 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I0604 12:16:08.431291 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
      "I0604 12:16:08.431373 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 7\n",
      "I0604 12:16:08.432895 140019516405568 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0604 12:16:08.445641 140019516405568 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0604 12:16:08.445722 140019516405568 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 12:16:08.586113 140019516405568 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 12:16:08.586246 140019516405568 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0604 12:16:08.876193 140019516405568 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0604 12:16:08.876351 140019516405568 efficientnet_model.py:143] round_filter input=40 output=64\n",
      "I0604 12:16:09.165420 140019516405568 efficientnet_model.py:143] round_filter input=40 output=64\n",
      "I0604 12:16:09.165580 140019516405568 efficientnet_model.py:143] round_filter input=80 output=128\n",
      "I0604 12:16:09.569298 140019516405568 efficientnet_model.py:143] round_filter input=80 output=128\n",
      "I0604 12:16:09.569458 140019516405568 efficientnet_model.py:143] round_filter input=112 output=176\n",
      "I0604 12:16:09.973331 140019516405568 efficientnet_model.py:143] round_filter input=112 output=176\n",
      "I0604 12:16:09.973490 140019516405568 efficientnet_model.py:143] round_filter input=192 output=304\n",
      "I0604 12:16:10.494059 140019516405568 efficientnet_model.py:143] round_filter input=192 output=304\n",
      "I0604 12:16:10.494220 140019516405568 efficientnet_model.py:143] round_filter input=320 output=512\n",
      "I0604 12:16:10.665517 140019516405568 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
      "I0604 12:16:10.688427 140019516405568 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 12:16:10.771111 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I0604 12:16:10.771263 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
      "I0604 12:16:10.771311 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 8\n",
      "I0604 12:16:10.772749 140019516405568 efficientnet_model.py:143] round_filter input=32 output=56\n",
      "I0604 12:16:10.786006 140019516405568 efficientnet_model.py:143] round_filter input=32 output=56\n",
      "I0604 12:16:10.786079 140019516405568 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0604 12:16:10.923635 140019516405568 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0604 12:16:10.923776 140019516405568 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0604 12:16:11.270153 140019516405568 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0604 12:16:11.270312 140019516405568 efficientnet_model.py:143] round_filter input=40 output=72\n",
      "I0604 12:16:11.615469 140019516405568 efficientnet_model.py:143] round_filter input=40 output=72\n",
      "I0604 12:16:11.615614 140019516405568 efficientnet_model.py:143] round_filter input=80 output=144\n",
      "I0604 12:16:12.079166 140019516405568 efficientnet_model.py:143] round_filter input=80 output=144\n",
      "I0604 12:16:12.079321 140019516405568 efficientnet_model.py:143] round_filter input=112 output=200\n",
      "I0604 12:16:12.542259 140019516405568 efficientnet_model.py:143] round_filter input=112 output=200\n",
      "I0604 12:16:12.542405 140019516405568 efficientnet_model.py:143] round_filter input=192 output=344\n",
      "I0604 12:16:13.396212 140019516405568 efficientnet_model.py:143] round_filter input=192 output=344\n",
      "I0604 12:16:13.396355 140019516405568 efficientnet_model.py:143] round_filter input=320 output=576\n",
      "I0604 12:16:13.575879 140019516405568 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
      "I0604 12:16:13.598521 140019516405568 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 12:16:13.694716 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I0604 12:16:13.694846 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
      "I0604 12:16:13.694938 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 8\n",
      "I0604 12:16:13.696341 140019516405568 efficientnet_model.py:143] round_filter input=32 output=64\n",
      "I0604 12:16:13.708751 140019516405568 efficientnet_model.py:143] round_filter input=32 output=64\n",
      "I0604 12:16:13.708830 140019516405568 efficientnet_model.py:143] round_filter input=16 output=32\n"
=======
      "I0604 14:50:29.242540 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I0604 14:50:29.242716 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
      "I0604 14:50:29.242763 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 7\n",
      "I0604 14:50:29.244234 139855472297792 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0604 14:50:29.257435 139855472297792 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0604 14:50:29.257508 139855472297792 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 14:50:29.396936 139855472297792 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 14:50:29.397068 139855472297792 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0604 14:50:29.691451 139855472297792 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0604 14:50:29.691610 139855472297792 efficientnet_model.py:143] round_filter input=40 output=64\n",
      "I0604 14:50:29.980289 139855472297792 efficientnet_model.py:143] round_filter input=40 output=64\n",
      "I0604 14:50:29.980450 139855472297792 efficientnet_model.py:143] round_filter input=80 output=128\n",
      "I0604 14:50:30.379958 139855472297792 efficientnet_model.py:143] round_filter input=80 output=128\n",
      "I0604 14:50:30.380110 139855472297792 efficientnet_model.py:143] round_filter input=112 output=176\n",
      "I0604 14:50:30.801538 139855472297792 efficientnet_model.py:143] round_filter input=112 output=176\n",
      "I0604 14:50:30.801715 139855472297792 efficientnet_model.py:143] round_filter input=192 output=304\n",
      "I0604 14:50:31.315668 139855472297792 efficientnet_model.py:143] round_filter input=192 output=304\n",
      "I0604 14:50:31.315809 139855472297792 efficientnet_model.py:143] round_filter input=320 output=512\n",
      "I0604 14:50:31.485720 139855472297792 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
      "I0604 14:50:31.507036 139855472297792 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 14:50:31.587359 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I0604 14:50:31.587490 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
      "I0604 14:50:31.587568 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 8\n",
      "I0604 14:50:31.588954 139855472297792 efficientnet_model.py:143] round_filter input=32 output=56\n",
      "I0604 14:50:31.601296 139855472297792 efficientnet_model.py:143] round_filter input=32 output=56\n",
      "I0604 14:50:31.601366 139855472297792 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0604 14:50:31.738288 139855472297792 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0604 14:50:31.738407 139855472297792 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0604 14:50:32.086179 139855472297792 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0604 14:50:32.086334 139855472297792 efficientnet_model.py:143] round_filter input=40 output=72\n",
      "I0604 14:50:32.431923 139855472297792 efficientnet_model.py:143] round_filter input=40 output=72\n",
      "I0604 14:50:32.432068 139855472297792 efficientnet_model.py:143] round_filter input=80 output=144\n",
      "I0604 14:50:32.890937 139855472297792 efficientnet_model.py:143] round_filter input=80 output=144\n",
      "I0604 14:50:32.891084 139855472297792 efficientnet_model.py:143] round_filter input=112 output=200\n",
      "I0604 14:50:33.351494 139855472297792 efficientnet_model.py:143] round_filter input=112 output=200\n",
      "I0604 14:50:33.351629 139855472297792 efficientnet_model.py:143] round_filter input=192 output=344\n",
      "I0604 14:50:34.184695 139855472297792 efficientnet_model.py:143] round_filter input=192 output=344\n",
      "I0604 14:50:34.184826 139855472297792 efficientnet_model.py:143] round_filter input=320 output=576\n",
      "I0604 14:50:34.361479 139855472297792 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
      "I0604 14:50:34.383230 139855472297792 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 14:50:34.476186 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I0604 14:50:34.476311 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
      "I0604 14:50:34.476393 139855472297792 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 8\n",
      "I0604 14:50:34.477793 139855472297792 efficientnet_model.py:143] round_filter input=32 output=64\n",
      "I0604 14:50:34.489859 139855472297792 efficientnet_model.py:143] round_filter input=32 output=64\n",
      "I0604 14:50:34.489936 139855472297792 efficientnet_model.py:143] round_filter input=16 output=32\n"
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "I0604 12:16:13.899262 140019516405568 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0604 12:16:13.899398 140019516405568 efficientnet_model.py:143] round_filter input=24 output=48\n",
      "I0604 12:16:14.313197 140019516405568 efficientnet_model.py:143] round_filter input=24 output=48\n",
      "I0604 12:16:14.313328 140019516405568 efficientnet_model.py:143] round_filter input=40 output=80\n",
      "I0604 12:16:14.730289 140019516405568 efficientnet_model.py:143] round_filter input=40 output=80\n",
      "I0604 12:16:14.730424 140019516405568 efficientnet_model.py:143] round_filter input=80 output=160\n",
      "I0604 12:16:15.314172 140019516405568 efficientnet_model.py:143] round_filter input=80 output=160\n",
      "I0604 12:16:15.314306 140019516405568 efficientnet_model.py:143] round_filter input=112 output=224\n",
      "I0604 12:16:15.894876 140019516405568 efficientnet_model.py:143] round_filter input=112 output=224\n",
      "I0604 12:16:15.895009 140019516405568 efficientnet_model.py:143] round_filter input=192 output=384\n",
      "I0604 12:16:16.653286 140019516405568 efficientnet_model.py:143] round_filter input=192 output=384\n",
      "I0604 12:16:16.653409 140019516405568 efficientnet_model.py:143] round_filter input=320 output=640\n",
      "I0604 12:16:16.885907 140019516405568 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
      "I0604 12:16:16.908070 140019516405568 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 16.59s\n",
      "I0604 12:16:17.020110 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 16.59s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I0604 12:16:17.028485 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I0604 12:16:17.029984 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I0604 12:16:17.030311 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I0604 12:16:17.031620 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
=======
      "I0604 14:50:34.677487 139855472297792 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0604 14:50:34.677613 139855472297792 efficientnet_model.py:143] round_filter input=24 output=48\n",
      "I0604 14:50:35.087833 139855472297792 efficientnet_model.py:143] round_filter input=24 output=48\n",
      "I0604 14:50:35.087962 139855472297792 efficientnet_model.py:143] round_filter input=40 output=80\n",
      "I0604 14:50:35.494953 139855472297792 efficientnet_model.py:143] round_filter input=40 output=80\n",
      "I0604 14:50:35.495087 139855472297792 efficientnet_model.py:143] round_filter input=80 output=160\n",
      "I0604 14:50:36.077861 139855472297792 efficientnet_model.py:143] round_filter input=80 output=160\n",
      "I0604 14:50:36.077988 139855472297792 efficientnet_model.py:143] round_filter input=112 output=224\n",
      "I0604 14:50:36.661187 139855472297792 efficientnet_model.py:143] round_filter input=112 output=224\n",
      "I0604 14:50:36.661316 139855472297792 efficientnet_model.py:143] round_filter input=192 output=384\n",
      "I0604 14:50:37.420617 139855472297792 efficientnet_model.py:143] round_filter input=192 output=384\n",
      "I0604 14:50:37.420755 139855472297792 efficientnet_model.py:143] round_filter input=320 output=640\n",
      "I0604 14:50:37.658795 139855472297792 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
      "I0604 14:50:37.680369 139855472297792 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 16.49s\n",
      "I0604 14:50:37.792579 139855472297792 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 16.49s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I0604 14:50:37.802568 139855472297792 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I0604 14:50:37.804013 139855472297792 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I0604 14:50:37.804345 139855472297792 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I0604 14:50:37.805600 139855472297792 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
<<<<<<< HEAD
      "I0604 12:16:17.032799 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I0604 12:16:17.033087 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I0604 12:16:17.033943 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 21.468s\n",
=======
      "I0604 14:50:37.806768 139855472297792 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I0604 14:50:37.807054 139855472297792 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I0604 14:50:37.807909 139855472297792 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 21.230s\n",
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "# (For cont')\n",
    "\n",
    "!python object_detection/builders/model_builder_tf2_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TntgsRpEhkGL"
   },
   "source": [
    "## Download pre-trained model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KljfW26pixrB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/train1/data\n"
     ]
    }
   ],
   "source": [
    "%cd {DATA_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt install wget -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T4wCOUPwikAs",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
    "!tar -xzvf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the pipeline.config (IMPORTANT!)\n",
    "change the checkpoint, label map, train, and test in data/pipeline.config to below path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: /root/train1/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\n",
      "Label map: /root/train1/data/label_map.pbtxt\n",
      "Train: /root/train1/data/train.record\n",
      "Test: /root/train1/data/test.record\n"
     ]
    }
   ],
   "source": [
    "print(\"Checkpoint: \" + os.path.join(DATA_PATH, \"ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\", \"checkpoint\", \"ckpt-0\"))\n",
    "print(\"Label map: \" + LABEL_MAP_PATH)\n",
    "print(\"Train: \" + TRAIN_DATA_PATH)\n",
    "print(\"Test: \" + TEST_DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also change add \"max_to_keep=None\" as parameter in tf.train.Saver() in /research/object_detection/legacy/trainer.py \\\n",
    "So it'll be:\\\n",
    "\\\n",
    "saver = tf.train.Saver(max_to_keep=None, \\\n",
    "keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vr1BMAKl2kG"
   },
   "source": [
    "## Load Tensorboard"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 12,
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
   "metadata": {
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1654187407390,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "zNqRvjtKl2Xn",
    "scrolled": true
   },
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1b38004d969088b1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1b38004d969088b1\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
   "source": [
    "# (For cont')\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /root/train1/training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYYViyUNmFDy"
   },
   "source": [
    "# Train The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTgNmhT5alLz"
   },
   "source": [
    "## Fixing incompatible libraries"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 13,
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19274,
     "status": "ok",
     "timestamp": 1654182416826,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "JbRpZNpOn_NY",
    "outputId": "6cd829fa-4f44-41dc-ee92-a33ad74da7d2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: opencv-python 4.5.5.64\n",
      "Uninstalling opencv-python-4.5.5.64:\n",
      "  Successfully uninstalled opencv-python-4.5.5.64\n",
      "\u001b[33mWARNING: Skipping opencv-contrib-python as it is not installed.\u001b[0m\n",
      "Found existing installation: opencv-python-headless 4.5.5.64\n",
      "Uninstalling opencv-python-headless-4.5.5.64:\n",
      "  Successfully uninstalled opencv-python-headless-4.5.5.64\n",
      "Collecting opencv-python==4.5.5.64\n",
      "  Using cached opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5; python_version >= \"3.7\" in /usr/local/lib/python3.8/dist-packages (from opencv-python==4.5.5.64) (1.22.4)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.5.64\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting opencv-contrib-python==4.5.5.64\n",
      "  Downloading opencv_contrib_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (66.7 MB)\n",
<<<<<<< HEAD
      "\u001b[K     |████████████████████████████████| 66.7 MB 153 kB/s eta 0:00:01\n",
=======
      "\u001b[K     |████████████████████████████████| 66.7 MB 563 kB/s eta 0:00:01\n",
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3; python_version >= \"3.8\" in /usr/local/lib/python3.8/dist-packages (from opencv-contrib-python==4.5.5.64) (1.22.4)\n",
      "Installing collected packages: opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-4.5.5.64\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting opencv-python-headless==4.5.5.64\n",
      "  Using cached opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5; python_version >= \"3.7\" in /usr/local/lib/python3.8/dist-packages (from opencv-python-headless==4.5.5.64) (1.22.4)\n",
      "Installing collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.5.5.64\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# (For cont')\n",
    "#==4.5.4.60\n",
    "!pip uninstall opencv-python --y\n",
    "!pip uninstall opencv-contrib-python --y\n",
    "!pip uninstall opencv-python-headless --y\n",
    "!pip install opencv-python==4.5.5.64 \n",
    "!pip install opencv-contrib-python==4.5.5.64 \n",
    "!pip install opencv-python-headless==4.5.5.64 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1614535,
     "status": "ok",
     "timestamp": 1654189769240,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "Qv3gj-XQmaJN",
    "outputId": "8766c2e3-5058-4c4c-8be9-a5dcd8d1488c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/train1/models/research/object_detection\n",
<<<<<<< HEAD
      "2022-06-04 13:46:36.873828: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-04 13:46:37.702119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22340 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-06-04 13:46:37.703288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22340 MB memory:  -> device: 1, name: NVIDIA RTX A5000, pci bus id: 0000:82:00.0, compute capability: 8.6\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "I0604 13:46:38.355494 139845714130752 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "INFO:tensorflow:Maybe overwriting train_steps: None\n",
      "I0604 13:46:38.359873 139845714130752 config_util.py:552] Maybe overwriting train_steps: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0604 13:46:38.359943 139845714130752 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0604 13:46:38.383476 139845714130752 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['/root/train1/data/train.record']\n",
      "I0604 13:46:38.388278 139845714130752 dataset_builder.py:162] Reading unweighted datasets: ['/root/train1/data/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['/root/train1/data/train.record']\n",
      "I0604 13:46:38.388381 139845714130752 dataset_builder.py:79] Reading record datasets for input file: ['/root/train1/data/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0604 13:46:38.388435 139845714130752 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0604 13:46:38.388480 139845714130752 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0604 13:46:38.390277 139845714130752 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
=======
      "2022-06-04 16:24:48.896280: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-04 16:24:49.732425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22340 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-06-04 16:24:49.733457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22340 MB memory:  -> device: 1, name: NVIDIA RTX A5000, pci bus id: 0000:82:00.0, compute capability: 8.6\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "I0604 16:24:50.198556 139647679457088 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "INFO:tensorflow:Maybe overwriting train_steps: None\n",
      "I0604 16:24:50.202862 139647679457088 config_util.py:552] Maybe overwriting train_steps: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0604 16:24:50.202931 139647679457088 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0604 16:24:50.305547 139647679457088 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['/root/train1/data/train.record']\n",
      "I0604 16:24:50.310402 139647679457088 dataset_builder.py:162] Reading unweighted datasets: ['/root/train1/data/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['/root/train1/data/train.record']\n",
      "I0604 16:24:50.310515 139647679457088 dataset_builder.py:79] Reading record datasets for input file: ['/root/train1/data/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0604 16:24:50.310570 139647679457088 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0604 16:24:50.310616 139647679457088 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0604 16:24:50.312423 139647679457088 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
<<<<<<< HEAD
      "W0604 13:46:38.408495 139845714130752 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
=======
      "W0604 16:24:50.330785 139647679457088 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
<<<<<<< HEAD
      "W0604 13:46:45.403353 139845714130752 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
=======
      "W0604 16:24:57.361249 139647679457088 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
<<<<<<< HEAD
      "W0604 13:46:48.512858 139845714130752 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
=======
      "W0604 16:25:00.393006 139647679457088 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
<<<<<<< HEAD
      "W0604 13:46:49.959858 139845714130752 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
=======
      "W0604 16:25:01.931123 139647679457088 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
<<<<<<< HEAD
      "W0604 13:46:52.838091 139777470875392 deprecation.py:554] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
=======
      "W0604 16:25:04.675110 139580523144960 deprecation.py:554] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "/usr/local/lib/python3.8/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "INFO:tensorflow:batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\n",
<<<<<<< HEAD
      "I0604 13:47:18.030015 139845714130752 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 13:47:20.435827 139845714130752 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 13:47:20.437555 139845714130752 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 13:47:20.438800 139845714130752 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 13:47:20.440032 139845714130752 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
=======
      "I0604 16:25:29.794574 139647679457088 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 16:25:31.206598 139647679457088 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 16:25:31.208299 139647679457088 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 16:25:31.209574 139647679457088 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 16:25:31.210827 139647679457088 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\n",
<<<<<<< HEAD
      "I0604 13:47:38.168219 139845714130752 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 13:47:40.404885 139845714130752 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 13:47:40.408127 139845714130752 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 13:47:40.410799 139845714130752 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 13:47:40.412044 139845714130752 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\n",
      "I0604 13:47:58.144204 139845714130752 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 13:48:01.172582 139845714130752 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 13:48:01.174952 139845714130752 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\n",
      "I0604 13:48:18.737613 139845714130752 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\n",
      "2022-06-04 13:48:35.267787: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: while/body/_1/replica_1/train_input_images/write_summary/summary_cond/branch_executed/_5325\n",
      "2022-06-04 13:48:49.037575: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-06-04 13:48:50.054199: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-06-04 13:48:50.967514: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "INFO:tensorflow:Step 35100 per-step time 1.585s\n",
      "I0604 13:49:30.933800 139845714130752 model_lib_v2.py:705] Step 35100 per-step time 1.585s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.099196866,\n",
      " 'Loss/localization_loss': 0.073883474,\n",
      " 'Loss/regularization_loss': 0.08507425,\n",
      " 'Loss/total_loss': 0.2581546,\n",
      " 'learning_rate': 0.01690546}\n",
      "I0604 13:49:30.934031 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.099196866,\n",
      " 'Loss/localization_loss': 0.073883474,\n",
      " 'Loss/regularization_loss': 0.08507425,\n",
      " 'Loss/total_loss': 0.2581546,\n",
      " 'learning_rate': 0.01690546}\n",
      "INFO:tensorflow:Step 35200 per-step time 0.375s\n",
      "I0604 13:50:08.402032 139845714130752 model_lib_v2.py:705] Step 35200 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09986697,\n",
      " 'Loss/localization_loss': 0.06878224,\n",
      " 'Loss/regularization_loss': 0.084984526,\n",
      " 'Loss/total_loss': 0.25363374,\n",
      " 'learning_rate': 0.016696546}\n",
      "I0604 13:50:08.402251 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.09986697,\n",
      " 'Loss/localization_loss': 0.06878224,\n",
      " 'Loss/regularization_loss': 0.084984526,\n",
      " 'Loss/total_loss': 0.25363374,\n",
      " 'learning_rate': 0.016696546}\n",
      "INFO:tensorflow:Step 35300 per-step time 0.373s\n",
      "I0604 13:50:45.738347 139845714130752 model_lib_v2.py:705] Step 35300 per-step time 0.373s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08428559,\n",
      " 'Loss/localization_loss': 0.0633734,\n",
      " 'Loss/regularization_loss': 0.08489934,\n",
      " 'Loss/total_loss': 0.23255832,\n",
      " 'learning_rate': 0.016488582}\n",
      "I0604 13:50:45.738628 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.08428559,\n",
      " 'Loss/localization_loss': 0.0633734,\n",
      " 'Loss/regularization_loss': 0.08489934,\n",
      " 'Loss/total_loss': 0.23255832,\n",
      " 'learning_rate': 0.016488582}\n",
      "INFO:tensorflow:Step 35400 per-step time 0.372s\n",
      "I0604 13:51:22.897936 139845714130752 model_lib_v2.py:705] Step 35400 per-step time 0.372s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08998175,\n",
      " 'Loss/localization_loss': 0.053246718,\n",
      " 'Loss/regularization_loss': 0.08481042,\n",
      " 'Loss/total_loss': 0.22803889,\n",
      " 'learning_rate': 0.016281592}\n",
      "I0604 13:51:22.898156 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.08998175,\n",
      " 'Loss/localization_loss': 0.053246718,\n",
      " 'Loss/regularization_loss': 0.08481042,\n",
      " 'Loss/total_loss': 0.22803889,\n",
      " 'learning_rate': 0.016281592}\n",
      "INFO:tensorflow:Step 35500 per-step time 0.375s\n",
      "I0604 13:52:00.348120 139845714130752 model_lib_v2.py:705] Step 35500 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.086089775,\n",
      " 'Loss/localization_loss': 0.05662597,\n",
      " 'Loss/regularization_loss': 0.08472237,\n",
      " 'Loss/total_loss': 0.22743812,\n",
      " 'learning_rate': 0.01607557}\n",
      "I0604 13:52:00.348347 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.086089775,\n",
      " 'Loss/localization_loss': 0.05662597,\n",
      " 'Loss/regularization_loss': 0.08472237,\n",
      " 'Loss/total_loss': 0.22743812,\n",
      " 'learning_rate': 0.01607557}\n",
      "INFO:tensorflow:Step 35600 per-step time 0.373s\n",
      "I0604 13:52:37.628314 139845714130752 model_lib_v2.py:705] Step 35600 per-step time 0.373s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10358511,\n",
      " 'Loss/localization_loss': 0.072112486,\n",
      " 'Loss/regularization_loss': 0.08464108,\n",
      " 'Loss/total_loss': 0.26033866,\n",
      " 'learning_rate': 0.01587054}\n",
      "I0604 13:52:37.628572 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.10358511,\n",
      " 'Loss/localization_loss': 0.072112486,\n",
      " 'Loss/regularization_loss': 0.08464108,\n",
      " 'Loss/total_loss': 0.26033866,\n",
      " 'learning_rate': 0.01587054}\n",
      "INFO:tensorflow:Step 35700 per-step time 0.376s\n",
      "I0604 13:53:15.254410 139845714130752 model_lib_v2.py:705] Step 35700 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08622354,\n",
      " 'Loss/localization_loss': 0.05690019,\n",
      " 'Loss/regularization_loss': 0.08455365,\n",
      " 'Loss/total_loss': 0.22767739,\n",
      " 'learning_rate': 0.015666498}\n",
      "I0604 13:53:15.254681 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.08622354,\n",
      " 'Loss/localization_loss': 0.05690019,\n",
      " 'Loss/regularization_loss': 0.08455365,\n",
      " 'Loss/total_loss': 0.22767739,\n",
      " 'learning_rate': 0.015666498}\n",
      "INFO:tensorflow:Step 35800 per-step time 0.376s\n",
      "I0604 13:53:52.895099 139845714130752 model_lib_v2.py:705] Step 35800 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11205125,\n",
      " 'Loss/localization_loss': 0.09019689,\n",
      " 'Loss/regularization_loss': 0.0844711,\n",
      " 'Loss/total_loss': 0.28671926,\n",
      " 'learning_rate': 0.015463452}\n",
      "I0604 13:53:52.895463 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.11205125,\n",
      " 'Loss/localization_loss': 0.09019689,\n",
      " 'Loss/regularization_loss': 0.0844711,\n",
      " 'Loss/total_loss': 0.28671926,\n",
      " 'learning_rate': 0.015463452}\n",
      "INFO:tensorflow:Step 35900 per-step time 0.376s\n",
      "I0604 13:54:30.475187 139845714130752 model_lib_v2.py:705] Step 35900 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0827273,\n",
      " 'Loss/localization_loss': 0.069916554,\n",
      " 'Loss/regularization_loss': 0.08438844,\n",
      " 'Loss/total_loss': 0.2370323,\n",
      " 'learning_rate': 0.015261421}\n",
      "I0604 13:54:30.475435 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.0827273,\n",
      " 'Loss/localization_loss': 0.069916554,\n",
      " 'Loss/regularization_loss': 0.08438844,\n",
      " 'Loss/total_loss': 0.2370323,\n",
      " 'learning_rate': 0.015261421}\n"
=======
      "I0604 16:25:49.030204 139647679457088 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 16:25:50.275377 139647679457088 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 16:25:50.277860 139647679457088 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 16:25:50.279083 139647679457088 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 16:25:50.280289 139647679457088 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\n",
      "I0604 16:26:08.086915 139647679457088 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 16:26:10.922812 139647679457088 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 16:26:10.925217 139647679457088 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\n",
      "I0604 16:26:28.427394 139647679457088 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\n",
      "2022-06-04 16:26:45.386439: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: while/body/_1/replica_1/train_input_images/write_summary/summary_cond/branch_executed/_5325\n",
      "2022-06-04 16:26:59.616938: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-06-04 16:27:00.410522: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-06-04 16:27:01.534205: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "INFO:tensorflow:Step 52100 per-step time 1.572s\n",
      "I0604 16:27:41.522659 139647679457088 model_lib_v2.py:705] Step 52100 per-step time 1.572s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07972051,\n",
      " 'Loss/localization_loss': 0.055014405,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21486913,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:27:41.522937 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07972051,\n",
      " 'Loss/localization_loss': 0.055014405,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21486913,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 52200 per-step time 0.374s\n",
      "I0604 16:28:18.952744 139647679457088 model_lib_v2.py:705] Step 52200 per-step time 0.374s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07750781,\n",
      " 'Loss/localization_loss': 0.040135257,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.19777727,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:28:18.952967 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07750781,\n",
      " 'Loss/localization_loss': 0.040135257,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.19777727,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 52300 per-step time 0.377s\n",
      "I0604 16:28:56.636076 139647679457088 model_lib_v2.py:705] Step 52300 per-step time 0.377s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08254483,\n",
      " 'Loss/localization_loss': 0.060981415,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.22366044,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:28:56.636304 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.08254483,\n",
      " 'Loss/localization_loss': 0.060981415,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.22366044,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 52400 per-step time 0.378s\n",
      "I0604 16:29:34.432367 139647679457088 model_lib_v2.py:705] Step 52400 per-step time 0.378s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0665116,\n",
      " 'Loss/localization_loss': 0.03743403,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.18407983,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:29:34.432589 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.0665116,\n",
      " 'Loss/localization_loss': 0.03743403,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.18407983,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 52500 per-step time 0.376s\n",
      "I0604 16:30:12.004588 139647679457088 model_lib_v2.py:705] Step 52500 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07333964,\n",
      " 'Loss/localization_loss': 0.053626716,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.20710056,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:30:12.004814 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07333964,\n",
      " 'Loss/localization_loss': 0.053626716,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.20710056,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 52600 per-step time 0.374s\n",
      "I0604 16:30:49.418768 139647679457088 model_lib_v2.py:705] Step 52600 per-step time 0.374s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07854256,\n",
      " 'Loss/localization_loss': 0.0453649,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.20404166,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:30:49.418987 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07854256,\n",
      " 'Loss/localization_loss': 0.0453649,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.20404166,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 52700 per-step time 0.375s\n",
      "I0604 16:31:26.945039 139647679457088 model_lib_v2.py:705] Step 52700 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07708362,\n",
      " 'Loss/localization_loss': 0.045381576,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.20259939,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:31:26.945268 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07708362,\n",
      " 'Loss/localization_loss': 0.045381576,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.20259939,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 52800 per-step time 0.376s\n",
      "I0604 16:32:04.525604 139647679457088 model_lib_v2.py:705] Step 52800 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0762977,\n",
      " 'Loss/localization_loss': 0.06116703,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21759893,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:32:04.525846 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.0762977,\n",
      " 'Loss/localization_loss': 0.06116703,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21759893,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 52900 per-step time 0.376s\n",
      "I0604 16:32:42.135859 139647679457088 model_lib_v2.py:705] Step 52900 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.095065765,\n",
      " 'Loss/localization_loss': 0.063583136,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.23878309,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:32:42.136118 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.095065765,\n",
      " 'Loss/localization_loss': 0.063583136,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.23878309,\n",
      " 'learning_rate': 0.0}\n"
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "INFO:tensorflow:Step 36000 per-step time 0.377s\n",
      "I0604 13:55:08.196836 139845714130752 model_lib_v2.py:705] Step 36000 per-step time 0.377s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08683649,\n",
      " 'Loss/localization_loss': 0.050683074,\n",
      " 'Loss/regularization_loss': 0.084303446,\n",
      " 'Loss/total_loss': 0.221823,\n",
      " 'learning_rate': 0.015060408}\n",
      "I0604 13:55:08.197113 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.08683649,\n",
      " 'Loss/localization_loss': 0.050683074,\n",
      " 'Loss/regularization_loss': 0.084303446,\n",
      " 'Loss/total_loss': 0.221823,\n",
      " 'learning_rate': 0.015060408}\n",
      "INFO:tensorflow:Step 36100 per-step time 0.378s\n",
      "I0604 13:55:46.024338 139845714130752 model_lib_v2.py:705] Step 36100 per-step time 0.378s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.088408165,\n",
      " 'Loss/localization_loss': 0.054447204,\n",
      " 'Loss/regularization_loss': 0.08422506,\n",
      " 'Loss/total_loss': 0.22708043,\n",
      " 'learning_rate': 0.014860413}\n",
      "I0604 13:55:46.024629 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.088408165,\n",
      " 'Loss/localization_loss': 0.054447204,\n",
      " 'Loss/regularization_loss': 0.08422506,\n",
      " 'Loss/total_loss': 0.22708043,\n",
      " 'learning_rate': 0.014860413}\n",
      "INFO:tensorflow:Step 36200 per-step time 0.375s\n",
      "I0604 13:56:23.517332 139845714130752 model_lib_v2.py:705] Step 36200 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07624216,\n",
      " 'Loss/localization_loss': 0.04169526,\n",
      " 'Loss/regularization_loss': 0.08414292,\n",
      " 'Loss/total_loss': 0.20208034,\n",
      " 'learning_rate': 0.014661457}\n",
      "I0604 13:56:23.517592 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.07624216,\n",
      " 'Loss/localization_loss': 0.04169526,\n",
      " 'Loss/regularization_loss': 0.08414292,\n",
      " 'Loss/total_loss': 0.20208034,\n",
      " 'learning_rate': 0.014661457}\n",
      "INFO:tensorflow:Step 36300 per-step time 0.375s\n",
      "I0604 13:57:00.985305 139845714130752 model_lib_v2.py:705] Step 36300 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07950924,\n",
      " 'Loss/localization_loss': 0.06723987,\n",
      " 'Loss/regularization_loss': 0.08406404,\n",
      " 'Loss/total_loss': 0.23081315,\n",
      " 'learning_rate': 0.014463534}\n",
      "I0604 13:57:00.985574 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.07950924,\n",
      " 'Loss/localization_loss': 0.06723987,\n",
      " 'Loss/regularization_loss': 0.08406404,\n",
      " 'Loss/total_loss': 0.23081315,\n",
      " 'learning_rate': 0.014463534}\n",
      "INFO:tensorflow:Step 36400 per-step time 0.374s\n",
      "I0604 13:57:38.389726 139845714130752 model_lib_v2.py:705] Step 36400 per-step time 0.374s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.078803204,\n",
      " 'Loss/localization_loss': 0.046613887,\n",
      " 'Loss/regularization_loss': 0.08398726,\n",
      " 'Loss/total_loss': 0.20940435,\n",
      " 'learning_rate': 0.014266672}\n",
      "I0604 13:57:38.389986 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.078803204,\n",
      " 'Loss/localization_loss': 0.046613887,\n",
      " 'Loss/regularization_loss': 0.08398726,\n",
      " 'Loss/total_loss': 0.20940435,\n",
      " 'learning_rate': 0.014266672}\n",
      "INFO:tensorflow:Step 36500 per-step time 0.377s\n",
      "I0604 13:58:16.126589 139845714130752 model_lib_v2.py:705] Step 36500 per-step time 0.377s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08634111,\n",
      " 'Loss/localization_loss': 0.061503418,\n",
      " 'Loss/regularization_loss': 0.08390913,\n",
      " 'Loss/total_loss': 0.23175366,\n",
      " 'learning_rate': 0.014070864}\n",
      "I0604 13:58:16.126871 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.08634111,\n",
      " 'Loss/localization_loss': 0.061503418,\n",
      " 'Loss/regularization_loss': 0.08390913,\n",
      " 'Loss/total_loss': 0.23175366,\n",
      " 'learning_rate': 0.014070864}\n",
      "INFO:tensorflow:Step 36600 per-step time 0.375s\n",
      "I0604 13:58:53.593353 139845714130752 model_lib_v2.py:705] Step 36600 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09354222,\n",
      " 'Loss/localization_loss': 0.06225849,\n",
      " 'Loss/regularization_loss': 0.08384289,\n",
      " 'Loss/total_loss': 0.23964359,\n",
      " 'learning_rate': 0.013876116}\n",
      "I0604 13:58:53.593608 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.09354222,\n",
      " 'Loss/localization_loss': 0.06225849,\n",
      " 'Loss/regularization_loss': 0.08384289,\n",
      " 'Loss/total_loss': 0.23964359,\n",
      " 'learning_rate': 0.013876116}\n",
      "INFO:tensorflow:Step 36700 per-step time 0.373s\n",
      "I0604 13:59:30.906304 139845714130752 model_lib_v2.py:705] Step 36700 per-step time 0.373s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.075980455,\n",
      " 'Loss/localization_loss': 0.04694947,\n",
      " 'Loss/regularization_loss': 0.08376573,\n",
      " 'Loss/total_loss': 0.20669565,\n",
      " 'learning_rate': 0.013682451}\n",
      "I0604 13:59:30.906552 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.075980455,\n",
      " 'Loss/localization_loss': 0.04694947,\n",
      " 'Loss/regularization_loss': 0.08376573,\n",
      " 'Loss/total_loss': 0.20669565,\n",
      " 'learning_rate': 0.013682451}\n",
      "INFO:tensorflow:Step 36800 per-step time 0.371s\n",
      "I0604 14:00:08.027385 139845714130752 model_lib_v2.py:705] Step 36800 per-step time 0.371s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08417933,\n",
      " 'Loss/localization_loss': 0.059234485,\n",
      " 'Loss/regularization_loss': 0.08369021,\n",
      " 'Loss/total_loss': 0.22710402,\n",
      " 'learning_rate': 0.013489859}\n",
      "I0604 14:00:08.027628 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.08417933,\n",
      " 'Loss/localization_loss': 0.059234485,\n",
      " 'Loss/regularization_loss': 0.08369021,\n",
      " 'Loss/total_loss': 0.22710402,\n",
      " 'learning_rate': 0.013489859}\n",
      "INFO:tensorflow:Step 36900 per-step time 0.373s\n",
      "I0604 14:00:45.372045 139845714130752 model_lib_v2.py:705] Step 36900 per-step time 0.373s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07815106,\n",
      " 'Loss/localization_loss': 0.049337503,\n",
      " 'Loss/regularization_loss': 0.083617926,\n",
      " 'Loss/total_loss': 0.21110648,\n",
      " 'learning_rate': 0.013298363}\n",
      "I0604 14:00:45.372361 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.07815106,\n",
      " 'Loss/localization_loss': 0.049337503,\n",
      " 'Loss/regularization_loss': 0.083617926,\n",
      " 'Loss/total_loss': 0.21110648,\n",
      " 'learning_rate': 0.013298363}\n",
      "INFO:tensorflow:Step 37000 per-step time 0.371s\n",
      "I0604 14:01:22.503489 139845714130752 model_lib_v2.py:705] Step 37000 per-step time 0.371s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0953514,\n",
      " 'Loss/localization_loss': 0.069294296,\n",
      " 'Loss/regularization_loss': 0.08354351,\n",
      " 'Loss/total_loss': 0.24818921,\n",
      " 'learning_rate': 0.013107965}\n",
      "I0604 14:01:22.503744 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.0953514,\n",
      " 'Loss/localization_loss': 0.069294296,\n",
      " 'Loss/regularization_loss': 0.08354351,\n",
      " 'Loss/total_loss': 0.24818921,\n",
      " 'learning_rate': 0.013107965}\n",
      "INFO:tensorflow:Step 37100 per-step time 0.375s\n",
      "I0604 14:01:59.957226 139845714130752 model_lib_v2.py:705] Step 37100 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.092423975,\n",
      " 'Loss/localization_loss': 0.06428283,\n",
      " 'Loss/regularization_loss': 0.083473355,\n",
      " 'Loss/total_loss': 0.24018016,\n",
      " 'learning_rate': 0.012918665}\n",
      "I0604 14:01:59.957542 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.092423975,\n",
      " 'Loss/localization_loss': 0.06428283,\n",
      " 'Loss/regularization_loss': 0.083473355,\n",
      " 'Loss/total_loss': 0.24018016,\n",
      " 'learning_rate': 0.012918665}\n",
      "INFO:tensorflow:Step 37200 per-step time 0.377s\n",
      "I0604 14:02:37.652700 139845714130752 model_lib_v2.py:705] Step 37200 per-step time 0.377s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.086706504,\n",
      " 'Loss/localization_loss': 0.06498009,\n",
      " 'Loss/regularization_loss': 0.0834004,\n",
      " 'Loss/total_loss': 0.23508699,\n",
      " 'learning_rate': 0.012730486}\n",
      "I0604 14:02:37.652983 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.086706504,\n",
      " 'Loss/localization_loss': 0.06498009,\n",
      " 'Loss/regularization_loss': 0.0834004,\n",
      " 'Loss/total_loss': 0.23508699,\n",
      " 'learning_rate': 0.012730486}\n",
      "INFO:tensorflow:Step 37300 per-step time 0.378s\n",
      "I0604 14:03:15.442804 139845714130752 model_lib_v2.py:705] Step 37300 per-step time 0.378s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09139445,\n",
      " 'Loss/localization_loss': 0.07155137,\n",
      " 'Loss/regularization_loss': 0.08332952,\n",
      " 'Loss/total_loss': 0.24627534,\n",
      " 'learning_rate': 0.012543423}\n",
      "I0604 14:03:15.443069 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.09139445,\n",
      " 'Loss/localization_loss': 0.07155137,\n",
      " 'Loss/regularization_loss': 0.08332952,\n",
      " 'Loss/total_loss': 0.24627534,\n",
      " 'learning_rate': 0.012543423}\n",
      "INFO:tensorflow:Step 37400 per-step time 0.374s\n",
      "I0604 14:03:52.872107 139845714130752 model_lib_v2.py:705] Step 37400 per-step time 0.374s\n"
=======
      "INFO:tensorflow:Step 53000 per-step time 0.375s\n",
      "I0604 16:33:19.585717 139647679457088 model_lib_v2.py:705] Step 53000 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07710032,\n",
      " 'Loss/localization_loss': 0.05606947,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21330398,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:33:19.585942 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07710032,\n",
      " 'Loss/localization_loss': 0.05606947,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21330398,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 53100 per-step time 0.378s\n",
      "I0604 16:33:57.388876 139647679457088 model_lib_v2.py:705] Step 53100 per-step time 0.378s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.085542396,\n",
      " 'Loss/localization_loss': 0.06469309,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.23036969,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:33:57.389104 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.085542396,\n",
      " 'Loss/localization_loss': 0.06469309,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.23036969,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 53200 per-step time 0.376s\n",
      "I0604 16:34:35.030494 139647679457088 model_lib_v2.py:705] Step 53200 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.079935655,\n",
      " 'Loss/localization_loss': 0.05547349,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21554333,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:34:35.030729 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.079935655,\n",
      " 'Loss/localization_loss': 0.05547349,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21554333,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 53300 per-step time 0.375s\n",
      "I0604 16:35:12.506982 139647679457088 model_lib_v2.py:705] Step 53300 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.080135435,\n",
      " 'Loss/localization_loss': 0.05718076,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21745038,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:35:12.507197 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.080135435,\n",
      " 'Loss/localization_loss': 0.05718076,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21745038,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 53400 per-step time 0.376s\n",
      "I0604 16:35:50.137289 139647679457088 model_lib_v2.py:705] Step 53400 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.06823836,\n",
      " 'Loss/localization_loss': 0.041690297,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.19006287,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:35:50.137512 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.06823836,\n",
      " 'Loss/localization_loss': 0.041690297,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.19006287,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 53500 per-step time 0.375s\n",
      "I0604 16:36:27.646626 139647679457088 model_lib_v2.py:705] Step 53500 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08043106,\n",
      " 'Loss/localization_loss': 0.050437428,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21100268,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:36:27.646912 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.08043106,\n",
      " 'Loss/localization_loss': 0.050437428,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21100268,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 53600 per-step time 0.379s\n",
      "I0604 16:37:05.566968 139647679457088 model_lib_v2.py:705] Step 53600 per-step time 0.379s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08572991,\n",
      " 'Loss/localization_loss': 0.059033494,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.22489762,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:37:05.567254 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.08572991,\n",
      " 'Loss/localization_loss': 0.059033494,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.22489762,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 53700 per-step time 0.378s\n",
      "I0604 16:37:43.331966 139647679457088 model_lib_v2.py:705] Step 53700 per-step time 0.378s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07836811,\n",
      " 'Loss/localization_loss': 0.048351556,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.20685387,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:37:43.332210 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07836811,\n",
      " 'Loss/localization_loss': 0.048351556,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.20685387,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 53800 per-step time 0.375s\n",
      "I0604 16:38:20.811022 139647679457088 model_lib_v2.py:705] Step 53800 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.080618516,\n",
      " 'Loss/localization_loss': 0.06884469,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.22959742,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:38:20.811246 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.080618516,\n",
      " 'Loss/localization_loss': 0.06884469,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.22959742,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 53900 per-step time 0.375s\n",
      "I0604 16:38:58.269699 139647679457088 model_lib_v2.py:705] Step 53900 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08189219,\n",
      " 'Loss/localization_loss': 0.052214812,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.2142412,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:38:58.269946 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.08189219,\n",
      " 'Loss/localization_loss': 0.052214812,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.2142412,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 54000 per-step time 0.375s\n",
      "I0604 16:39:35.747614 139647679457088 model_lib_v2.py:705] Step 54000 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.070347376,\n",
      " 'Loss/localization_loss': 0.049425565,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.19990712,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:39:35.747845 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.070347376,\n",
      " 'Loss/localization_loss': 0.049425565,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.19990712,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 54100 per-step time 0.377s\n",
      "I0604 16:40:13.481501 139647679457088 model_lib_v2.py:705] Step 54100 per-step time 0.377s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.079750195,\n",
      " 'Loss/localization_loss': 0.057083245,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21696764,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:40:13.481772 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.079750195,\n",
      " 'Loss/localization_loss': 0.057083245,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21696764,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 54200 per-step time 0.377s\n",
      "I0604 16:40:51.209238 139647679457088 model_lib_v2.py:705] Step 54200 per-step time 0.377s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07044137,\n",
      " 'Loss/localization_loss': 0.041803226,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.19237879,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:40:51.209537 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07044137,\n",
      " 'Loss/localization_loss': 0.041803226,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.19237879,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 54300 per-step time 0.376s\n",
      "I0604 16:41:28.829288 139647679457088 model_lib_v2.py:705] Step 54300 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07998245,\n",
      " 'Loss/localization_loss': 0.055902902,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21601956,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:41:28.829547 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07998245,\n",
      " 'Loss/localization_loss': 0.055902902,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21601956,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 54400 per-step time 0.378s\n",
      "I0604 16:42:06.663973 139647679457088 model_lib_v2.py:705] Step 54400 per-step time 0.378s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.06621306,\n",
      " 'Loss/localization_loss': 0.038735192,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.18508245,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:42:06.664228 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.06621306,\n",
      " 'Loss/localization_loss': 0.038735192,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.18508245,\n",
      " 'learning_rate': 0.0}\n"
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "INFO:tensorflow:{'Loss/classification_loss': 0.1006263,\n",
      " 'Loss/localization_loss': 0.076978244,\n",
      " 'Loss/regularization_loss': 0.08326079,\n",
      " 'Loss/total_loss': 0.26086533,\n",
      " 'learning_rate': 0.012357492}\n",
      "I0604 14:03:52.872341 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.1006263,\n",
      " 'Loss/localization_loss': 0.076978244,\n",
      " 'Loss/regularization_loss': 0.08326079,\n",
      " 'Loss/total_loss': 0.26086533,\n",
      " 'learning_rate': 0.012357492}\n",
      "INFO:tensorflow:Step 37500 per-step time 0.375s\n",
      "I0604 14:04:30.359035 139845714130752 model_lib_v2.py:705] Step 37500 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.079909235,\n",
      " 'Loss/localization_loss': 0.04955727,\n",
      " 'Loss/regularization_loss': 0.08319079,\n",
      " 'Loss/total_loss': 0.2126573,\n",
      " 'learning_rate': 0.012172694}\n",
      "I0604 14:04:30.359259 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.079909235,\n",
      " 'Loss/localization_loss': 0.04955727,\n",
      " 'Loss/regularization_loss': 0.08319079,\n",
      " 'Loss/total_loss': 0.2126573,\n",
      " 'learning_rate': 0.012172694}\n",
      "INFO:tensorflow:Step 37600 per-step time 0.374s\n",
      "I0604 14:05:07.754761 139845714130752 model_lib_v2.py:705] Step 37600 per-step time 0.374s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.099479236,\n",
      " 'Loss/localization_loss': 0.07255593,\n",
      " 'Loss/regularization_loss': 0.08312788,\n",
      " 'Loss/total_loss': 0.25516304,\n",
      " 'learning_rate': 0.011989042}\n",
      "I0604 14:05:07.754983 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.099479236,\n",
      " 'Loss/localization_loss': 0.07255593,\n",
      " 'Loss/regularization_loss': 0.08312788,\n",
      " 'Loss/total_loss': 0.25516304,\n",
      " 'learning_rate': 0.011989042}\n",
      "INFO:tensorflow:Step 37700 per-step time 0.374s\n",
      "I0604 14:05:45.189032 139845714130752 model_lib_v2.py:705] Step 37700 per-step time 0.374s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.072795145,\n",
      " 'Loss/localization_loss': 0.046159312,\n",
      " 'Loss/regularization_loss': 0.08306013,\n",
      " 'Loss/total_loss': 0.2020146,\n",
      " 'learning_rate': 0.011806537}\n",
      "I0604 14:05:45.189266 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.072795145,\n",
      " 'Loss/localization_loss': 0.046159312,\n",
      " 'Loss/regularization_loss': 0.08306013,\n",
      " 'Loss/total_loss': 0.2020146,\n",
      " 'learning_rate': 0.011806537}\n",
      "INFO:tensorflow:Step 37800 per-step time 0.376s\n",
      "I0604 14:06:22.783204 139845714130752 model_lib_v2.py:705] Step 37800 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09398847,\n",
      " 'Loss/localization_loss': 0.07289493,\n",
      " 'Loss/regularization_loss': 0.08299381,\n",
      " 'Loss/total_loss': 0.24987721,\n",
      " 'learning_rate': 0.011625201}\n",
      "I0604 14:06:22.783442 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.09398847,\n",
      " 'Loss/localization_loss': 0.07289493,\n",
      " 'Loss/regularization_loss': 0.08299381,\n",
      " 'Loss/total_loss': 0.24987721,\n",
      " 'learning_rate': 0.011625201}\n"
=======
      "INFO:tensorflow:Step 54500 per-step time 0.375s\n",
      "I0604 16:42:44.116230 139647679457088 model_lib_v2.py:705] Step 54500 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07817604,\n",
      " 'Loss/localization_loss': 0.04293523,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.20124546,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:42:44.116542 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07817604,\n",
      " 'Loss/localization_loss': 0.04293523,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.20124546,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 54600 per-step time 0.377s\n",
      "I0604 16:43:21.804257 139647679457088 model_lib_v2.py:705] Step 54600 per-step time 0.377s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09039383,\n",
      " 'Loss/localization_loss': 0.0687283,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.23925632,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:43:21.804511 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.09039383,\n",
      " 'Loss/localization_loss': 0.0687283,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.23925632,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 54700 per-step time 0.376s\n",
      "I0604 16:43:59.412256 139647679457088 model_lib_v2.py:705] Step 54700 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.06033825,\n",
      " 'Loss/localization_loss': 0.037582427,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.17805487,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:43:59.412508 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.06033825,\n",
      " 'Loss/localization_loss': 0.037582427,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.17805487,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 54800 per-step time 0.376s\n",
      "I0604 16:44:37.014987 139647679457088 model_lib_v2.py:705] Step 54800 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.071696274,\n",
      " 'Loss/localization_loss': 0.045972966,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.19780344,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:44:37.015232 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.071696274,\n",
      " 'Loss/localization_loss': 0.045972966,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.19780344,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 54900 per-step time 0.377s\n",
      "I0604 16:45:14.667991 139647679457088 model_lib_v2.py:705] Step 54900 per-step time 0.377s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.072955824,\n",
      " 'Loss/localization_loss': 0.043036297,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.19612631,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:45:14.668263 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.072955824,\n",
      " 'Loss/localization_loss': 0.043036297,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.19612631,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 55000 per-step time 0.374s\n",
      "I0604 16:45:52.044449 139647679457088 model_lib_v2.py:705] Step 55000 per-step time 0.374s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.077901855,\n",
      " 'Loss/localization_loss': 0.048165433,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.2062015,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:45:52.044723 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.077901855,\n",
      " 'Loss/localization_loss': 0.048165433,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.2062015,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 55100 per-step time 0.381s\n",
      "I0604 16:46:30.096415 139647679457088 model_lib_v2.py:705] Step 55100 per-step time 0.381s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08871447,\n",
      " 'Loss/localization_loss': 0.058927044,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.22777571,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:46:30.096657 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.08871447,\n",
      " 'Loss/localization_loss': 0.058927044,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.22777571,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 55200 per-step time 0.377s\n",
      "I0604 16:47:07.795331 139647679457088 model_lib_v2.py:705] Step 55200 per-step time 0.377s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07792626,\n",
      " 'Loss/localization_loss': 0.047845487,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.20590594,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:47:07.795601 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07792626,\n",
      " 'Loss/localization_loss': 0.047845487,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.20590594,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 55300 per-step time 0.376s\n",
      "I0604 16:47:45.383008 139647679457088 model_lib_v2.py:705] Step 55300 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07977414,\n",
      " 'Loss/localization_loss': 0.056206156,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21611449,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:47:45.383268 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07977414,\n",
      " 'Loss/localization_loss': 0.056206156,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21611449,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 55400 per-step time 0.377s\n",
      "I0604 16:48:23.133522 139647679457088 model_lib_v2.py:705] Step 55400 per-step time 0.377s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07674001,\n",
      " 'Loss/localization_loss': 0.042087756,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.19896197,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:48:23.133848 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07674001,\n",
      " 'Loss/localization_loss': 0.042087756,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.19896197,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 55500 per-step time 0.379s\n",
      "I0604 16:49:01.012387 139647679457088 model_lib_v2.py:705] Step 55500 per-step time 0.379s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.083659634,\n",
      " 'Loss/localization_loss': 0.050665513,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21445934,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:49:01.012650 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.083659634,\n",
      " 'Loss/localization_loss': 0.050665513,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21445934,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 55600 per-step time 0.376s\n",
      "I0604 16:49:38.565311 139647679457088 model_lib_v2.py:705] Step 55600 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09271842,\n",
      " 'Loss/localization_loss': 0.061153766,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.23400638,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:49:38.565575 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.09271842,\n",
      " 'Loss/localization_loss': 0.061153766,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.23400638,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 55700 per-step time 0.378s\n",
      "I0604 16:50:16.321951 139647679457088 model_lib_v2.py:705] Step 55700 per-step time 0.378s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.090516195,\n",
      " 'Loss/localization_loss': 0.061093688,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.23174408,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:50:16.322230 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.090516195,\n",
      " 'Loss/localization_loss': 0.061093688,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.23174408,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 55800 per-step time 0.376s\n",
      "I0604 16:50:53.956303 139647679457088 model_lib_v2.py:705] Step 55800 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09679127,\n",
      " 'Loss/localization_loss': 0.0886577,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.26558316,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:50:53.956570 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.09679127,\n",
      " 'Loss/localization_loss': 0.0886577,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.26558316,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 55900 per-step time 0.375s\n",
      "I0604 16:51:31.479706 139647679457088 model_lib_v2.py:705] Step 55900 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07792346,\n",
      " 'Loss/localization_loss': 0.058771342,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.216829,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:51:31.480014 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07792346,\n",
      " 'Loss/localization_loss': 0.058771342,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.216829,\n",
      " 'learning_rate': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 56000 per-step time 0.376s\n",
      "I0604 16:52:09.109758 139647679457088 model_lib_v2.py:705] Step 56000 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07607384,\n",
      " 'Loss/localization_loss': 0.04750592,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.20371395,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:52:09.110014 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07607384,\n",
      " 'Loss/localization_loss': 0.04750592,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.20371395,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 56100 per-step time 0.381s\n",
      "I0604 16:52:47.202192 139647679457088 model_lib_v2.py:705] Step 56100 per-step time 0.381s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.076186046,\n",
      " 'Loss/localization_loss': 0.040681124,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.19700137,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:52:47.202474 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.076186046,\n",
      " 'Loss/localization_loss': 0.040681124,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.19700137,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 56200 per-step time 0.377s\n",
      "I0604 16:53:24.901290 139647679457088 model_lib_v2.py:705] Step 56200 per-step time 0.377s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08144186,\n",
      " 'Loss/localization_loss': 0.05434042,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21591648,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:53:24.901557 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.08144186,\n",
      " 'Loss/localization_loss': 0.05434042,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21591648,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 56300 per-step time 0.376s\n",
      "I0604 16:54:02.488338 139647679457088 model_lib_v2.py:705] Step 56300 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0921593,\n",
      " 'Loss/localization_loss': 0.08054069,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.2528342,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:54:02.488613 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.0921593,\n",
      " 'Loss/localization_loss': 0.08054069,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.2528342,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 56400 per-step time 0.374s\n",
      "I0604 16:54:39.936615 139647679457088 model_lib_v2.py:705] Step 56400 per-step time 0.374s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.083986074,\n",
      " 'Loss/localization_loss': 0.056931317,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.22105159,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:54:39.936882 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.083986074,\n",
      " 'Loss/localization_loss': 0.056931317,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.22105159,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 56500 per-step time 0.378s\n",
      "I0604 16:55:17.771001 139647679457088 model_lib_v2.py:705] Step 56500 per-step time 0.378s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08207635,\n",
      " 'Loss/localization_loss': 0.049589902,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21180046,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:55:17.771360 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.08207635,\n",
      " 'Loss/localization_loss': 0.049589902,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21180046,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 56600 per-step time 0.378s\n",
      "I0604 16:55:55.603225 139647679457088 model_lib_v2.py:705] Step 56600 per-step time 0.378s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.088504806,\n",
      " 'Loss/localization_loss': 0.068558365,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.23719737,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:55:55.603496 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.088504806,\n",
      " 'Loss/localization_loss': 0.068558365,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.23719737,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 56700 per-step time 0.377s\n",
      "I0604 16:56:33.308323 139647679457088 model_lib_v2.py:705] Step 56700 per-step time 0.377s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07958564,\n",
      " 'Loss/localization_loss': 0.052638717,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21235856,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:56:33.308568 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07958564,\n",
      " 'Loss/localization_loss': 0.052638717,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21235856,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 56800 per-step time 0.375s\n",
      "I0604 16:57:10.777305 139647679457088 model_lib_v2.py:705] Step 56800 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08576682,\n",
      " 'Loss/localization_loss': 0.06375556,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.22965658,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:57:10.777565 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.08576682,\n",
      " 'Loss/localization_loss': 0.06375556,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.22965658,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 56900 per-step time 0.376s\n",
      "I0604 16:57:48.337204 139647679457088 model_lib_v2.py:705] Step 56900 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08214906,\n",
      " 'Loss/localization_loss': 0.051307097,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21359035,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:57:48.337488 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.08214906,\n",
      " 'Loss/localization_loss': 0.051307097,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21359035,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 57000 per-step time 0.375s\n",
      "I0604 16:58:25.855884 139647679457088 model_lib_v2.py:705] Step 57000 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07280439,\n",
      " 'Loss/localization_loss': 0.037987486,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.19092607,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:58:25.856147 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07280439,\n",
      " 'Loss/localization_loss': 0.037987486,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.19092607,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 57100 per-step time 0.378s\n",
      "I0604 16:59:03.663653 139647679457088 model_lib_v2.py:705] Step 57100 per-step time 0.378s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.075821765,\n",
      " 'Loss/localization_loss': 0.057112098,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21306807,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:59:03.663978 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.075821765,\n",
      " 'Loss/localization_loss': 0.057112098,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21306807,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 57200 per-step time 0.376s\n",
      "I0604 16:59:41.246655 139647679457088 model_lib_v2.py:705] Step 57200 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08107145,\n",
      " 'Loss/localization_loss': 0.05984477,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.22105041,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 16:59:41.246919 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.08107145,\n",
      " 'Loss/localization_loss': 0.05984477,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.22105041,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 57300 per-step time 0.377s\n",
      "I0604 17:00:18.939077 139647679457088 model_lib_v2.py:705] Step 57300 per-step time 0.377s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07858578,\n",
      " 'Loss/localization_loss': 0.058295086,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21701506,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:00:18.939319 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07858578,\n",
      " 'Loss/localization_loss': 0.058295086,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21701506,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 57400 per-step time 0.375s\n",
      "I0604 17:00:56.476454 139647679457088 model_lib_v2.py:705] Step 57400 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08645718,\n",
      " 'Loss/localization_loss': 0.06585659,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.23244797,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:00:56.476734 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.08645718,\n",
      " 'Loss/localization_loss': 0.06585659,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.23244797,\n",
      " 'learning_rate': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 57500 per-step time 0.377s\n",
      "I0604 17:01:34.214839 139647679457088 model_lib_v2.py:705] Step 57500 per-step time 0.377s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.083893105,\n",
      " 'Loss/localization_loss': 0.04753662,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21156392,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:01:34.215083 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.083893105,\n",
      " 'Loss/localization_loss': 0.04753662,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21156392,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 57600 per-step time 0.380s\n",
      "I0604 17:02:12.197392 139647679457088 model_lib_v2.py:705] Step 57600 per-step time 0.380s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.079981714,\n",
      " 'Loss/localization_loss': 0.06600614,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.22612205,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:02:12.197629 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.079981714,\n",
      " 'Loss/localization_loss': 0.06600614,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.22612205,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 57700 per-step time 0.378s\n",
      "I0604 17:02:49.982027 139647679457088 model_lib_v2.py:705] Step 57700 per-step time 0.378s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08446083,\n",
      " 'Loss/localization_loss': 0.061359942,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.22595498,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:02:49.982267 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.08446083,\n",
      " 'Loss/localization_loss': 0.061359942,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.22595498,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 57800 per-step time 0.374s\n",
      "I0604 17:03:27.420504 139647679457088 model_lib_v2.py:705] Step 57800 per-step time 0.374s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09299394,\n",
      " 'Loss/localization_loss': 0.06436449,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.23749262,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:03:27.420763 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.09299394,\n",
      " 'Loss/localization_loss': 0.06436449,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.23749262,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 57900 per-step time 0.378s\n",
      "I0604 17:04:05.190447 139647679457088 model_lib_v2.py:705] Step 57900 per-step time 0.378s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08060316,\n",
      " 'Loss/localization_loss': 0.051248908,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21198627,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:04:05.190872 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.08060316,\n",
      " 'Loss/localization_loss': 0.051248908,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21198627,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 58000 per-step time 0.375s\n",
      "I0604 17:04:42.716246 139647679457088 model_lib_v2.py:705] Step 58000 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07197316,\n",
      " 'Loss/localization_loss': 0.04005389,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.19216123,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:04:42.716595 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07197316,\n",
      " 'Loss/localization_loss': 0.04005389,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.19216123,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 58100 per-step time 0.379s\n",
      "I0604 17:05:20.614714 139647679457088 model_lib_v2.py:705] Step 58100 per-step time 0.379s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08867324,\n",
      " 'Loss/localization_loss': 0.07355743,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.24236488,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:05:20.614980 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.08867324,\n",
      " 'Loss/localization_loss': 0.07355743,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.24236488,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 58200 per-step time 0.378s\n",
      "I0604 17:05:58.406642 139647679457088 model_lib_v2.py:705] Step 58200 per-step time 0.378s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.068366736,\n",
      " 'Loss/localization_loss': 0.035761863,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.1842628,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:05:58.406918 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.068366736,\n",
      " 'Loss/localization_loss': 0.035761863,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.1842628,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 58300 per-step time 0.379s\n",
      "I0604 17:06:36.259617 139647679457088 model_lib_v2.py:705] Step 58300 per-step time 0.379s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08770162,\n",
      " 'Loss/localization_loss': 0.06350056,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.23133639,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:06:36.259878 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.08770162,\n",
      " 'Loss/localization_loss': 0.06350056,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.23133639,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 58400 per-step time 0.377s\n",
      "I0604 17:07:13.924926 139647679457088 model_lib_v2.py:705] Step 58400 per-step time 0.377s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08429335,\n",
      " 'Loss/localization_loss': 0.04979913,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.2142267,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:07:13.925281 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.08429335,\n",
      " 'Loss/localization_loss': 0.04979913,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.2142267,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 58500 per-step time 0.377s\n",
      "I0604 17:07:51.596485 139647679457088 model_lib_v2.py:705] Step 58500 per-step time 0.377s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08289938,\n",
      " 'Loss/localization_loss': 0.061397992,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.22443157,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:07:51.596762 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.08289938,\n",
      " 'Loss/localization_loss': 0.061397992,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.22443157,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 58600 per-step time 0.377s\n",
      "I0604 17:08:29.319657 139647679457088 model_lib_v2.py:705] Step 58600 per-step time 0.377s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09186219,\n",
      " 'Loss/localization_loss': 0.06374148,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.23573786,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:08:29.320064 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.09186219,\n",
      " 'Loss/localization_loss': 0.06374148,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.23573786,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 58700 per-step time 0.380s\n",
      "I0604 17:09:07.358220 139647679457088 model_lib_v2.py:705] Step 58700 per-step time 0.380s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0770685,\n",
      " 'Loss/localization_loss': 0.04174029,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.19894299,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:09:07.358469 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.0770685,\n",
      " 'Loss/localization_loss': 0.04174029,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.19894299,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 58800 per-step time 0.379s\n",
      "I0604 17:09:45.299639 139647679457088 model_lib_v2.py:705] Step 58800 per-step time 0.379s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.082692556,\n",
      " 'Loss/localization_loss': 0.06286282,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.22568958,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:09:45.299946 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.082692556,\n",
      " 'Loss/localization_loss': 0.06286282,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.22568958,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 58900 per-step time 0.377s\n",
      "I0604 17:10:22.970093 139647679457088 model_lib_v2.py:705] Step 58900 per-step time 0.377s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08247461,\n",
      " 'Loss/localization_loss': 0.053171135,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21577993,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:10:22.970430 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.08247461,\n",
      " 'Loss/localization_loss': 0.053171135,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21577993,\n",
      " 'learning_rate': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 59000 per-step time 0.379s\n",
      "I0604 17:11:00.849910 139647679457088 model_lib_v2.py:705] Step 59000 per-step time 0.379s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.077747315,\n",
      " 'Loss/localization_loss': 0.0496214,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.2075029,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:11:00.850152 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.077747315,\n",
      " 'Loss/localization_loss': 0.0496214,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.2075029,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 59100 per-step time 0.381s\n",
      "I0604 17:11:38.902004 139647679457088 model_lib_v2.py:705] Step 59100 per-step time 0.381s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07308647,\n",
      " 'Loss/localization_loss': 0.062436543,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.2156572,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:11:38.902329 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07308647,\n",
      " 'Loss/localization_loss': 0.062436543,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.2156572,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 59200 per-step time 0.378s\n",
      "I0604 17:12:16.676146 139647679457088 model_lib_v2.py:705] Step 59200 per-step time 0.378s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0715487,\n",
      " 'Loss/localization_loss': 0.049947664,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.20163056,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:12:16.676423 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.0715487,\n",
      " 'Loss/localization_loss': 0.049947664,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.20163056,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 59300 per-step time 0.376s\n",
      "I0604 17:12:54.297910 139647679457088 model_lib_v2.py:705] Step 59300 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.080592945,\n",
      " 'Loss/localization_loss': 0.04610406,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.2068312,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:12:54.298180 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.080592945,\n",
      " 'Loss/localization_loss': 0.04610406,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.2068312,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 59400 per-step time 0.374s\n",
      "I0604 17:13:31.741981 139647679457088 model_lib_v2.py:705] Step 59400 per-step time 0.374s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07676944,\n",
      " 'Loss/localization_loss': 0.05873559,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21563923,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:13:31.742223 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07676944,\n",
      " 'Loss/localization_loss': 0.05873559,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21563923,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 59500 per-step time 0.379s\n",
      "I0604 17:14:09.663229 139647679457088 model_lib_v2.py:705] Step 59500 per-step time 0.379s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08766485,\n",
      " 'Loss/localization_loss': 0.06658856,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.2343876,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:14:09.663491 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.08766485,\n",
      " 'Loss/localization_loss': 0.06658856,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.2343876,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 59600 per-step time 0.377s\n",
      "I0604 17:14:47.388970 139647679457088 model_lib_v2.py:705] Step 59600 per-step time 0.377s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08540876,\n",
      " 'Loss/localization_loss': 0.05213642,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21767938,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:14:47.389238 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.08540876,\n",
      " 'Loss/localization_loss': 0.05213642,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21767938,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 59700 per-step time 0.375s\n",
      "I0604 17:15:24.839133 139647679457088 model_lib_v2.py:705] Step 59700 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07212924,\n",
      " 'Loss/localization_loss': 0.05180835,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.20407179,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:15:24.839408 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07212924,\n",
      " 'Loss/localization_loss': 0.05180835,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.20407179,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 59800 per-step time 0.375s\n",
      "I0604 17:16:02.325142 139647679457088 model_lib_v2.py:705] Step 59800 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07494192,\n",
      " 'Loss/localization_loss': 0.045102187,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.2001783,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:16:02.325460 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07494192,\n",
      " 'Loss/localization_loss': 0.045102187,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.2001783,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 59900 per-step time 0.375s\n",
      "I0604 17:16:39.795344 139647679457088 model_lib_v2.py:705] Step 59900 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.079946786,\n",
      " 'Loss/localization_loss': 0.056276537,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21635753,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:16:39.795616 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.079946786,\n",
      " 'Loss/localization_loss': 0.056276537,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.21635753,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 60000 per-step time 0.379s\n",
      "I0604 17:17:17.656753 139647679457088 model_lib_v2.py:705] Step 60000 per-step time 0.379s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.062377855,\n",
      " 'Loss/localization_loss': 0.032422096,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.17493415,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:17:17.656994 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.062377855,\n",
      " 'Loss/localization_loss': 0.032422096,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.17493415,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 60100 per-step time 0.380s\n",
      "I0604 17:17:55.651973 139647679457088 model_lib_v2.py:705] Step 60100 per-step time 0.380s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08397609,\n",
      " 'Loss/localization_loss': 0.068035156,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.23214546,\n",
      " 'learning_rate': 0.0}\n",
      "I0604 17:17:55.652283 139647679457088 model_lib_v2.py:708] {'Loss/classification_loss': 0.08397609,\n",
      " 'Loss/localization_loss': 0.068035156,\n",
      " 'Loss/regularization_loss': 0.0801342,\n",
      " 'Loss/total_loss': 0.23214546,\n",
      " 'learning_rate': 0.0}\n"
>>>>>>> 74cfdf21ff24f42b448ed1348f3a11cf3a9cc81b
     ]
    }
   ],
   "source": [
    "# (For cont')\n",
    "\n",
    "%cd {MAIN_PATH}/models/research/object_detection\n",
    "\n",
    "!python model_main_tf2.py \\\n",
    "--pipeline_config_path={CONFIG_PATH} \\\n",
    "--model_dir={TRAINING_PATH} \\\n",
    "--alsologtostderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/train1\n",
      "On branch main\r\n",
      "Your branch is up to date with 'origin/main'.\r\n",
      "\r\n",
      "Changes not staged for commit:\r\n",
      "  (use \"git add <file>...\" to update what will be committed)\r\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\r\n",
      "\t\u001b[31mmodified:   MyModel.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   training/checkpoint\u001b[m\r\n",
      "\r\n",
      "Untracked files:\r\n",
      "  (use \"git add <file>...\" to include in what will be committed)\r\n",
      "\t\u001b[31mtraining/ckpt-40.data-00000-of-00001\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-40.index\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-41.data-00000-of-00001\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-41.index\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-42.data-00000-of-00001\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-42.index\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-43.data-00000-of-00001\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-43.index\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-44.data-00000-of-00001\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-44.index\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-45.data-00000-of-00001\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-45.index\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-46.data-00000-of-00001\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-46.index\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-47.data-00000-of-00001\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-47.index\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-48.data-00000-of-00001\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-48.index\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-49.data-00000-of-00001\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-49.index\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-50.data-00000-of-00001\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-50.index\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-51.data-00000-of-00001\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-51.index\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-52.data-00000-of-00001\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-52.index\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-53.data-00000-of-00001\u001b[m\r\n",
      "\t\u001b[31mtraining/ckpt-53.index\u001b[m\r\n",
      "\t\u001b[31mtraining/train/events.out.tfevents.1654354273.d769da57293c.1711.0.v2\u001b[m\r\n",
      "\r\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\r\n"
     ]
    }
   ],
   "source": [
    "%cd /root/train1\n",
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add -A\n",
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 8110272] up to ckpt 53\n",
      " 31 files changed, 2364 insertions(+), 829 deletions(-)\n",
      " create mode 100644 training/ckpt-40.data-00000-of-00001\n",
      " create mode 100644 training/ckpt-40.index\n",
      " create mode 100644 training/ckpt-41.data-00000-of-00001\n",
      " create mode 100644 training/ckpt-41.index\n",
      " create mode 100644 training/ckpt-42.data-00000-of-00001\n",
      " create mode 100644 training/ckpt-42.index\n",
      " create mode 100644 training/ckpt-43.data-00000-of-00001\n",
      " create mode 100644 training/ckpt-43.index\n",
      " create mode 100644 training/ckpt-44.data-00000-of-00001\n",
      " create mode 100644 training/ckpt-44.index\n",
      " create mode 100644 training/ckpt-45.data-00000-of-00001\n",
      " create mode 100644 training/ckpt-45.index\n",
      " create mode 100644 training/ckpt-46.data-00000-of-00001\n",
      " create mode 100644 training/ckpt-46.index\n",
      " create mode 100644 training/ckpt-47.data-00000-of-00001\n",
      " create mode 100644 training/ckpt-47.index\n",
      " create mode 100644 training/ckpt-48.data-00000-of-00001\n",
      " create mode 100644 training/ckpt-48.index\n",
      " create mode 100644 training/ckpt-49.data-00000-of-00001\n",
      " create mode 100644 training/ckpt-49.index\n",
      " create mode 100644 training/ckpt-50.data-00000-of-00001\n",
      " create mode 100644 training/ckpt-50.index\n",
      " create mode 100644 training/ckpt-51.data-00000-of-00001\n",
      " create mode 100644 training/ckpt-51.index\n",
      " create mode 100644 training/ckpt-52.data-00000-of-00001\n",
      " create mode 100644 training/ckpt-52.index\n",
      " create mode 100644 training/ckpt-53.data-00000-of-00001\n",
      " create mode 100644 training/ckpt-53.index\n",
      " create mode 100644 training/train/events.out.tfevents.1654354273.d769da57293c.1711.0.v2\n",
      "Enumerating objects: 40, done.\n",
      "Counting objects: 100% (40/40), done.\n",
      "Delta compression using up to 48 threads\n",
      "Compressing objects: 100% (35/35), done.\n",
      "Writing objects: 100% (35/35), 266.27 MiB | 8.18 MiB/s, done.\n",
      "Total 35 (delta 19), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (19/19), completed with 5 local objects.\u001b[K\n",
      "To https://github.com/ahmadnurokhim/train1.git\n",
      "   a122ce1..8110272  main -> main\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!git commit -m \"up to ckpt 53\"\n",
    "!git push https://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@github.com/ahmadnurokhim/train1.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cvPZMyPiZFFO"
   },
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0eK0oTxsNcCK",
    "outputId": "710b71d9-24e7-40d2-a205-31b2961c967e"
   },
   "outputs": [],
   "source": [
    "!python model_main_tf2.py \\\n",
    "--model_dir={TRAINING_PATH} \\\n",
    "--pipeline_config_path={CONFIG_PATH} \\\n",
    "--checkpoint_dir={TRAINING_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWIDrr3ZQjj6"
   },
   "source": [
    "## Inference/Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 951,
     "status": "ok",
     "timestamp": 1654190006848,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "Ezl_U9UpT2Kd",
    "outputId": "cc9248b5-a4d5-4e17-d2e8-ef85fad4ee42"
   },
   "outputs": [],
   "source": [
    "!python exporter_main_v2.py \\\n",
    "--trained_checkpoint_dir={TRAINING_PATH} \\\n",
    "--pipeline_config_path={CONFIG_PATH} \\\n",
    "--output_directory {DATA_PATH}/inference_graph"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNZfYiFeNihRAo+EdSsnJrM",
   "collapsed_sections": [],
   "name": "MyModel.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "71824dd40866df3d2aa82f78c70152c0d364eafa49dfb98f28d6e83617cc2488"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
