{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwF2B1_gVgQM"
   },
   "source": [
    "# Note\n",
    "For continous training only run the \"for cont'\" cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJSAGCSOd2To"
   },
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 381,
     "status": "ok",
     "timestamp": 1654182338444,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "cTEojBogHuAQ",
    "outputId": "2bc37e82-20eb-49a5-e745-d13ebff60a2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/train1/training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "MAIN_PATH = os.getcwd()\n",
    "TRAINING_PATH = os.path.join(MAIN_PATH, \"training\")\n",
    "DATA_PATH = os.path.join(MAIN_PATH, \"data\")\n",
    "CONFIG_PATH = os.path.join(DATA_PATH, \"pipeline.config\")\n",
    "LABEL_MAP_PATH = os.path.join(DATA_PATH, \"label_map.pbtxt\")\n",
    "TRAIN_DATA_PATH = os.path.join(DATA_PATH, \"train.record\")\n",
    "VAL_DATA_PATH = os.path.join(DATA_PATH, \"validation.record\")\n",
    "TEST_DATA_PATH = os.path.join(DATA_PATH, \"test.record\")\n",
    "\n",
    "print(TRAINING_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "urls = ['https://dl.dropboxusercontent.com/s/9f5suk5oo5u7yyi/test.record',\n",
    "        'https://dl.dropboxusercontent.com/s/tqvtgswib6r4f8u/validation.record',\n",
    "        'https://dl.dropboxusercontent.com/s/6kgr2pwi7kgtmwb/train.record']\n",
    "names = [\"test.record\",\n",
    "        \"validation.record\",\n",
    "        \"train.record\"]\n",
    "\n",
    "for url, name in zip(urls, names):\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    open(os.path.join(DATA_PATH, name), 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldFNUUgIXUYj"
   },
   "source": [
    "## Clone the TensorFlow Model Garden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1654182343201,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "gVoGBfbhePZF",
    "outputId": "00071925-01bb-4d6f-babc-086111c62ba9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/train1\n",
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 74201, done.\u001b[K\n",
      "remote: Counting objects: 100% (287/287), done.\u001b[K\n",
      "remote: Compressing objects: 100% (181/181), done.\u001b[K\n",
      "remote: Total 74201 (delta 129), reused 235 (delta 97), pack-reused 73914\u001b[K\n",
      "Receiving objects: 100% (74201/74201), 580.22 MiB | 30.60 MiB/s, done.\n",
      "Resolving deltas: 100% (52568/52568), done.\n"
     ]
    }
   ],
   "source": [
    "# (For cont')\n",
    "%cd {MAIN_PATH}\n",
    "!git clone https://github.com/ahmadnurokhim/models.git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGaPKO0R_CYk"
   },
   "source": [
    "## TF Object Detection API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owhIVGjB-yAJ"
   },
   "source": [
    "### Compile/install the TF Object Detection API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3IwuD-NXo9l"
   },
   "source": [
    "CD to the models/research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1654182344628,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "lJ6tPMATeWDi",
    "outputId": "4f28f095-dc37-443b-946f-358918fd0814"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/train1/models/research\n"
     ]
    }
   ],
   "source": [
    "# (For cont')\n",
    "%cd {MAIN_PATH}/models/research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3ba50LW_xRd"
   },
   "source": [
    "### Install the protoc files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libprotobuf-dev libprotobuf-lite17 libprotobuf17 libprotoc17\n",
      "The following NEW packages will be installed:\n",
      "  libprotobuf-dev libprotobuf-lite17 libprotobuf17 libprotoc17\n",
      "  protobuf-compiler\n",
      "0 upgraded, 5 newly installed, 0 to remove and 15 not upgraded.\n",
      "Need to get 2758 kB of archives.\n",
      "After this operation, 16.9 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libprotobuf-lite17 amd64 3.6.1.3-2ubuntu5 [132 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 libprotobuf17 amd64 3.6.1.3-2ubuntu5 [798 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal/main amd64 libprotoc17 amd64 3.6.1.3-2ubuntu5 [646 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal/main amd64 libprotobuf-dev amd64 3.6.1.3-2ubuntu5 [1155 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu focal/universe amd64 protobuf-compiler amd64 3.6.1.3-2ubuntu5 [27.6 kB]\n",
      "Fetched 2758 kB in 1s (2136 kB/s)            \u001b[0m\u001b[33m\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libprotobuf-lite17:amd64.\n",
      "(Reading database ... 21502 files and directories currently installed.)\n",
      "Preparing to unpack .../libprotobuf-lite17_3.6.1.3-2ubuntu5_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  5%]\u001b[49m\u001b[39m [##........................................................] \u001b8Unpacking libprotobuf-lite17:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 10%]\u001b[49m\u001b[39m [#####.....................................................] \u001b8Selecting previously unselected package libprotobuf17:amd64.\n",
      "Preparing to unpack .../libprotobuf17_3.6.1.3-2ubuntu5_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 14%]\u001b[49m\u001b[39m [########..................................................] \u001b8Unpacking libprotobuf17:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 19%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Selecting previously unselected package libprotoc17:amd64.\n",
      "Preparing to unpack .../libprotoc17_3.6.1.3-2ubuntu5_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 24%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Unpacking libprotoc17:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 29%]\u001b[49m\u001b[39m [################..........................................] \u001b8Selecting previously unselected package libprotobuf-dev:amd64.\n",
      "Preparing to unpack .../libprotobuf-dev_3.6.1.3-2ubuntu5_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Unpacking libprotobuf-dev:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [######################....................................] \u001b8Selecting previously unselected package protobuf-compiler.\n",
      "Preparing to unpack .../protobuf-compiler_3.6.1.3-2ubuntu5_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 43%]\u001b[49m\u001b[39m [########################..................................] \u001b8Unpacking protobuf-compiler (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 48%]\u001b[49m\u001b[39m [###########################...............................] \u001b8Setting up libprotobuf-lite17:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 52%]\u001b[49m\u001b[39m [##############################............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 57%]\u001b[49m\u001b[39m [#################################.........................] \u001b8Setting up libprotobuf17:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [###################################.......................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 67%]\u001b[49m\u001b[39m [######################################....................] \u001b8Setting up libprotoc17:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 71%]\u001b[49m\u001b[39m [#########################################.................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 76%]\u001b[49m\u001b[39m [############################################..............] \u001b8Setting up protobuf-compiler (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 81%]\u001b[49m\u001b[39m [##############################################............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 86%]\u001b[49m\u001b[39m [#################################################.........] \u001b8Setting up libprotobuf-dev:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 90%]\u001b[49m\u001b[39m [####################################################......] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 95%]\u001b[49m\u001b[39m [#######################################################...] \u001b8Processing triggers for libc-bin (2.31-0ubuntu9.7) ...\n",
      "\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "!apt install protobuf-compiler -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1654182345692,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "2VCOalHYfYhh"
   },
   "outputs": [],
   "source": [
    "# (For cont')\n",
    "\n",
    "!protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1g8ZdQoWWN2_"
   },
   "source": [
    "(For cont') \\\n",
    "\\\n",
    "To avoid DNN library not found problem, open the object_detection/packages/tf2/setup.py and make sure to add these lines or you can just run the next cell\n",
    "```\n",
    "    'tensorflow==2.8.0',\n",
    "    'tf-models-official==2.8.0',\n",
    "    'tensorflow_io==0.23.1',\n",
    "    'keras==2.8.0',\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10979,
     "status": "ok",
     "timestamp": 1654182358394,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "t-hzXOqV-Opt",
    "outputId": "e0801f6c-9220-483f-f8f2-f585be4a2c69",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-models-official\n",
      "  Downloading tf_models_official-2.9.2-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kaggle>=1.3.9\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 7.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-hub>=0.6.0\n",
      "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "\u001b[K     |████████████████████████████████| 108 kB 66.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /usr/lib/python3/dist-packages (from tf-models-official) (1.14.0)\n",
      "Collecting pycocotools\n",
      "  Downloading pycocotools-2.0.4.tar.gz (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 67.2 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-models-official) (5.9.1)\n",
      "Collecting tensorflow-text~=2.9.0\n",
      "  Downloading tensorflow_text-2.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.6 MB 38.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
      "  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
      "\u001b[K     |████████████████████████████████| 662 kB 51.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.19.1\n",
      "  Downloading scipy-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 41.6 MB 54.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 2.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorflow~=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official) (2.9.1)\n",
      "Collecting pandas>=0.22.0\n",
      "  Downloading pandas-1.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7 MB 39.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tf-slim>=1.1.0\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "\u001b[K     |████████████████████████████████| 352 kB 50.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-datasets\n",
      "  Downloading tensorflow_datasets-4.6.0-py3-none-any.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 55.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
      "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 12.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Cython\n",
      "  Using cached Cython-0.29.30-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
      "Collecting tensorflow-model-optimization>=0.4.1\n",
      "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
      "\u001b[K     |████████████████████████████████| 237 kB 60.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacrebleu\n",
      "  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\n",
      "\u001b[K     |████████████████████████████████| 92 kB 13.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Pillow\n",
      "  Downloading Pillow-9.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 58.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 64.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gin-config\n",
      "  Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 9.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting oauth2client\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 7.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 47.8 MB 28.3 MB/s eta 0:00:01     |█████████████████████████████▏  | 43.5 MB 28.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tf-models-official) (1.22.4)\n",
      "Collecting google-api-python-client>=1.6.7\n",
      "  Downloading google_api_python_client-2.49.0-py2.py3-none-any.whl (8.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.5 MB 41.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.17.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 65.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 53.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi in /usr/lib/python3/dist-packages (from kaggle>=1.3.9->tf-models-official) (2019.11.28)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.8.2)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.22.0)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 8.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting python-slugify\n",
      "  Downloading python_slugify-6.1.2-py2.py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: urllib3 in /usr/lib/python3/dist-packages (from kaggle>=1.3.9->tf-models-official) (1.25.8)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-hub>=0.6.0->tf-models-official) (3.19.4)\n",
      "Collecting scikit-learn>=0.21.3\n",
      "  Downloading scikit_learn-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 31.2 MB 67.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (0.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.14.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (62.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (4.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (0.26.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (2.9.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.0.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (14.0.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (21.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.46.3)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (2.9.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (3.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.1.2)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.12)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.22.0->tf-models-official) (2022.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dill\n",
      "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 6.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official) (5.7.1)\n",
      "Collecting etils[epath]\n",
      "  Downloading etils-0.6.0-py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 9.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.8.0-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 8.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Collecting dm-tree~=0.1.1\n",
      "  Downloading dm_tree-0.1.7-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (142 kB)\n",
      "\u001b[K     |████████████████████████████████| 142 kB 61.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting portalocker\n",
      "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting tabulate>=0.8.9\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting regex\n",
      "  Downloading regex-2022.6.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\n",
      "\u001b[K     |████████████████████████████████| 764 kB 37.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting colorama\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official) (0.2.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official) (0.4.8)\n",
      "Collecting httplib2>=0.9.1\n",
      "  Downloading httplib2-0.20.4-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 7.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-httplib2>=0.1.0\n",
      "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (2.6.6)\n",
      "Collecting uritemplate<5,>=3.0.1\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Downloading google_api_core-2.8.1-py3-none-any.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 17.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typeguard>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 56.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
      "\u001b[K     |████████████████████████████████| 930 kB 57.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->tf-models-official) (3.0.9)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 8.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "\u001b[K     |████████████████████████████████| 306 kB 53.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (0.6.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (0.34.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (2.1.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (3.3.7)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official) (3.8.0)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.56.2-py2.py3-none-any.whl (211 kB)\n",
      "\u001b[K     |████████████████████████████████| 211 kB 53.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (5.1.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (4.11.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (3.2.0)\n",
      "Building wheels for collected packages: kaggle, pycocotools, seqeval, py-cpuinfo, promise\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73032 sha256=da27424fed96d4e0cf564a61b19139818cb5fef13f9f0df743796551126f7a92\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/da/11/144cc25aebdaeb4931b231e25fd34b394e6a5725cbb2f50106\n",
      "  Building wheel for pycocotools (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.4-cp38-cp38-linux_x86_64.whl size=418782 sha256=eae63cc73da1e2d7da9e1675d6c6a3251574ed4811147d145ebac35478fc9dd3\n",
      "  Stored in directory: /root/.cache/pip/wheels/dd/e2/43/3e93cd653b3346b3d702bb0509bc611189f95d60407bff1484\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16166 sha256=74fb03597ae60cbe0d19eee33859c7e3d27ee196ae1c5342f3157d0a051d4ea6\n",
      "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
      "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22242 sha256=23adaa4fac5de0f25869948f2fdc985d1d149af6ee64747d8bda75a98cda017f\n",
      "  Stored in directory: /root/.cache/pip/wheels/57/cb/6d/bab2257f26c5be4a96ff65c3d2a7122c96529b73773ee37f36\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21485 sha256=aeed3d7b04f2ee9460838fd11197a24a652cc58b50584ace59e24df158a88a86\n",
      "  Stored in directory: /root/.cache/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "Successfully built kaggle pycocotools seqeval py-cpuinfo promise\n",
      "Installing collected packages: tqdm, text-unidecode, python-slugify, kaggle, tensorflow-hub, kiwisolver, cycler, fonttools, Pillow, matplotlib, pycocotools, tensorflow-text, pyyaml, scipy, threadpoolctl, joblib, scikit-learn, seqeval, pandas, tf-slim, dill, toml, etils, googleapis-common-protos, tensorflow-metadata, promise, tensorflow-datasets, py-cpuinfo, Cython, dm-tree, tensorflow-model-optimization, portalocker, tabulate, regex, colorama, sacrebleu, sentencepiece, gin-config, httplib2, oauth2client, opencv-python-headless, google-auth-httplib2, uritemplate, google-api-core, google-api-python-client, typeguard, tensorflow-addons, tf-models-official\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed Cython-0.29.30 Pillow-9.1.1 colorama-0.4.4 cycler-0.11.0 dill-0.3.5.1 dm-tree-0.1.7 etils-0.6.0 fonttools-4.33.3 gin-config-0.5.0 google-api-core-2.8.1 google-api-python-client-2.49.0 google-auth-httplib2-0.1.0 googleapis-common-protos-1.56.2 httplib2-0.20.4 joblib-1.1.0 kaggle-1.5.12 kiwisolver-1.4.2 matplotlib-3.5.2 oauth2client-4.1.3 opencv-python-headless-4.5.5.64 pandas-1.4.2 portalocker-2.4.0 promise-2.3 py-cpuinfo-8.0.0 pycocotools-2.0.4 python-slugify-6.1.2 pyyaml-5.4.1 regex-2022.6.2 sacrebleu-2.1.0 scikit-learn-1.1.1 scipy-1.8.1 sentencepiece-0.1.96 seqeval-1.2.2 tabulate-0.8.9 tensorflow-addons-0.17.0 tensorflow-datasets-4.6.0 tensorflow-hub-0.12.0 tensorflow-metadata-1.8.0 tensorflow-model-optimization-0.7.2 tensorflow-text-2.9.0 text-unidecode-1.3 tf-models-official-2.9.2 tf-slim-1.1.0 threadpoolctl-3.1.0 toml-0.10.2 tqdm-4.64.0 typeguard-2.13.3 uritemplate-4.1.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tensorflow_io\n",
      "  Downloading tensorflow_io-0.26.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem==0.26.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_io) (0.26.0)\n",
      "Installing collected packages: tensorflow-io\n",
      "Successfully installed tensorflow-io-0.26.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (2.9.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorflow==2.8.0\n",
    "#!pip install tf-models-official==2.8.0\n",
    "#!pip install tensorflow_io==0.23.1\n",
    "#!pip install keras==2.8.0\n",
    "!pip install tf-models-official\n",
    "!pip install tensorflow_io\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 642,
     "status": "ok",
     "timestamp": 1654182359025,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "7VDFzo4bfZx8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /root/train1/models/research\n",
      "Collecting avro-python3\n",
      "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
      "Collecting apache-beam\n",
      "  Downloading apache_beam-2.39.0-cp38-cp38-manylinux2010_x86_64.whl (12.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.3 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (9.1.1)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.9 MB 59.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (3.5.2)\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.29.30)\n",
      "Collecting contextlib2\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: tf-slim in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from object-detection==0.1) (1.14.0)\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.0.4)\n",
      "Collecting lvis\n",
      "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.8.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: tf-models-official>=2.5.1 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.9.2)\n",
      "Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.26.0)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.9.0)\n",
      "Collecting pyparsing==2.4.7\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 17.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyarrow<8.0.0,>=0.15.1\n",
      "  Downloading pyarrow-7.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.7 MB 33.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
      "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (4.2.0)\n",
      "Collecting cloudpickle<3,>=2.0.0\n",
      "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.14.3 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.22.4)\n",
      "Collecting crcmod<2.0,>=1.7\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "\u001b[K     |████████████████████████████████| 89 kB 23.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fastavro<2,>=0.23.6\n",
      "  Downloading fastavro-1.4.12-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 46.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2022.1)\n",
      "Collecting pymongo<4.0.0,>=3.8.0\n",
      "  Downloading pymongo-3.12.3-cp38-cp38-manylinux2014_x86_64.whl (546 kB)\n",
      "\u001b[K     |████████████████████████████████| 546 kB 50.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting proto-plus<2,>=1.7.1\n",
      "  Downloading proto_plus-1.20.5-py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 10.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.19.4)\n",
      "Collecting requests<3.0.0,>=2.24.0\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 5.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting httplib2<0.20.0,>=0.8\n",
      "  Downloading httplib2-0.19.1-py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 11.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.46.3)\n",
      "Collecting orjson<4.0\n",
      "  Downloading orjson-3.7.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (256 kB)\n",
      "\u001b[K     |████████████████████████████████| 256 kB 53.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 62.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydot<2,>=1.2.0\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->object-detection==0.1) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->object-detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->object-detection==0.1) (4.33.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->object-detection==0.1) (0.11.0)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from tf-slim->object-detection==0.1) (1.0.0)\n",
      "Collecting opencv-python>=4.1.0.25\n",
      "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 60.5 MB 52.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.17.0)\n",
      "Requirement already satisfied: seqeval in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.1)\n",
      "Requirement already satisfied: gin-config in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
      "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0)\n",
      "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.5.5.64)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.96)\n",
      "Requirement already satisfied: tensorflow~=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.9.1)\n",
      "Requirement already satisfied: tensorflow-text~=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.9.0)\n",
      "Requirement already satisfied: pyyaml<6.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.1)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.49.0)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (8.0.0)\n",
      "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.1.0)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.7.2)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.26.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_io->object-detection==0.1) (0.26.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docopt\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.8)\n",
      "Collecting charset-normalizer~=2.0.0; python_version >= \"3\"\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.25.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.13.3)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.1)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.7.1)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
      "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.6.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.6.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.9.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (62.3.2)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.9.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.6.6)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.8.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.2)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2.4.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.8/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.4.4)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.56.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.34.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.1.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
      "Building wheels for collected packages: object-detection, avro-python3, crcmod, dill, docopt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for object-detection (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1693568 sha256=298770672daff4291d9e30abc15ed55eb39c0967e952a30cb5b2ed97128389d0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-m9juhbqr/wheels/63/a7/0e/470621870b3a152ee838e90ee41621c4a103254383f3be3d97\n",
      "  Building wheel for avro-python3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43992 sha256=d7aec39c848ded726166e1936634a55eeae27cd429f0a7c7954314139f95795a\n",
      "  Stored in directory: /root/.cache/pip/wheels/bb/73/e9/d273421f5723c4bf544dcf9eb097bda94421ef8d3252699f0a\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for crcmod: filename=crcmod-1.7-cp38-cp38-linux_x86_64.whl size=36003 sha256=a217ab998d5e1e0d3b628868697c4042ce5cbf83772e890a57c1feb1974e0184\n",
      "  Stored in directory: /root/.cache/pip/wheels/ca/5a/02/f3acf982a026f3319fb3e798a8dca2d48fafee7761788562e9\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78543 sha256=0ed930910737ac542d2e50d794678e2ac0c18fd9810a45e852d3315c7ac2b68a\n",
      "  Stored in directory: /root/.cache/pip/wheels/07/35/78/e9004fa30578734db7f10e7a211605f3f0778d2bdde38a239d\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=36cdc8b88d24883e22f8fce7287494223f26d59bd25d756a0922ead7151a96ff\n",
      "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
      "Successfully built object-detection avro-python3 crcmod dill docopt\n",
      "Installing collected packages: avro-python3, pyarrow, docopt, charset-normalizer, requests, hdfs, cloudpickle, crcmod, fastavro, pymongo, proto-plus, pyparsing, httplib2, orjson, dill, pydot, apache-beam, lxml, contextlib2, opencv-python, lvis, object-detection\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.22.0\n",
      "    Uninstalling requests-2.22.0:\n",
      "      Successfully uninstalled requests-2.22.0\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.9\n",
      "    Uninstalling pyparsing-3.0.9:\n",
      "      Successfully uninstalled pyparsing-3.0.9\n",
      "  Attempting uninstall: httplib2\n",
      "    Found existing installation: httplib2 0.20.4\n",
      "    Uninstalling httplib2-0.20.4:\n",
      "      Successfully uninstalled httplib2-0.20.4\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.5.1\n",
      "    Uninstalling dill-0.3.5.1:\n",
      "      Successfully uninstalled dill-0.3.5.1\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "jupyterlab 3.4.2 requires tornado>=6.1.0, but you'll have tornado 5.1.1 which is incompatible.\n",
      "jupyter-server 1.17.0 requires tornado>=6.1.0, but you'll have tornado 5.1.1 which is incompatible.\n",
      "ipykernel 6.13.0 requires tornado>=6.1, but you'll have tornado 5.1.1 which is incompatible.\u001b[0m\n",
      "Successfully installed apache-beam-2.39.0 avro-python3-1.10.2 charset-normalizer-2.0.12 cloudpickle-2.1.0 contextlib2-21.6.0 crcmod-1.7 dill-0.3.1.1 docopt-0.6.2 fastavro-1.4.12 hdfs-2.7.0 httplib2-0.19.1 lvis-0.5.3 lxml-4.9.0 object-detection-0.1 opencv-python-4.5.5.64 orjson-3.7.1 proto-plus-1.20.5 pyarrow-7.0.0 pydot-1.4.2 pymongo-3.12.3 pyparsing-2.4.7 requests-2.27.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# (For cont')\n",
    "\n",
    "!cp object_detection/packages/tf2/setup.py .\n",
    "!python -m pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7S6YquyWg_HW"
   },
   "source": [
    "### Test the TF Object Detection installation API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30628,
     "status": "ok",
     "timestamp": 1654182396978,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "cDB1YYuqhJcp",
    "outputId": "cfe9f44c-8a7a-4ca4-e3c6-fb611b108f3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tests under Python 3.8.10: /usr/local/bin/python\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "2022-06-04 12:15:55.571735: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-04 12:15:56.725578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22340 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-06-04 12:15:56.727285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22340 MB memory:  -> device: 1, name: NVIDIA RTX A5000, pci bus id: 0000:82:00.0, compute capability: 8.6\n",
      "/usr/local/lib/python3.8/dist-packages/object_detection/builders/model_builder.py:1102: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
      "W0604 12:15:57.273956 140019516405568 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.93s\n",
      "I0604 12:15:57.492414 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.93s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.48s\n",
      "I0604 12:15:57.972113 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.48s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.35s\n",
      "I0604 12:15:58.317851 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.35s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.2s\n",
      "I0604 12:15:58.522015 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.2s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.45s\n",
      "I0604 12:15:59.967412 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.45s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I0604 12:15:59.968438 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "I0604 12:15:59.988090 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "I0604 12:16:00.000308 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "I0604 12:16:00.012933 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.08s\n",
      "I0604 12:16:00.092483 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
      "I0604 12:16:00.168124 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.08s\n",
      "I0604 12:16:00.247474 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.08s\n",
      "I0604 12:16:00.325862 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.08s\n",
      "I0604 12:16:00.402322 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "I0604 12:16:00.424865 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I0604 12:16:00.701574 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I0604 12:16:00.701725 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
      "I0604 12:16:00.701776 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 3\n",
      "I0604 12:16:00.703637 140019516405568 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 12:16:00.716587 140019516405568 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 12:16:00.716663 140019516405568 efficientnet_model.py:143] round_filter input=16 output=16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0604 12:16:00.762233 140019516405568 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0604 12:16:00.762325 140019516405568 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 12:16:00.875456 140019516405568 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 12:16:00.875553 140019516405568 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0604 12:16:00.989835 140019516405568 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0604 12:16:00.989939 140019516405568 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0604 12:16:01.162424 140019516405568 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0604 12:16:01.162549 140019516405568 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0604 12:16:01.335368 140019516405568 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0604 12:16:01.335484 140019516405568 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0604 12:16:01.573688 140019516405568 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0604 12:16:01.573861 140019516405568 efficientnet_model.py:143] round_filter input=320 output=320\n",
      "I0604 12:16:01.627964 140019516405568 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
      "I0604 12:16:01.652861 140019516405568 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 12:16:01.699382 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I0604 12:16:01.699489 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
      "I0604 12:16:01.699537 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 4\n",
      "I0604 12:16:01.701040 140019516405568 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 12:16:01.713015 140019516405568 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 12:16:01.713084 140019516405568 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0604 12:16:01.803715 140019516405568 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0604 12:16:01.803803 140019516405568 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 12:16:01.975205 140019516405568 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 12:16:01.975326 140019516405568 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0604 12:16:02.146262 140019516405568 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0604 12:16:02.146374 140019516405568 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0604 12:16:02.374913 140019516405568 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0604 12:16:02.375050 140019516405568 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0604 12:16:02.606195 140019516405568 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0604 12:16:02.606341 140019516405568 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0604 12:16:02.895252 140019516405568 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0604 12:16:02.895394 140019516405568 efficientnet_model.py:143] round_filter input=320 output=320\n",
      "I0604 12:16:03.008480 140019516405568 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
      "I0604 12:16:03.029739 140019516405568 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 12:16:03.084149 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0604 12:16:03.084279 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
      "I0604 12:16:03.084354 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 5\n",
      "I0604 12:16:03.085741 140019516405568 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 12:16:03.097837 140019516405568 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 12:16:03.097906 140019516405568 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0604 12:16:03.189528 140019516405568 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0604 12:16:03.189637 140019516405568 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 12:16:03.362607 140019516405568 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 12:16:03.362747 140019516405568 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0604 12:16:03.536120 140019516405568 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0604 12:16:03.536242 140019516405568 efficientnet_model.py:143] round_filter input=80 output=88\n",
      "I0604 12:16:03.766072 140019516405568 efficientnet_model.py:143] round_filter input=80 output=88\n",
      "I0604 12:16:03.766196 140019516405568 efficientnet_model.py:143] round_filter input=112 output=120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0604 12:16:04.139407 140019516405568 efficientnet_model.py:143] round_filter input=112 output=120\n",
      "I0604 12:16:04.139548 140019516405568 efficientnet_model.py:143] round_filter input=192 output=208\n",
      "I0604 12:16:04.439208 140019516405568 efficientnet_model.py:143] round_filter input=192 output=208\n",
      "I0604 12:16:04.439340 140019516405568 efficientnet_model.py:143] round_filter input=320 output=352\n",
      "I0604 12:16:04.555382 140019516405568 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
      "I0604 12:16:04.578605 140019516405568 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 12:16:04.632550 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0604 12:16:04.632664 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
      "I0604 12:16:04.632739 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 6\n",
      "I0604 12:16:04.634289 140019516405568 efficientnet_model.py:143] round_filter input=32 output=40\n",
      "I0604 12:16:04.649108 140019516405568 efficientnet_model.py:143] round_filter input=32 output=40\n",
      "I0604 12:16:04.649248 140019516405568 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 12:16:04.741867 140019516405568 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 12:16:04.741992 140019516405568 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0604 12:16:04.913329 140019516405568 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0604 12:16:04.913451 140019516405568 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0604 12:16:05.084046 140019516405568 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0604 12:16:05.084174 140019516405568 efficientnet_model.py:143] round_filter input=80 output=96\n",
      "I0604 12:16:05.371321 140019516405568 efficientnet_model.py:143] round_filter input=80 output=96\n",
      "I0604 12:16:05.371455 140019516405568 efficientnet_model.py:143] round_filter input=112 output=136\n",
      "I0604 12:16:05.663168 140019516405568 efficientnet_model.py:143] round_filter input=112 output=136\n",
      "I0604 12:16:05.663302 140019516405568 efficientnet_model.py:143] round_filter input=192 output=232\n",
      "I0604 12:16:06.008544 140019516405568 efficientnet_model.py:143] round_filter input=192 output=232\n",
      "I0604 12:16:06.008680 140019516405568 efficientnet_model.py:143] round_filter input=320 output=384\n",
      "I0604 12:16:06.122856 140019516405568 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
      "I0604 12:16:06.144393 140019516405568 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 12:16:06.207113 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I0604 12:16:06.207247 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
      "I0604 12:16:06.207301 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 7\n",
      "I0604 12:16:06.208726 140019516405568 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0604 12:16:06.221300 140019516405568 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0604 12:16:06.221388 140019516405568 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 12:16:06.313993 140019516405568 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 12:16:06.314121 140019516405568 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0604 12:16:06.544176 140019516405568 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0604 12:16:06.544313 140019516405568 efficientnet_model.py:143] round_filter input=40 output=56\n",
      "I0604 12:16:06.776473 140019516405568 efficientnet_model.py:143] round_filter input=40 output=56\n",
      "I0604 12:16:06.776615 140019516405568 efficientnet_model.py:143] round_filter input=80 output=112\n",
      "I0604 12:16:07.124933 140019516405568 efficientnet_model.py:143] round_filter input=80 output=112\n",
      "I0604 12:16:07.125083 140019516405568 efficientnet_model.py:143] round_filter input=112 output=160\n",
      "I0604 12:16:07.475575 140019516405568 efficientnet_model.py:143] round_filter input=112 output=160\n",
      "I0604 12:16:07.475762 140019516405568 efficientnet_model.py:143] round_filter input=192 output=272\n",
      "I0604 12:16:07.947630 140019516405568 efficientnet_model.py:143] round_filter input=192 output=272\n",
      "I0604 12:16:07.947815 140019516405568 efficientnet_model.py:143] round_filter input=320 output=448\n",
      "I0604 12:16:08.062626 140019516405568 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
      "I0604 12:16:08.084455 140019516405568 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0604 12:16:08.431102 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I0604 12:16:08.431291 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
      "I0604 12:16:08.431373 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 7\n",
      "I0604 12:16:08.432895 140019516405568 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0604 12:16:08.445641 140019516405568 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0604 12:16:08.445722 140019516405568 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 12:16:08.586113 140019516405568 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 12:16:08.586246 140019516405568 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0604 12:16:08.876193 140019516405568 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0604 12:16:08.876351 140019516405568 efficientnet_model.py:143] round_filter input=40 output=64\n",
      "I0604 12:16:09.165420 140019516405568 efficientnet_model.py:143] round_filter input=40 output=64\n",
      "I0604 12:16:09.165580 140019516405568 efficientnet_model.py:143] round_filter input=80 output=128\n",
      "I0604 12:16:09.569298 140019516405568 efficientnet_model.py:143] round_filter input=80 output=128\n",
      "I0604 12:16:09.569458 140019516405568 efficientnet_model.py:143] round_filter input=112 output=176\n",
      "I0604 12:16:09.973331 140019516405568 efficientnet_model.py:143] round_filter input=112 output=176\n",
      "I0604 12:16:09.973490 140019516405568 efficientnet_model.py:143] round_filter input=192 output=304\n",
      "I0604 12:16:10.494059 140019516405568 efficientnet_model.py:143] round_filter input=192 output=304\n",
      "I0604 12:16:10.494220 140019516405568 efficientnet_model.py:143] round_filter input=320 output=512\n",
      "I0604 12:16:10.665517 140019516405568 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
      "I0604 12:16:10.688427 140019516405568 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 12:16:10.771111 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I0604 12:16:10.771263 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
      "I0604 12:16:10.771311 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 8\n",
      "I0604 12:16:10.772749 140019516405568 efficientnet_model.py:143] round_filter input=32 output=56\n",
      "I0604 12:16:10.786006 140019516405568 efficientnet_model.py:143] round_filter input=32 output=56\n",
      "I0604 12:16:10.786079 140019516405568 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0604 12:16:10.923635 140019516405568 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0604 12:16:10.923776 140019516405568 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0604 12:16:11.270153 140019516405568 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0604 12:16:11.270312 140019516405568 efficientnet_model.py:143] round_filter input=40 output=72\n",
      "I0604 12:16:11.615469 140019516405568 efficientnet_model.py:143] round_filter input=40 output=72\n",
      "I0604 12:16:11.615614 140019516405568 efficientnet_model.py:143] round_filter input=80 output=144\n",
      "I0604 12:16:12.079166 140019516405568 efficientnet_model.py:143] round_filter input=80 output=144\n",
      "I0604 12:16:12.079321 140019516405568 efficientnet_model.py:143] round_filter input=112 output=200\n",
      "I0604 12:16:12.542259 140019516405568 efficientnet_model.py:143] round_filter input=112 output=200\n",
      "I0604 12:16:12.542405 140019516405568 efficientnet_model.py:143] round_filter input=192 output=344\n",
      "I0604 12:16:13.396212 140019516405568 efficientnet_model.py:143] round_filter input=192 output=344\n",
      "I0604 12:16:13.396355 140019516405568 efficientnet_model.py:143] round_filter input=320 output=576\n",
      "I0604 12:16:13.575879 140019516405568 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
      "I0604 12:16:13.598521 140019516405568 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 12:16:13.694716 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I0604 12:16:13.694846 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
      "I0604 12:16:13.694938 140019516405568 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 8\n",
      "I0604 12:16:13.696341 140019516405568 efficientnet_model.py:143] round_filter input=32 output=64\n",
      "I0604 12:16:13.708751 140019516405568 efficientnet_model.py:143] round_filter input=32 output=64\n",
      "I0604 12:16:13.708830 140019516405568 efficientnet_model.py:143] round_filter input=16 output=32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0604 12:16:13.899262 140019516405568 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0604 12:16:13.899398 140019516405568 efficientnet_model.py:143] round_filter input=24 output=48\n",
      "I0604 12:16:14.313197 140019516405568 efficientnet_model.py:143] round_filter input=24 output=48\n",
      "I0604 12:16:14.313328 140019516405568 efficientnet_model.py:143] round_filter input=40 output=80\n",
      "I0604 12:16:14.730289 140019516405568 efficientnet_model.py:143] round_filter input=40 output=80\n",
      "I0604 12:16:14.730424 140019516405568 efficientnet_model.py:143] round_filter input=80 output=160\n",
      "I0604 12:16:15.314172 140019516405568 efficientnet_model.py:143] round_filter input=80 output=160\n",
      "I0604 12:16:15.314306 140019516405568 efficientnet_model.py:143] round_filter input=112 output=224\n",
      "I0604 12:16:15.894876 140019516405568 efficientnet_model.py:143] round_filter input=112 output=224\n",
      "I0604 12:16:15.895009 140019516405568 efficientnet_model.py:143] round_filter input=192 output=384\n",
      "I0604 12:16:16.653286 140019516405568 efficientnet_model.py:143] round_filter input=192 output=384\n",
      "I0604 12:16:16.653409 140019516405568 efficientnet_model.py:143] round_filter input=320 output=640\n",
      "I0604 12:16:16.885907 140019516405568 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
      "I0604 12:16:16.908070 140019516405568 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 16.59s\n",
      "I0604 12:16:17.020110 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 16.59s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I0604 12:16:17.028485 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I0604 12:16:17.029984 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I0604 12:16:17.030311 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I0604 12:16:17.031620 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "I0604 12:16:17.032799 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I0604 12:16:17.033087 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I0604 12:16:17.033943 140019516405568 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 21.468s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "# (For cont')\n",
    "\n",
    "!python object_detection/builders/model_builder_tf2_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TntgsRpEhkGL"
   },
   "source": [
    "## Download pre-trained model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KljfW26pixrB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/train1/data\n"
     ]
    }
   ],
   "source": [
    "%cd {DATA_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt install wget -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T4wCOUPwikAs",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
    "!tar -xzvf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the pipeline.config (IMPORTANT!)\n",
    "change the checkpoint, label map, train, and test in data/pipeline.config to below path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: /root/train1/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\n",
      "Label map: /root/train1/data/label_map.pbtxt\n",
      "Train: /root/train1/data/train.record\n",
      "Test: /root/train1/data/test.record\n"
     ]
    }
   ],
   "source": [
    "print(\"Checkpoint: \" + os.path.join(DATA_PATH, \"ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\", \"checkpoint\", \"ckpt-0\"))\n",
    "print(\"Label map: \" + LABEL_MAP_PATH)\n",
    "print(\"Train: \" + TRAIN_DATA_PATH)\n",
    "print(\"Test: \" + TEST_DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also change add \"max_to_keep=None\" as parameter in tf.train.Saver() in /research/object_detection/legacy/trainer.py \\\n",
    "So it'll be:\\\n",
    "\\\n",
    "saver = tf.train.Saver(max_to_keep=None, \\\n",
    "keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vr1BMAKl2kG"
   },
   "source": [
    "## Load Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1654187407390,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "zNqRvjtKl2Xn",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (For cont')\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /root/train1/training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYYViyUNmFDy"
   },
   "source": [
    "# Train The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTgNmhT5alLz"
   },
   "source": [
    "## Fixing incompatible libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19274,
     "status": "ok",
     "timestamp": 1654182416826,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "JbRpZNpOn_NY",
    "outputId": "6cd829fa-4f44-41dc-ee92-a33ad74da7d2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: opencv-python 4.5.5.64\n",
      "Uninstalling opencv-python-4.5.5.64:\n",
      "  Successfully uninstalled opencv-python-4.5.5.64\n",
      "\u001b[33mWARNING: Skipping opencv-contrib-python as it is not installed.\u001b[0m\n",
      "Found existing installation: opencv-python-headless 4.5.5.64\n",
      "Uninstalling opencv-python-headless-4.5.5.64:\n",
      "  Successfully uninstalled opencv-python-headless-4.5.5.64\n",
      "Collecting opencv-python==4.5.5.64\n",
      "  Using cached opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5; python_version >= \"3.7\" in /usr/local/lib/python3.8/dist-packages (from opencv-python==4.5.5.64) (1.22.4)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.5.64\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting opencv-contrib-python==4.5.5.64\n",
      "  Downloading opencv_contrib_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (66.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 66.7 MB 153 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3; python_version >= \"3.8\" in /usr/local/lib/python3.8/dist-packages (from opencv-contrib-python==4.5.5.64) (1.22.4)\n",
      "Installing collected packages: opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-4.5.5.64\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting opencv-python-headless==4.5.5.64\n",
      "  Using cached opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3; python_version >= \"3.8\" in /usr/local/lib/python3.8/dist-packages (from opencv-python-headless==4.5.5.64) (1.22.4)\n",
      "Installing collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.5.5.64\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# (For cont')\n",
    "#==4.5.4.60\n",
    "!pip uninstall opencv-python --y\n",
    "!pip uninstall opencv-contrib-python --y\n",
    "!pip uninstall opencv-python-headless --y\n",
    "!pip install opencv-python==4.5.5.64 \n",
    "!pip install opencv-contrib-python==4.5.5.64 \n",
    "!pip install opencv-python-headless==4.5.5.64 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1614535,
     "status": "ok",
     "timestamp": 1654189769240,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "Qv3gj-XQmaJN",
    "outputId": "8766c2e3-5058-4c4c-8be9-a5dcd8d1488c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/train1/models/research/object_detection\n",
      "2022-06-04 13:46:36.873828: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-04 13:46:37.702119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22340 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-06-04 13:46:37.703288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22340 MB memory:  -> device: 1, name: NVIDIA RTX A5000, pci bus id: 0000:82:00.0, compute capability: 8.6\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "I0604 13:46:38.355494 139845714130752 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "INFO:tensorflow:Maybe overwriting train_steps: None\n",
      "I0604 13:46:38.359873 139845714130752 config_util.py:552] Maybe overwriting train_steps: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0604 13:46:38.359943 139845714130752 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0604 13:46:38.383476 139845714130752 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['/root/train1/data/train.record']\n",
      "I0604 13:46:38.388278 139845714130752 dataset_builder.py:162] Reading unweighted datasets: ['/root/train1/data/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['/root/train1/data/train.record']\n",
      "I0604 13:46:38.388381 139845714130752 dataset_builder.py:79] Reading record datasets for input file: ['/root/train1/data/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0604 13:46:38.388435 139845714130752 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0604 13:46:38.388480 139845714130752 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0604 13:46:38.390277 139845714130752 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0604 13:46:38.408495 139845714130752 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0604 13:46:45.403353 139845714130752 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0604 13:46:48.512858 139845714130752 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0604 13:46:49.959858 139845714130752 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0604 13:46:52.838091 139777470875392 deprecation.py:554] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "/usr/local/lib/python3.8/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "INFO:tensorflow:batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\n",
      "I0604 13:47:18.030015 139845714130752 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 13:47:20.435827 139845714130752 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 13:47:20.437555 139845714130752 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 13:47:20.438800 139845714130752 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 13:47:20.440032 139845714130752 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\n",
      "I0604 13:47:38.168219 139845714130752 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 13:47:40.404885 139845714130752 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 13:47:40.408127 139845714130752 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 13:47:40.410799 139845714130752 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 13:47:40.412044 139845714130752 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\n",
      "I0604 13:47:58.144204 139845714130752 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 13:48:01.172582 139845714130752 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0604 13:48:01.174952 139845714130752 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\n",
      "I0604 13:48:18.737613 139845714130752 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\n",
      "2022-06-04 13:48:35.267787: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: while/body/_1/replica_1/train_input_images/write_summary/summary_cond/branch_executed/_5325\n",
      "2022-06-04 13:48:49.037575: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-06-04 13:48:50.054199: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-06-04 13:48:50.967514: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "INFO:tensorflow:Step 35100 per-step time 1.585s\n",
      "I0604 13:49:30.933800 139845714130752 model_lib_v2.py:705] Step 35100 per-step time 1.585s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.099196866,\n",
      " 'Loss/localization_loss': 0.073883474,\n",
      " 'Loss/regularization_loss': 0.08507425,\n",
      " 'Loss/total_loss': 0.2581546,\n",
      " 'learning_rate': 0.01690546}\n",
      "I0604 13:49:30.934031 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.099196866,\n",
      " 'Loss/localization_loss': 0.073883474,\n",
      " 'Loss/regularization_loss': 0.08507425,\n",
      " 'Loss/total_loss': 0.2581546,\n",
      " 'learning_rate': 0.01690546}\n",
      "INFO:tensorflow:Step 35200 per-step time 0.375s\n",
      "I0604 13:50:08.402032 139845714130752 model_lib_v2.py:705] Step 35200 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09986697,\n",
      " 'Loss/localization_loss': 0.06878224,\n",
      " 'Loss/regularization_loss': 0.084984526,\n",
      " 'Loss/total_loss': 0.25363374,\n",
      " 'learning_rate': 0.016696546}\n",
      "I0604 13:50:08.402251 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.09986697,\n",
      " 'Loss/localization_loss': 0.06878224,\n",
      " 'Loss/regularization_loss': 0.084984526,\n",
      " 'Loss/total_loss': 0.25363374,\n",
      " 'learning_rate': 0.016696546}\n",
      "INFO:tensorflow:Step 35300 per-step time 0.373s\n",
      "I0604 13:50:45.738347 139845714130752 model_lib_v2.py:705] Step 35300 per-step time 0.373s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08428559,\n",
      " 'Loss/localization_loss': 0.0633734,\n",
      " 'Loss/regularization_loss': 0.08489934,\n",
      " 'Loss/total_loss': 0.23255832,\n",
      " 'learning_rate': 0.016488582}\n",
      "I0604 13:50:45.738628 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.08428559,\n",
      " 'Loss/localization_loss': 0.0633734,\n",
      " 'Loss/regularization_loss': 0.08489934,\n",
      " 'Loss/total_loss': 0.23255832,\n",
      " 'learning_rate': 0.016488582}\n",
      "INFO:tensorflow:Step 35400 per-step time 0.372s\n",
      "I0604 13:51:22.897936 139845714130752 model_lib_v2.py:705] Step 35400 per-step time 0.372s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08998175,\n",
      " 'Loss/localization_loss': 0.053246718,\n",
      " 'Loss/regularization_loss': 0.08481042,\n",
      " 'Loss/total_loss': 0.22803889,\n",
      " 'learning_rate': 0.016281592}\n",
      "I0604 13:51:22.898156 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.08998175,\n",
      " 'Loss/localization_loss': 0.053246718,\n",
      " 'Loss/regularization_loss': 0.08481042,\n",
      " 'Loss/total_loss': 0.22803889,\n",
      " 'learning_rate': 0.016281592}\n",
      "INFO:tensorflow:Step 35500 per-step time 0.375s\n",
      "I0604 13:52:00.348120 139845714130752 model_lib_v2.py:705] Step 35500 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.086089775,\n",
      " 'Loss/localization_loss': 0.05662597,\n",
      " 'Loss/regularization_loss': 0.08472237,\n",
      " 'Loss/total_loss': 0.22743812,\n",
      " 'learning_rate': 0.01607557}\n",
      "I0604 13:52:00.348347 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.086089775,\n",
      " 'Loss/localization_loss': 0.05662597,\n",
      " 'Loss/regularization_loss': 0.08472237,\n",
      " 'Loss/total_loss': 0.22743812,\n",
      " 'learning_rate': 0.01607557}\n",
      "INFO:tensorflow:Step 35600 per-step time 0.373s\n",
      "I0604 13:52:37.628314 139845714130752 model_lib_v2.py:705] Step 35600 per-step time 0.373s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10358511,\n",
      " 'Loss/localization_loss': 0.072112486,\n",
      " 'Loss/regularization_loss': 0.08464108,\n",
      " 'Loss/total_loss': 0.26033866,\n",
      " 'learning_rate': 0.01587054}\n",
      "I0604 13:52:37.628572 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.10358511,\n",
      " 'Loss/localization_loss': 0.072112486,\n",
      " 'Loss/regularization_loss': 0.08464108,\n",
      " 'Loss/total_loss': 0.26033866,\n",
      " 'learning_rate': 0.01587054}\n",
      "INFO:tensorflow:Step 35700 per-step time 0.376s\n",
      "I0604 13:53:15.254410 139845714130752 model_lib_v2.py:705] Step 35700 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08622354,\n",
      " 'Loss/localization_loss': 0.05690019,\n",
      " 'Loss/regularization_loss': 0.08455365,\n",
      " 'Loss/total_loss': 0.22767739,\n",
      " 'learning_rate': 0.015666498}\n",
      "I0604 13:53:15.254681 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.08622354,\n",
      " 'Loss/localization_loss': 0.05690019,\n",
      " 'Loss/regularization_loss': 0.08455365,\n",
      " 'Loss/total_loss': 0.22767739,\n",
      " 'learning_rate': 0.015666498}\n",
      "INFO:tensorflow:Step 35800 per-step time 0.376s\n",
      "I0604 13:53:52.895099 139845714130752 model_lib_v2.py:705] Step 35800 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11205125,\n",
      " 'Loss/localization_loss': 0.09019689,\n",
      " 'Loss/regularization_loss': 0.0844711,\n",
      " 'Loss/total_loss': 0.28671926,\n",
      " 'learning_rate': 0.015463452}\n",
      "I0604 13:53:52.895463 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.11205125,\n",
      " 'Loss/localization_loss': 0.09019689,\n",
      " 'Loss/regularization_loss': 0.0844711,\n",
      " 'Loss/total_loss': 0.28671926,\n",
      " 'learning_rate': 0.015463452}\n",
      "INFO:tensorflow:Step 35900 per-step time 0.376s\n",
      "I0604 13:54:30.475187 139845714130752 model_lib_v2.py:705] Step 35900 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0827273,\n",
      " 'Loss/localization_loss': 0.069916554,\n",
      " 'Loss/regularization_loss': 0.08438844,\n",
      " 'Loss/total_loss': 0.2370323,\n",
      " 'learning_rate': 0.015261421}\n",
      "I0604 13:54:30.475435 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.0827273,\n",
      " 'Loss/localization_loss': 0.069916554,\n",
      " 'Loss/regularization_loss': 0.08438844,\n",
      " 'Loss/total_loss': 0.2370323,\n",
      " 'learning_rate': 0.015261421}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 36000 per-step time 0.377s\n",
      "I0604 13:55:08.196836 139845714130752 model_lib_v2.py:705] Step 36000 per-step time 0.377s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08683649,\n",
      " 'Loss/localization_loss': 0.050683074,\n",
      " 'Loss/regularization_loss': 0.084303446,\n",
      " 'Loss/total_loss': 0.221823,\n",
      " 'learning_rate': 0.015060408}\n",
      "I0604 13:55:08.197113 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.08683649,\n",
      " 'Loss/localization_loss': 0.050683074,\n",
      " 'Loss/regularization_loss': 0.084303446,\n",
      " 'Loss/total_loss': 0.221823,\n",
      " 'learning_rate': 0.015060408}\n",
      "INFO:tensorflow:Step 36100 per-step time 0.378s\n",
      "I0604 13:55:46.024338 139845714130752 model_lib_v2.py:705] Step 36100 per-step time 0.378s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.088408165,\n",
      " 'Loss/localization_loss': 0.054447204,\n",
      " 'Loss/regularization_loss': 0.08422506,\n",
      " 'Loss/total_loss': 0.22708043,\n",
      " 'learning_rate': 0.014860413}\n",
      "I0604 13:55:46.024629 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.088408165,\n",
      " 'Loss/localization_loss': 0.054447204,\n",
      " 'Loss/regularization_loss': 0.08422506,\n",
      " 'Loss/total_loss': 0.22708043,\n",
      " 'learning_rate': 0.014860413}\n",
      "INFO:tensorflow:Step 36200 per-step time 0.375s\n",
      "I0604 13:56:23.517332 139845714130752 model_lib_v2.py:705] Step 36200 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07624216,\n",
      " 'Loss/localization_loss': 0.04169526,\n",
      " 'Loss/regularization_loss': 0.08414292,\n",
      " 'Loss/total_loss': 0.20208034,\n",
      " 'learning_rate': 0.014661457}\n",
      "I0604 13:56:23.517592 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.07624216,\n",
      " 'Loss/localization_loss': 0.04169526,\n",
      " 'Loss/regularization_loss': 0.08414292,\n",
      " 'Loss/total_loss': 0.20208034,\n",
      " 'learning_rate': 0.014661457}\n",
      "INFO:tensorflow:Step 36300 per-step time 0.375s\n",
      "I0604 13:57:00.985305 139845714130752 model_lib_v2.py:705] Step 36300 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07950924,\n",
      " 'Loss/localization_loss': 0.06723987,\n",
      " 'Loss/regularization_loss': 0.08406404,\n",
      " 'Loss/total_loss': 0.23081315,\n",
      " 'learning_rate': 0.014463534}\n",
      "I0604 13:57:00.985574 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.07950924,\n",
      " 'Loss/localization_loss': 0.06723987,\n",
      " 'Loss/regularization_loss': 0.08406404,\n",
      " 'Loss/total_loss': 0.23081315,\n",
      " 'learning_rate': 0.014463534}\n",
      "INFO:tensorflow:Step 36400 per-step time 0.374s\n",
      "I0604 13:57:38.389726 139845714130752 model_lib_v2.py:705] Step 36400 per-step time 0.374s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.078803204,\n",
      " 'Loss/localization_loss': 0.046613887,\n",
      " 'Loss/regularization_loss': 0.08398726,\n",
      " 'Loss/total_loss': 0.20940435,\n",
      " 'learning_rate': 0.014266672}\n",
      "I0604 13:57:38.389986 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.078803204,\n",
      " 'Loss/localization_loss': 0.046613887,\n",
      " 'Loss/regularization_loss': 0.08398726,\n",
      " 'Loss/total_loss': 0.20940435,\n",
      " 'learning_rate': 0.014266672}\n",
      "INFO:tensorflow:Step 36500 per-step time 0.377s\n",
      "I0604 13:58:16.126589 139845714130752 model_lib_v2.py:705] Step 36500 per-step time 0.377s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08634111,\n",
      " 'Loss/localization_loss': 0.061503418,\n",
      " 'Loss/regularization_loss': 0.08390913,\n",
      " 'Loss/total_loss': 0.23175366,\n",
      " 'learning_rate': 0.014070864}\n",
      "I0604 13:58:16.126871 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.08634111,\n",
      " 'Loss/localization_loss': 0.061503418,\n",
      " 'Loss/regularization_loss': 0.08390913,\n",
      " 'Loss/total_loss': 0.23175366,\n",
      " 'learning_rate': 0.014070864}\n",
      "INFO:tensorflow:Step 36600 per-step time 0.375s\n",
      "I0604 13:58:53.593353 139845714130752 model_lib_v2.py:705] Step 36600 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09354222,\n",
      " 'Loss/localization_loss': 0.06225849,\n",
      " 'Loss/regularization_loss': 0.08384289,\n",
      " 'Loss/total_loss': 0.23964359,\n",
      " 'learning_rate': 0.013876116}\n",
      "I0604 13:58:53.593608 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.09354222,\n",
      " 'Loss/localization_loss': 0.06225849,\n",
      " 'Loss/regularization_loss': 0.08384289,\n",
      " 'Loss/total_loss': 0.23964359,\n",
      " 'learning_rate': 0.013876116}\n",
      "INFO:tensorflow:Step 36700 per-step time 0.373s\n",
      "I0604 13:59:30.906304 139845714130752 model_lib_v2.py:705] Step 36700 per-step time 0.373s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.075980455,\n",
      " 'Loss/localization_loss': 0.04694947,\n",
      " 'Loss/regularization_loss': 0.08376573,\n",
      " 'Loss/total_loss': 0.20669565,\n",
      " 'learning_rate': 0.013682451}\n",
      "I0604 13:59:30.906552 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.075980455,\n",
      " 'Loss/localization_loss': 0.04694947,\n",
      " 'Loss/regularization_loss': 0.08376573,\n",
      " 'Loss/total_loss': 0.20669565,\n",
      " 'learning_rate': 0.013682451}\n",
      "INFO:tensorflow:Step 36800 per-step time 0.371s\n",
      "I0604 14:00:08.027385 139845714130752 model_lib_v2.py:705] Step 36800 per-step time 0.371s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08417933,\n",
      " 'Loss/localization_loss': 0.059234485,\n",
      " 'Loss/regularization_loss': 0.08369021,\n",
      " 'Loss/total_loss': 0.22710402,\n",
      " 'learning_rate': 0.013489859}\n",
      "I0604 14:00:08.027628 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.08417933,\n",
      " 'Loss/localization_loss': 0.059234485,\n",
      " 'Loss/regularization_loss': 0.08369021,\n",
      " 'Loss/total_loss': 0.22710402,\n",
      " 'learning_rate': 0.013489859}\n",
      "INFO:tensorflow:Step 36900 per-step time 0.373s\n",
      "I0604 14:00:45.372045 139845714130752 model_lib_v2.py:705] Step 36900 per-step time 0.373s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07815106,\n",
      " 'Loss/localization_loss': 0.049337503,\n",
      " 'Loss/regularization_loss': 0.083617926,\n",
      " 'Loss/total_loss': 0.21110648,\n",
      " 'learning_rate': 0.013298363}\n",
      "I0604 14:00:45.372361 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.07815106,\n",
      " 'Loss/localization_loss': 0.049337503,\n",
      " 'Loss/regularization_loss': 0.083617926,\n",
      " 'Loss/total_loss': 0.21110648,\n",
      " 'learning_rate': 0.013298363}\n",
      "INFO:tensorflow:Step 37000 per-step time 0.371s\n",
      "I0604 14:01:22.503489 139845714130752 model_lib_v2.py:705] Step 37000 per-step time 0.371s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0953514,\n",
      " 'Loss/localization_loss': 0.069294296,\n",
      " 'Loss/regularization_loss': 0.08354351,\n",
      " 'Loss/total_loss': 0.24818921,\n",
      " 'learning_rate': 0.013107965}\n",
      "I0604 14:01:22.503744 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.0953514,\n",
      " 'Loss/localization_loss': 0.069294296,\n",
      " 'Loss/regularization_loss': 0.08354351,\n",
      " 'Loss/total_loss': 0.24818921,\n",
      " 'learning_rate': 0.013107965}\n",
      "INFO:tensorflow:Step 37100 per-step time 0.375s\n",
      "I0604 14:01:59.957226 139845714130752 model_lib_v2.py:705] Step 37100 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.092423975,\n",
      " 'Loss/localization_loss': 0.06428283,\n",
      " 'Loss/regularization_loss': 0.083473355,\n",
      " 'Loss/total_loss': 0.24018016,\n",
      " 'learning_rate': 0.012918665}\n",
      "I0604 14:01:59.957542 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.092423975,\n",
      " 'Loss/localization_loss': 0.06428283,\n",
      " 'Loss/regularization_loss': 0.083473355,\n",
      " 'Loss/total_loss': 0.24018016,\n",
      " 'learning_rate': 0.012918665}\n",
      "INFO:tensorflow:Step 37200 per-step time 0.377s\n",
      "I0604 14:02:37.652700 139845714130752 model_lib_v2.py:705] Step 37200 per-step time 0.377s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.086706504,\n",
      " 'Loss/localization_loss': 0.06498009,\n",
      " 'Loss/regularization_loss': 0.0834004,\n",
      " 'Loss/total_loss': 0.23508699,\n",
      " 'learning_rate': 0.012730486}\n",
      "I0604 14:02:37.652983 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.086706504,\n",
      " 'Loss/localization_loss': 0.06498009,\n",
      " 'Loss/regularization_loss': 0.0834004,\n",
      " 'Loss/total_loss': 0.23508699,\n",
      " 'learning_rate': 0.012730486}\n",
      "INFO:tensorflow:Step 37300 per-step time 0.378s\n",
      "I0604 14:03:15.442804 139845714130752 model_lib_v2.py:705] Step 37300 per-step time 0.378s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09139445,\n",
      " 'Loss/localization_loss': 0.07155137,\n",
      " 'Loss/regularization_loss': 0.08332952,\n",
      " 'Loss/total_loss': 0.24627534,\n",
      " 'learning_rate': 0.012543423}\n",
      "I0604 14:03:15.443069 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.09139445,\n",
      " 'Loss/localization_loss': 0.07155137,\n",
      " 'Loss/regularization_loss': 0.08332952,\n",
      " 'Loss/total_loss': 0.24627534,\n",
      " 'learning_rate': 0.012543423}\n",
      "INFO:tensorflow:Step 37400 per-step time 0.374s\n",
      "I0604 14:03:52.872107 139845714130752 model_lib_v2.py:705] Step 37400 per-step time 0.374s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:{'Loss/classification_loss': 0.1006263,\n",
      " 'Loss/localization_loss': 0.076978244,\n",
      " 'Loss/regularization_loss': 0.08326079,\n",
      " 'Loss/total_loss': 0.26086533,\n",
      " 'learning_rate': 0.012357492}\n",
      "I0604 14:03:52.872341 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.1006263,\n",
      " 'Loss/localization_loss': 0.076978244,\n",
      " 'Loss/regularization_loss': 0.08326079,\n",
      " 'Loss/total_loss': 0.26086533,\n",
      " 'learning_rate': 0.012357492}\n",
      "INFO:tensorflow:Step 37500 per-step time 0.375s\n",
      "I0604 14:04:30.359035 139845714130752 model_lib_v2.py:705] Step 37500 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.079909235,\n",
      " 'Loss/localization_loss': 0.04955727,\n",
      " 'Loss/regularization_loss': 0.08319079,\n",
      " 'Loss/total_loss': 0.2126573,\n",
      " 'learning_rate': 0.012172694}\n",
      "I0604 14:04:30.359259 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.079909235,\n",
      " 'Loss/localization_loss': 0.04955727,\n",
      " 'Loss/regularization_loss': 0.08319079,\n",
      " 'Loss/total_loss': 0.2126573,\n",
      " 'learning_rate': 0.012172694}\n",
      "INFO:tensorflow:Step 37600 per-step time 0.374s\n",
      "I0604 14:05:07.754761 139845714130752 model_lib_v2.py:705] Step 37600 per-step time 0.374s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.099479236,\n",
      " 'Loss/localization_loss': 0.07255593,\n",
      " 'Loss/regularization_loss': 0.08312788,\n",
      " 'Loss/total_loss': 0.25516304,\n",
      " 'learning_rate': 0.011989042}\n",
      "I0604 14:05:07.754983 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.099479236,\n",
      " 'Loss/localization_loss': 0.07255593,\n",
      " 'Loss/regularization_loss': 0.08312788,\n",
      " 'Loss/total_loss': 0.25516304,\n",
      " 'learning_rate': 0.011989042}\n",
      "INFO:tensorflow:Step 37700 per-step time 0.374s\n",
      "I0604 14:05:45.189032 139845714130752 model_lib_v2.py:705] Step 37700 per-step time 0.374s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.072795145,\n",
      " 'Loss/localization_loss': 0.046159312,\n",
      " 'Loss/regularization_loss': 0.08306013,\n",
      " 'Loss/total_loss': 0.2020146,\n",
      " 'learning_rate': 0.011806537}\n",
      "I0604 14:05:45.189266 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.072795145,\n",
      " 'Loss/localization_loss': 0.046159312,\n",
      " 'Loss/regularization_loss': 0.08306013,\n",
      " 'Loss/total_loss': 0.2020146,\n",
      " 'learning_rate': 0.011806537}\n",
      "INFO:tensorflow:Step 37800 per-step time 0.376s\n",
      "I0604 14:06:22.783204 139845714130752 model_lib_v2.py:705] Step 37800 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09398847,\n",
      " 'Loss/localization_loss': 0.07289493,\n",
      " 'Loss/regularization_loss': 0.08299381,\n",
      " 'Loss/total_loss': 0.24987721,\n",
      " 'learning_rate': 0.011625201}\n",
      "I0604 14:06:22.783442 139845714130752 model_lib_v2.py:708] {'Loss/classification_loss': 0.09398847,\n",
      " 'Loss/localization_loss': 0.07289493,\n",
      " 'Loss/regularization_loss': 0.08299381,\n",
      " 'Loss/total_loss': 0.24987721,\n",
      " 'learning_rate': 0.011625201}\n"
     ]
    }
   ],
   "source": [
    "# (For cont')\n",
    "\n",
    "%cd {MAIN_PATH}/models/research/object_detection\n",
    "\n",
    "!python model_main_tf2.py \\\n",
    "--pipeline_config_path={CONFIG_PATH} \\\n",
    "--model_dir={TRAINING_PATH} \\\n",
    "--alsologtostderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cvPZMyPiZFFO"
   },
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0eK0oTxsNcCK",
    "outputId": "710b71d9-24e7-40d2-a205-31b2961c967e"
   },
   "outputs": [],
   "source": [
    "!python model_main_tf2.py \\\n",
    "--model_dir={TRAINING_PATH} \\\n",
    "--pipeline_config_path={CONFIG_PATH} \\\n",
    "--checkpoint_dir={TRAINING_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWIDrr3ZQjj6"
   },
   "source": [
    "## Inference/Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 951,
     "status": "ok",
     "timestamp": 1654190006848,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "Ezl_U9UpT2Kd",
    "outputId": "cc9248b5-a4d5-4e17-d2e8-ef85fad4ee42"
   },
   "outputs": [],
   "source": [
    "!python exporter_main_v2.py \\\n",
    "--trained_checkpoint_dir={TRAINING_PATH} \\\n",
    "--pipeline_config_path={CONFIG_PATH} \\\n",
    "--output_directory {DATA_PATH}/inference_graph"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNZfYiFeNihRAo+EdSsnJrM",
   "collapsed_sections": [],
   "name": "MyModel.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "71824dd40866df3d2aa82f78c70152c0d364eafa49dfb98f28d6e83617cc2488"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
