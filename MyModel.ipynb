{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwF2B1_gVgQM"
   },
   "source": [
    "# Note\n",
    "For continous training only run the \"for cont'\" cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJSAGCSOd2To"
   },
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 381,
     "status": "ok",
     "timestamp": 1654182338444,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "cTEojBogHuAQ",
    "outputId": "2bc37e82-20eb-49a5-e745-d13ebff60a2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/train1/training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "MAIN_PATH = os.getcwd()\n",
    "TRAINING_PATH = os.path.join(MAIN_PATH, \"training\")\n",
    "DATA_PATH = os.path.join(MAIN_PATH, \"data\")\n",
    "CONFIG_PATH = os.path.join(DATA_PATH, \"pipeline.config\")\n",
    "LABEL_MAP_PATH = os.path.join(DATA_PATH, \"label_map.pbtxt\")\n",
    "TRAIN_DATA_PATH = os.path.join(DATA_PATH, \"train.record\")\n",
    "VAL_DATA_PATH = os.path.join(DATA_PATH, \"validation.record\")\n",
    "TEST_DATA_PATH = os.path.join(DATA_PATH, \"test.record\")\n",
    "\n",
    "print(TRAINING_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "urls = ['https://dl.dropboxusercontent.com/s/9f5suk5oo5u7yyi/test.record',\n",
    "        'https://dl.dropboxusercontent.com/s/tqvtgswib6r4f8u/validation.record',\n",
    "        'https://dl.dropboxusercontent.com/s/6kgr2pwi7kgtmwb/train.record']\n",
    "names = [\"test.record\",\n",
    "        \"validation.record\",\n",
    "        \"train.record\"]\n",
    "\n",
    "for url, name in zip(urls, names):\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    open(os.path.join(DATA_PATH, name), 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldFNUUgIXUYj"
   },
   "source": [
    "## Clone the TensorFlow Model Garden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1654182343201,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "gVoGBfbhePZF",
    "outputId": "00071925-01bb-4d6f-babc-086111c62ba9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/train1\n",
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 74201, done.\u001b[K\n",
      "remote: Counting objects: 100% (287/287), done.\u001b[K\n",
      "remote: Compressing objects: 100% (181/181), done.\u001b[K\n",
      "remote: Total 74201 (delta 128), reused 234 (delta 97), pack-reused 73914\u001b[K\n",
      "Receiving objects: 100% (74201/74201), 580.22 MiB | 28.51 MiB/s, done.\n",
      "Resolving deltas: 100% (52540/52540), done.\n"
     ]
    }
   ],
   "source": [
    "# (For cont')\n",
    "%cd {MAIN_PATH}\n",
    "!git clone https://github.com/ahmadnurokhim/models.git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGaPKO0R_CYk"
   },
   "source": [
    "## TF Object Detection API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owhIVGjB-yAJ"
   },
   "source": [
    "### Compile/install the TF Object Detection API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3IwuD-NXo9l"
   },
   "source": [
    "CD to the models/research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1654182344628,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "lJ6tPMATeWDi",
    "outputId": "4f28f095-dc37-443b-946f-358918fd0814"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/train1/models/research\n"
     ]
    }
   ],
   "source": [
    "# (For cont')\n",
    "%cd {MAIN_PATH}/models/research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3ba50LW_xRd"
   },
   "source": [
    "### Install the protoc files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libprotobuf-dev libprotobuf-lite17 libprotobuf17 libprotoc17\n",
      "The following NEW packages will be installed:\n",
      "  libprotobuf-dev libprotobuf-lite17 libprotobuf17 libprotoc17\n",
      "  protobuf-compiler\n",
      "0 upgraded, 5 newly installed, 0 to remove and 15 not upgraded.\n",
      "Need to get 2758 kB of archives.\n",
      "After this operation, 16.9 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libprotobuf-lite17 amd64 3.6.1.3-2ubuntu5 [132 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 libprotobuf17 amd64 3.6.1.3-2ubuntu5 [798 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal/main amd64 libprotoc17 amd64 3.6.1.3-2ubuntu5 [646 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal/main amd64 libprotobuf-dev amd64 3.6.1.3-2ubuntu5 [1155 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu focal/universe amd64 protobuf-compiler amd64 3.6.1.3-2ubuntu5 [27.6 kB]\n",
      "Fetched 2758 kB in 1s (2277 kB/s)           \u001b[0m\u001b[33m\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libprotobuf-lite17:amd64.\n",
      "(Reading database ... 21502 files and directories currently installed.)\n",
      "Preparing to unpack .../libprotobuf-lite17_3.6.1.3-2ubuntu5_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  5%]\u001b[49m\u001b[39m [##........................................................] \u001b8Unpacking libprotobuf-lite17:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 10%]\u001b[49m\u001b[39m [#####.....................................................] \u001b8Selecting previously unselected package libprotobuf17:amd64.\n",
      "Preparing to unpack .../libprotobuf17_3.6.1.3-2ubuntu5_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 14%]\u001b[49m\u001b[39m [########..................................................] \u001b8Unpacking libprotobuf17:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 19%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Selecting previously unselected package libprotoc17:amd64.\n",
      "Preparing to unpack .../libprotoc17_3.6.1.3-2ubuntu5_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 24%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Unpacking libprotoc17:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 29%]\u001b[49m\u001b[39m [################..........................................] \u001b8Selecting previously unselected package libprotobuf-dev:amd64.\n",
      "Preparing to unpack .../libprotobuf-dev_3.6.1.3-2ubuntu5_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Unpacking libprotobuf-dev:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [######################....................................] \u001b8Selecting previously unselected package protobuf-compiler.\n",
      "Preparing to unpack .../protobuf-compiler_3.6.1.3-2ubuntu5_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 43%]\u001b[49m\u001b[39m [########################..................................] \u001b8Unpacking protobuf-compiler (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 48%]\u001b[49m\u001b[39m [###########################...............................] \u001b8Setting up libprotobuf-lite17:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 52%]\u001b[49m\u001b[39m [##############################............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 57%]\u001b[49m\u001b[39m [#################################.........................] \u001b8Setting up libprotobuf17:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [###################################.......................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 67%]\u001b[49m\u001b[39m [######################################....................] \u001b8Setting up libprotoc17:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 71%]\u001b[49m\u001b[39m [#########################################.................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 76%]\u001b[49m\u001b[39m [############################################..............] \u001b8Setting up protobuf-compiler (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 81%]\u001b[49m\u001b[39m [##############################################............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 86%]\u001b[49m\u001b[39m [#################################################.........] \u001b8Setting up libprotobuf-dev:amd64 (3.6.1.3-2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 90%]\u001b[49m\u001b[39m [####################################################......] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 95%]\u001b[49m\u001b[39m [#######################################################...] \u001b8Processing triggers for libc-bin (2.31-0ubuntu9.7) ...\n",
      "\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "!apt install protobuf-compiler -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1654182345692,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "2VCOalHYfYhh"
   },
   "outputs": [],
   "source": [
    "# (For cont')\n",
    "\n",
    "!protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1g8ZdQoWWN2_"
   },
   "source": [
    "(For cont') \\\n",
    "\\\n",
    "To avoid DNN library not found problem, open the object_detection/packages/tf2/setup.py and make sure to add these lines or you can just run the next cell\n",
    "```\n",
    "    'tensorflow==2.8.0',\n",
    "    'tf-models-official==2.8.0',\n",
    "    'tensorflow_io==0.23.1',\n",
    "    'keras==2.8.0',\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10979,
     "status": "ok",
     "timestamp": 1654182358394,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "t-hzXOqV-Opt",
    "outputId": "e0801f6c-9220-483f-f8f2-f585be4a2c69",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-models-official\n",
      "  Downloading tf_models_official-2.9.2-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-models-official) (5.9.1)\n",
      "Collecting pandas>=0.22.0\n",
      "  Downloading pandas-1.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7 MB 39.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
      "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
      "\u001b[K     |████████████████████████████████| 237 kB 65.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorflow~=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official) (2.9.1)\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\n",
      "\u001b[K     |████████████████████████████████| 92 kB 29.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
      "  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
      "\u001b[K     |████████████████████████████████| 662 kB 35.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-api-python-client>=1.6.7\n",
      "  Downloading google_api_python_client-2.49.0-py2.py3-none-any.whl (8.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.5 MB 44.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Cython\n",
      "  Downloading Cython-0.29.30-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 60.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 5.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tf-slim>=1.1.0\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "\u001b[K     |████████████████████████████████| 352 kB 38.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tf-models-official) (1.22.4)\n",
      "Collecting tensorflow-text~=2.9.0\n",
      "  Downloading tensorflow_text-2.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.6 MB 63.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.17.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 57.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.19.1\n",
      "  Downloading scipy-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 41.6 MB 58.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gin-config\n",
      "  Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 19.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-hub>=0.6.0\n",
      "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "\u001b[K     |████████████████████████████████| 108 kB 70.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
      "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 23.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-datasets\n",
      "  Downloading tensorflow_datasets-4.6.0-py3-none-any.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 62.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pycocotools\n",
      "  Downloading pycocotools-2.0.4.tar.gz (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 60.7 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 107.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /usr/lib/python3/dist-packages (from tf-models-official) (1.14.0)\n",
      "Collecting oauth2client\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 18.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 47.8 MB 48.1 MB/s eta 0:00:01    |█████▎                          | 7.9 MB 48.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 50.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kaggle>=1.3.9\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 15.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Pillow\n",
      "  Downloading Pillow-9.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 65.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.22.0->tf-models-official) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.22.0->tf-models-official) (2.8.2)\n",
      "Collecting dm-tree~=0.1.1\n",
      "  Downloading dm_tree-0.1.7-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (142 kB)\n",
      "\u001b[K     |████████████████████████████████| 142 kB 59.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.46.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (2.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (14.0.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (0.26.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (3.19.4)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (2.9.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (2.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (4.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.14.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (3.3.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (0.4.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (21.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.6.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (62.3.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official) (1.1.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting regex\n",
      "  Downloading regex-2022.6.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\n",
      "\u001b[K     |████████████████████████████████| 764 kB 68.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting portalocker\n",
      "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting tabulate>=0.8.9\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (2.6.6)\n",
      "Collecting google-auth-httplib2>=0.1.0\n",
      "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting httplib2<1dev,>=0.15.0\n",
      "  Downloading httplib2-0.20.4-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 14.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting uritemplate<5,>=3.0.1\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Downloading google_api_core-2.8.1-py3-none-any.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 60.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn>=0.21.3\n",
      "  Downloading scikit_learn-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 31.2 MB 92.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typeguard>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/lib/python3/dist-packages (from tensorflow-datasets->tf-models-official) (2.22.0)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 13.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 17.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official) (5.7.1)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.8.0-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 14.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting etils[epath]\n",
      "  Downloading etils-0.6.0-py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 18.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official) (0.2.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official) (4.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official) (0.4.8)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 69.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->tf-models-official) (3.0.9)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
      "\u001b[K     |████████████████████████████████| 930 kB 39.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from kaggle>=1.3.9->tf-models-official) (2019.11.28)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-6.1.2-py2.py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: urllib3 in /usr/lib/python3/dist-packages (from kaggle>=1.3.9->tf-models-official) (1.25.8)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (0.34.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (2.1.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (1.8.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (5.1.0)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.56.2-py2.py3-none-any.whl (211 kB)\n",
      "\u001b[K     |████████████████████████████████| 211 kB 104.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=1.0.0\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "\u001b[K     |████████████████████████████████| 306 kB 43.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official) (3.8.0)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 19.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (4.11.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official) (3.2.0)\n",
      "Building wheels for collected packages: seqeval, py-cpuinfo, pycocotools, kaggle, promise\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16166 sha256=3aa42728eb7d28553fff3609876af2bd891ee8a2f8ab5e191bccf58679f6aa6e\n",
      "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
      "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22242 sha256=f4e096145e7c879e9aa57fa2d0f90037fd304fcf4b21ebff5a641ceab0f00f10\n",
      "  Stored in directory: /root/.cache/pip/wheels/57/cb/6d/bab2257f26c5be4a96ff65c3d2a7122c96529b73773ee37f36\n",
      "  Building wheel for pycocotools (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.4-cp38-cp38-linux_x86_64.whl size=418788 sha256=18470755641c25a4ba29b32d1190c148ae08ef62795b9bd43c2e68e72c961610\n",
      "  Stored in directory: /root/.cache/pip/wheels/dd/e2/43/3e93cd653b3346b3d702bb0509bc611189f95d60407bff1484\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73032 sha256=c69eb8adfb4d1d4b323ea16bbb16fb491c400b60dc19f690b588148888f38106\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/da/11/144cc25aebdaeb4931b231e25fd34b394e6a5725cbb2f50106\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21485 sha256=ef98b1115c6bc343cd6051f58c974357ae677a8243791b3468b55712815cc0e2\n",
      "  Stored in directory: /root/.cache/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "Successfully built seqeval py-cpuinfo pycocotools kaggle promise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: pandas, dm-tree, tensorflow-model-optimization, regex, portalocker, tabulate, colorama, sacrebleu, pyyaml, httplib2, google-auth-httplib2, uritemplate, googleapis-common-protos, google-api-core, google-api-python-client, Cython, joblib, scipy, threadpoolctl, scikit-learn, seqeval, tf-slim, tensorflow-hub, tensorflow-text, typeguard, tensorflow-addons, gin-config, py-cpuinfo, dill, tqdm, toml, promise, tensorflow-metadata, etils, tensorflow-datasets, kiwisolver, Pillow, fonttools, cycler, matplotlib, pycocotools, sentencepiece, oauth2client, opencv-python-headless, text-unidecode, python-slugify, kaggle, tf-models-official\n",
      "Successfully installed Cython-0.29.30 Pillow-9.1.1 colorama-0.4.4 cycler-0.11.0 dill-0.3.5.1 dm-tree-0.1.7 etils-0.6.0 fonttools-4.33.3 gin-config-0.5.0 google-api-core-2.8.1 google-api-python-client-2.49.0 google-auth-httplib2-0.1.0 googleapis-common-protos-1.56.2 httplib2-0.20.4 joblib-1.1.0 kaggle-1.5.12 kiwisolver-1.4.2 matplotlib-3.5.2 oauth2client-4.1.3 opencv-python-headless-4.5.5.64 pandas-1.4.2 portalocker-2.4.0 promise-2.3 py-cpuinfo-8.0.0 pycocotools-2.0.4 python-slugify-6.1.2 pyyaml-5.4.1 regex-2022.6.2 sacrebleu-2.1.0 scikit-learn-1.1.1 scipy-1.8.1 sentencepiece-0.1.96 seqeval-1.2.2 tabulate-0.8.9 tensorflow-addons-0.17.0 tensorflow-datasets-4.6.0 tensorflow-hub-0.12.0 tensorflow-metadata-1.8.0 tensorflow-model-optimization-0.7.2 tensorflow-text-2.9.0 text-unidecode-1.3 tf-models-official-2.9.2 tf-slim-1.1.0 threadpoolctl-3.1.0 toml-0.10.2 tqdm-4.64.0 typeguard-2.13.3 uritemplate-4.1.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tensorflow_io\n",
      "  Downloading tensorflow_io-0.26.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem==0.26.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_io) (0.26.0)\n",
      "Installing collected packages: tensorflow-io\n",
      "Successfully installed tensorflow-io-0.26.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (2.9.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorflow==2.8.0\n",
    "#!pip install tf-models-official==2.8.0\n",
    "#!pip install tensorflow_io==0.23.1\n",
    "#!pip install keras==2.8.0\n",
    "!pip install tf-models-official\n",
    "!pip install tensorflow_io\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 642,
     "status": "ok",
     "timestamp": 1654182359025,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "7VDFzo4bfZx8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /root/train1/models/research\n",
      "Collecting avro-python3\n",
      "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
      "Collecting apache-beam\n",
      "  Downloading apache_beam-2.39.0-cp38-cp38-manylinux2010_x86_64.whl (12.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.3 MB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (9.1.1)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.9 MB 105.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (3.5.2)\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.29.30)\n",
      "Collecting contextlib2\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: tf-slim in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from object-detection==0.1) (1.14.0)\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.0.4)\n",
      "Collecting lvis\n",
      "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.8.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: tf-models-official>=2.5.1 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.9.2)\n",
      "Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.26.0)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.9.0)\n",
      "Collecting pyparsing==2.4.7\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 14.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting crcmod<2.0,>=1.7\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "\u001b[K     |████████████████████████████████| 89 kB 28.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting fastavro<2,>=0.23.6\n",
      "  Downloading fastavro-1.4.12-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 32.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.46.3)\n",
      "Collecting hdfs<3.0.0,>=2.1.0\n",
      "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.14.3 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.22.4)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.8.2)\n",
      "Collecting httplib2<0.20.0,>=0.8\n",
      "  Downloading httplib2-0.19.1-py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 12.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cloudpickle<3,>=2.0.0\n",
      "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
      "Collecting pyarrow<8.0.0,>=0.15.1\n",
      "  Downloading pyarrow-7.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.7 MB 30.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting proto-plus<2,>=1.7.1\n",
      "  Downloading proto_plus-1.20.5-py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 10.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (4.2.0)\n",
      "Collecting orjson<4.0\n",
      "  Downloading orjson-3.7.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (256 kB)\n",
      "\u001b[K     |████████████████████████████████| 256 kB 38.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydot<2,>=1.2.0\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.19.4)\n",
      "Collecting requests<3.0.0,>=2.24.0\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 5.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2022.1)\n",
      "Collecting dill<0.3.2,>=0.3.1.1\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 61.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
      "  Downloading pymongo-3.12.3-cp38-cp38-manylinux2014_x86_64.whl (546 kB)\n",
      "\u001b[K     |████████████████████████████████| 546 kB 54.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->object-detection==0.1) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->object-detection==0.1) (4.33.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->object-detection==0.1) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->object-detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from tf-slim->object-detection==0.1) (1.0.0)\n",
      "Collecting opencv-python>=4.1.0.25\n",
      "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 60.5 MB 15.4 MB/s eta 0:00:01     |██████▎                         | 11.8 MB 37.8 MB/s eta 0:00:02     |█████████████████▌              | 33.1 MB 37.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.7.2)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: pyyaml<6.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.1)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (8.0.0)\n",
      "Requirement already satisfied: oauth2client in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
      "Requirement already satisfied: seqeval in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.17.0)\n",
      "Requirement already satisfied: tensorflow-text~=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.9.0)\n",
      "Requirement already satisfied: gin-config in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.49.0)\n",
      "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.1.0)\n",
      "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.5.5.64)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.96)\n",
      "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow~=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.9.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.26.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_io->object-detection==0.1) (0.26.0)\n",
      "Collecting docopt\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Collecting charset-normalizer~=2.0.0; python_version >= \"3\"\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.8)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.13.3)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.8.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.6.6)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2.4.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.2)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.8/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.4.4)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.7.1)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n",
      "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.6.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.1)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.9.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (62.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.1.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.34.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
      "Building wheels for collected packages: object-detection, avro-python3, crcmod, dill, docopt\n",
      "  Building wheel for object-detection (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1693568 sha256=3ff6dbe56f10e12ad3aba6b13a968821a0a26bad90fe95d12685e3818ee36e4b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-7f_f__iy/wheels/63/a7/0e/470621870b3a152ee838e90ee41621c4a103254383f3be3d97\n",
      "  Building wheel for avro-python3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43992 sha256=96254d3fae3049c9694d77a607f4dc3ad294ec92c876d494f2a4fb2e7f7baef6\n",
      "  Stored in directory: /root/.cache/pip/wheels/bb/73/e9/d273421f5723c4bf544dcf9eb097bda94421ef8d3252699f0a\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for crcmod: filename=crcmod-1.7-cp38-cp38-linux_x86_64.whl size=35987 sha256=7ae347bb5f032b00aa879c7c2cd8090b525ffd4ad13fddbbd5c48a4ae0d6559f\n",
      "  Stored in directory: /root/.cache/pip/wheels/ca/5a/02/f3acf982a026f3319fb3e798a8dca2d48fafee7761788562e9\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78543 sha256=8da3611c5457b27708718b5762b6cc27b6b0c7d7e00cca3f85ad599c0bcd2d68\n",
      "  Stored in directory: /root/.cache/pip/wheels/07/35/78/e9004fa30578734db7f10e7a211605f3f0778d2bdde38a239d\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=cdfa8c723966b1f0749e38144015e19b652df480c59a9a1a5639b0260a6aa7a2\n",
      "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
      "Successfully built object-detection avro-python3 crcmod dill docopt\n",
      "Installing collected packages: avro-python3, crcmod, fastavro, docopt, charset-normalizer, requests, hdfs, pyparsing, httplib2, cloudpickle, pyarrow, proto-plus, orjson, pydot, dill, pymongo, apache-beam, lxml, contextlib2, opencv-python, lvis, object-detection\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.22.0\n",
      "    Uninstalling requests-2.22.0:\n",
      "      Successfully uninstalled requests-2.22.0\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.9\n",
      "    Uninstalling pyparsing-3.0.9:\n",
      "      Successfully uninstalled pyparsing-3.0.9\n",
      "  Attempting uninstall: httplib2\n",
      "    Found existing installation: httplib2 0.20.4\n",
      "    Uninstalling httplib2-0.20.4:\n",
      "      Successfully uninstalled httplib2-0.20.4\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.5.1\n",
      "    Uninstalling dill-0.3.5.1:\n",
      "      Successfully uninstalled dill-0.3.5.1\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "jupyterlab 3.4.2 requires tornado>=6.1.0, but you'll have tornado 5.1.1 which is incompatible.\n",
      "jupyter-server 1.17.0 requires tornado>=6.1.0, but you'll have tornado 5.1.1 which is incompatible.\n",
      "ipykernel 6.13.0 requires tornado>=6.1, but you'll have tornado 5.1.1 which is incompatible.\u001b[0m\n",
      "Successfully installed apache-beam-2.39.0 avro-python3-1.10.2 charset-normalizer-2.0.12 cloudpickle-2.1.0 contextlib2-21.6.0 crcmod-1.7 dill-0.3.1.1 docopt-0.6.2 fastavro-1.4.12 hdfs-2.7.0 httplib2-0.19.1 lvis-0.5.3 lxml-4.9.0 object-detection-0.1 opencv-python-4.5.5.64 orjson-3.7.1 proto-plus-1.20.5 pyarrow-7.0.0 pydot-1.4.2 pymongo-3.12.3 pyparsing-2.4.7 requests-2.27.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# (For cont')\n",
    "\n",
    "!cp object_detection/packages/tf2/setup.py .\n",
    "!python -m pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7S6YquyWg_HW"
   },
   "source": [
    "### Test the TF Object Detection installation API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30628,
     "status": "ok",
     "timestamp": 1654182396978,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "cDB1YYuqhJcp",
    "outputId": "cfe9f44c-8a7a-4ca4-e3c6-fb611b108f3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tests under Python 3.8.10: /usr/local/bin/python\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "2022-06-04 08:56:45.876775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-04 08:56:46.602938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22342 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:81:00.0, compute capability: 8.6\n",
      "/usr/local/lib/python3.8/dist-packages/object_detection/builders/model_builder.py:1102: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
      "W0604 08:56:47.165323 140555412989760 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.52s\n",
      "I0604 08:56:47.388785 140555412989760 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.52s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.48s\n",
      "I0604 08:56:47.872305 140555412989760 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.48s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.34s\n",
      "I0604 08:56:48.210850 140555412989760 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.34s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.21s\n",
      "I0604 08:56:48.422688 140555412989760 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.21s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.47s\n",
      "I0604 08:56:49.895971 140555412989760 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.47s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I0604 08:56:49.896819 140555412989760 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "I0604 08:56:49.917434 140555412989760 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "I0604 08:56:49.930203 140555412989760 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "I0604 08:56:49.943250 140555412989760 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.08s\n",
      "I0604 08:56:50.026600 140555412989760 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
      "I0604 08:56:50.106138 140555412989760 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.08s\n",
      "I0604 08:56:50.189140 140555412989760 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.08s\n",
      "I0604 08:56:50.270589 140555412989760 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.08s\n",
      "I0604 08:56:50.351128 140555412989760 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "I0604 08:56:50.375002 140555412989760 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I0604 08:56:50.666204 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I0604 08:56:50.666343 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
      "I0604 08:56:50.666393 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 3\n",
      "I0604 08:56:50.668248 140555412989760 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 08:56:50.681490 140555412989760 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 08:56:50.681575 140555412989760 efficientnet_model.py:143] round_filter input=16 output=16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0604 08:56:50.728603 140555412989760 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0604 08:56:50.728703 140555412989760 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 08:56:50.847822 140555412989760 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 08:56:50.847936 140555412989760 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0604 08:56:50.965665 140555412989760 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0604 08:56:50.965777 140555412989760 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0604 08:56:51.145262 140555412989760 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0604 08:56:51.145391 140555412989760 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0604 08:56:51.324554 140555412989760 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0604 08:56:51.324677 140555412989760 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0604 08:56:51.563769 140555412989760 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0604 08:56:51.563888 140555412989760 efficientnet_model.py:143] round_filter input=320 output=320\n",
      "I0604 08:56:51.621462 140555412989760 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
      "I0604 08:56:51.645223 140555412989760 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 08:56:51.691580 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I0604 08:56:51.691686 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
      "I0604 08:56:51.691735 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 4\n",
      "I0604 08:56:51.693129 140555412989760 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 08:56:51.705343 140555412989760 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 08:56:51.705422 140555412989760 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0604 08:56:51.799656 140555412989760 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0604 08:56:51.799760 140555412989760 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 08:56:51.977835 140555412989760 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 08:56:51.977952 140555412989760 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0604 08:56:52.158248 140555412989760 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0604 08:56:52.158378 140555412989760 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0604 08:56:52.397541 140555412989760 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0604 08:56:52.397661 140555412989760 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0604 08:56:52.636339 140555412989760 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0604 08:56:52.636459 140555412989760 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0604 08:56:52.937852 140555412989760 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0604 08:56:52.937977 140555412989760 efficientnet_model.py:143] round_filter input=320 output=320\n",
      "I0604 08:56:53.084028 140555412989760 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
      "I0604 08:56:53.107265 140555412989760 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 08:56:53.162891 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0604 08:56:53.163011 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
      "I0604 08:56:53.163059 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 5\n",
      "I0604 08:56:53.164462 140555412989760 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 08:56:53.176830 140555412989760 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0604 08:56:53.176914 140555412989760 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0604 08:56:53.272447 140555412989760 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0604 08:56:53.272562 140555412989760 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 08:56:53.451314 140555412989760 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0604 08:56:53.451437 140555412989760 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0604 08:56:53.632120 140555412989760 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0604 08:56:53.632266 140555412989760 efficientnet_model.py:143] round_filter input=80 output=88\n",
      "I0604 08:56:53.872397 140555412989760 efficientnet_model.py:143] round_filter input=80 output=88\n",
      "I0604 08:56:53.872519 140555412989760 efficientnet_model.py:143] round_filter input=112 output=120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0604 08:56:54.255606 140555412989760 efficientnet_model.py:143] round_filter input=112 output=120\n",
      "I0604 08:56:54.255742 140555412989760 efficientnet_model.py:143] round_filter input=192 output=208\n",
      "I0604 08:56:54.561700 140555412989760 efficientnet_model.py:143] round_filter input=192 output=208\n",
      "I0604 08:56:54.561829 140555412989760 efficientnet_model.py:143] round_filter input=320 output=352\n",
      "I0604 08:56:54.680073 140555412989760 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
      "I0604 08:56:54.704226 140555412989760 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 08:56:54.759199 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0604 08:56:54.759316 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
      "I0604 08:56:54.759365 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 6\n",
      "I0604 08:56:54.760776 140555412989760 efficientnet_model.py:143] round_filter input=32 output=40\n",
      "I0604 08:56:54.774174 140555412989760 efficientnet_model.py:143] round_filter input=32 output=40\n",
      "I0604 08:56:54.774264 140555412989760 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 08:56:54.869261 140555412989760 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 08:56:54.869392 140555412989760 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0604 08:56:55.048425 140555412989760 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0604 08:56:55.048548 140555412989760 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0604 08:56:55.228061 140555412989760 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0604 08:56:55.228182 140555412989760 efficientnet_model.py:143] round_filter input=80 output=96\n",
      "I0604 08:56:55.533954 140555412989760 efficientnet_model.py:143] round_filter input=80 output=96\n",
      "I0604 08:56:55.534074 140555412989760 efficientnet_model.py:143] round_filter input=112 output=136\n",
      "I0604 08:56:55.872064 140555412989760 efficientnet_model.py:143] round_filter input=112 output=136\n",
      "I0604 08:56:55.872195 140555412989760 efficientnet_model.py:143] round_filter input=192 output=232\n",
      "I0604 08:56:56.234343 140555412989760 efficientnet_model.py:143] round_filter input=192 output=232\n",
      "I0604 08:56:56.234473 140555412989760 efficientnet_model.py:143] round_filter input=320 output=384\n",
      "I0604 08:56:56.354106 140555412989760 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
      "I0604 08:56:56.376840 140555412989760 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 08:56:56.439110 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I0604 08:56:56.439231 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
      "I0604 08:56:56.439282 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 7\n",
      "I0604 08:56:56.440713 140555412989760 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0604 08:56:56.453284 140555412989760 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0604 08:56:56.453381 140555412989760 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 08:56:56.549698 140555412989760 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 08:56:56.549816 140555412989760 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0604 08:56:56.789537 140555412989760 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0604 08:56:56.789664 140555412989760 efficientnet_model.py:143] round_filter input=40 output=56\n",
      "I0604 08:56:57.030179 140555412989760 efficientnet_model.py:143] round_filter input=40 output=56\n",
      "I0604 08:56:57.030314 140555412989760 efficientnet_model.py:143] round_filter input=80 output=112\n",
      "I0604 08:56:57.390766 140555412989760 efficientnet_model.py:143] round_filter input=80 output=112\n",
      "I0604 08:56:57.390896 140555412989760 efficientnet_model.py:143] round_filter input=112 output=160\n",
      "I0604 08:56:57.752784 140555412989760 efficientnet_model.py:143] round_filter input=112 output=160\n",
      "I0604 08:56:57.752907 140555412989760 efficientnet_model.py:143] round_filter input=192 output=272\n",
      "I0604 08:56:58.241003 140555412989760 efficientnet_model.py:143] round_filter input=192 output=272\n",
      "I0604 08:56:58.241132 140555412989760 efficientnet_model.py:143] round_filter input=320 output=448\n",
      "I0604 08:56:58.359250 140555412989760 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
      "I0604 08:56:58.381848 140555412989760 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0604 08:56:58.628317 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I0604 08:56:58.628448 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
      "I0604 08:56:58.628498 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 7\n",
      "I0604 08:56:58.629914 140555412989760 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0604 08:56:58.642528 140555412989760 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0604 08:56:58.642608 140555412989760 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 08:56:58.790271 140555412989760 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0604 08:56:58.790421 140555412989760 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0604 08:56:59.093118 140555412989760 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0604 08:56:59.093250 140555412989760 efficientnet_model.py:143] round_filter input=40 output=64\n",
      "I0604 08:56:59.396474 140555412989760 efficientnet_model.py:143] round_filter input=40 output=64\n",
      "I0604 08:56:59.396612 140555412989760 efficientnet_model.py:143] round_filter input=80 output=128\n",
      "I0604 08:56:59.820872 140555412989760 efficientnet_model.py:143] round_filter input=80 output=128\n",
      "I0604 08:56:59.821005 140555412989760 efficientnet_model.py:143] round_filter input=112 output=176\n",
      "I0604 08:57:00.244341 140555412989760 efficientnet_model.py:143] round_filter input=112 output=176\n",
      "I0604 08:57:00.244473 140555412989760 efficientnet_model.py:143] round_filter input=192 output=304\n",
      "I0604 08:57:00.788091 140555412989760 efficientnet_model.py:143] round_filter input=192 output=304\n",
      "I0604 08:57:00.788224 140555412989760 efficientnet_model.py:143] round_filter input=320 output=512\n",
      "I0604 08:57:00.967540 140555412989760 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
      "I0604 08:57:00.990073 140555412989760 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 08:57:01.075162 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I0604 08:57:01.075303 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
      "I0604 08:57:01.075356 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 8\n",
      "I0604 08:57:01.076778 140555412989760 efficientnet_model.py:143] round_filter input=32 output=56\n",
      "I0604 08:57:01.089357 140555412989760 efficientnet_model.py:143] round_filter input=32 output=56\n",
      "I0604 08:57:01.089437 140555412989760 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0604 08:57:01.234220 140555412989760 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0604 08:57:01.234362 140555412989760 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0604 08:57:01.595200 140555412989760 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0604 08:57:01.595336 140555412989760 efficientnet_model.py:143] round_filter input=40 output=72\n",
      "I0604 08:57:01.958674 140555412989760 efficientnet_model.py:143] round_filter input=40 output=72\n",
      "I0604 08:57:01.958802 140555412989760 efficientnet_model.py:143] round_filter input=80 output=144\n",
      "I0604 08:57:02.443062 140555412989760 efficientnet_model.py:143] round_filter input=80 output=144\n",
      "I0604 08:57:02.443191 140555412989760 efficientnet_model.py:143] round_filter input=112 output=200\n",
      "I0604 08:57:02.930850 140555412989760 efficientnet_model.py:143] round_filter input=112 output=200\n",
      "I0604 08:57:02.930977 140555412989760 efficientnet_model.py:143] round_filter input=192 output=344\n",
      "I0604 08:57:03.861659 140555412989760 efficientnet_model.py:143] round_filter input=192 output=344\n",
      "I0604 08:57:03.861796 140555412989760 efficientnet_model.py:143] round_filter input=320 output=576\n",
      "I0604 08:57:04.053018 140555412989760 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
      "I0604 08:57:04.076305 140555412989760 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0604 08:57:04.172921 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I0604 08:57:04.173068 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
      "I0604 08:57:04.173117 140555412989760 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 8\n",
      "I0604 08:57:04.174566 140555412989760 efficientnet_model.py:143] round_filter input=32 output=64\n",
      "I0604 08:57:04.187790 140555412989760 efficientnet_model.py:143] round_filter input=32 output=64\n",
      "I0604 08:57:04.187933 140555412989760 efficientnet_model.py:143] round_filter input=16 output=32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0604 08:57:04.387891 140555412989760 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0604 08:57:04.388024 140555412989760 efficientnet_model.py:143] round_filter input=24 output=48\n",
      "I0604 08:57:04.825096 140555412989760 efficientnet_model.py:143] round_filter input=24 output=48\n",
      "I0604 08:57:04.825236 140555412989760 efficientnet_model.py:143] round_filter input=40 output=80\n",
      "I0604 08:57:05.260443 140555412989760 efficientnet_model.py:143] round_filter input=40 output=80\n",
      "I0604 08:57:05.260593 140555412989760 efficientnet_model.py:143] round_filter input=80 output=160\n",
      "I0604 08:57:05.884390 140555412989760 efficientnet_model.py:143] round_filter input=80 output=160\n",
      "I0604 08:57:05.884534 140555412989760 efficientnet_model.py:143] round_filter input=112 output=224\n",
      "I0604 08:57:06.502642 140555412989760 efficientnet_model.py:143] round_filter input=112 output=224\n",
      "I0604 08:57:06.502781 140555412989760 efficientnet_model.py:143] round_filter input=192 output=384\n",
      "I0604 08:57:07.316887 140555412989760 efficientnet_model.py:143] round_filter input=192 output=384\n",
      "I0604 08:57:07.317026 140555412989760 efficientnet_model.py:143] round_filter input=320 output=640\n",
      "I0604 08:57:07.565014 140555412989760 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
      "I0604 08:57:07.588473 140555412989760 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 17.33s\n",
      "I0604 08:57:07.705605 140555412989760 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 17.33s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I0604 08:57:07.713536 140555412989760 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I0604 08:57:07.715156 140555412989760 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I0604 08:57:07.715514 140555412989760 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I0604 08:57:07.716859 140555412989760 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "I0604 08:57:07.718073 140555412989760 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I0604 08:57:07.718379 140555412989760 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I0604 08:57:07.719245 140555412989760 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 21.848s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "# (For cont')\n",
    "\n",
    "!python object_detection/builders/model_builder_tf2_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TntgsRpEhkGL"
   },
   "source": [
    "## Download pre-trained model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KljfW26pixrB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/train1/data\n"
     ]
    }
   ],
   "source": [
    "%cd {DATA_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "wget is already the newest version (1.20.3-1ubuntu2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt install wget -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "T4wCOUPwikAs",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-04 08:57:10--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 142.250.75.16, 2a00:1450:401b:801::2010\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|142.250.75.16|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20515344 (20M) [application/x-tar]\n",
      "Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz.1’\n",
      "\n",
      "ssd_mobilenet_v2_fp 100%[===================>]  19.56M  63.2MB/s    in 0.3s    \n",
      "\n",
      "2022-06-04 08:57:11 (63.2 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz.1’ saved [20515344/20515344]\n",
      "\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
    "!tar -xzvf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the pipeline.config (IMPORTANT!)\n",
    "change the checkpoint, label map, train, and test in data/pipeline.config to below path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: /root/train1/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\n",
      "Label map: /root/train1/data/label_map.pbtxt\n",
      "Train: /root/train1/data/train.record\n",
      "Test: /root/train1/data/test.record\n"
     ]
    }
   ],
   "source": [
    "print(\"Checkpoint: \" + os.path.join(DATA_PATH, \"ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\", \"checkpoint\", \"ckpt-0\"))\n",
    "print(\"Label map: \" + LABEL_MAP_PATH)\n",
    "print(\"Train: \" + TRAIN_DATA_PATH)\n",
    "print(\"Test: \" + TEST_DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also change add \"max_to_keep=None\" as parameter in tf.train.Saver() in /research/object_detection/legacy/trainer.py \\\n",
    "So it'll be:\\\n",
    "\\\n",
    "saver = tf.train.Saver(max_to_keep=None, \\\n",
    "keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vr1BMAKl2kG"
   },
   "source": [
    "## Load Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1654187407390,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "zNqRvjtKl2Xn",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b8f68bbd5885d5e8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b8f68bbd5885d5e8\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (For cont')\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /root/train1/training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYYViyUNmFDy"
   },
   "source": [
    "# Train The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTgNmhT5alLz"
   },
   "source": [
    "## Fixing incompatible libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19274,
     "status": "ok",
     "timestamp": 1654182416826,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "JbRpZNpOn_NY",
    "outputId": "6cd829fa-4f44-41dc-ee92-a33ad74da7d2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: opencv-python 4.5.5.64\n",
      "Uninstalling opencv-python-4.5.5.64:\n",
      "  Successfully uninstalled opencv-python-4.5.5.64\n",
      "\u001b[33mWARNING: Skipping opencv-contrib-python as it is not installed.\u001b[0m\n",
      "Found existing installation: opencv-python-headless 4.5.5.64\n",
      "Uninstalling opencv-python-headless-4.5.5.64:\n",
      "  Successfully uninstalled opencv-python-headless-4.5.5.64\n",
      "Collecting opencv-python==4.5.5.64\n",
      "  Using cached opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5; python_version >= \"3.7\" in /usr/local/lib/python3.8/dist-packages (from opencv-python==4.5.5.64) (1.22.4)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.5.64\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting opencv-contrib-python==4.5.5.64\n",
      "  Downloading opencv_contrib_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (66.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 66.7 MB 159 kB/s eta 0:00:01     |████████████████████████▎       | 50.5 MB 2.2 MB/s eta 0:00:08     |██████████████████████████      | 54.4 MB 2.2 MB/s eta 0:00:06\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3; python_version >= \"3.8\" in /usr/local/lib/python3.8/dist-packages (from opencv-contrib-python==4.5.5.64) (1.22.4)\n",
      "Installing collected packages: opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-4.5.5.64\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting opencv-python-headless==4.5.5.64\n",
      "  Using cached opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3; python_version >= \"3.8\" in /usr/local/lib/python3.8/dist-packages (from opencv-python-headless==4.5.5.64) (1.22.4)\n",
      "Installing collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.5.5.64\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# (For cont')\n",
    "#==4.5.4.60\n",
    "!pip uninstall opencv-python --y\n",
    "!pip uninstall opencv-contrib-python --y\n",
    "!pip uninstall opencv-python-headless --y\n",
    "!pip install opencv-python==4.5.5.64 \n",
    "!pip install opencv-contrib-python==4.5.5.64 \n",
    "!pip install opencv-python-headless==4.5.5.64 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1614535,
     "status": "ok",
     "timestamp": 1654189769240,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "Qv3gj-XQmaJN",
    "outputId": "8766c2e3-5058-4c4c-8be9-a5dcd8d1488c",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/train1/models/research/object_detection\n",
      "2022-06-04 08:58:52.145771: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-04 08:58:52.566534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22340 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:81:00.0, compute capability: 8.6\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I0604 08:58:52.787027 139685712938816 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: None\n",
      "I0604 08:58:52.791342 139685712938816 config_util.py:552] Maybe overwriting train_steps: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0604 08:58:52.791433 139685712938816 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0604 08:58:52.820286 139685712938816 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['/root/train1/data/train.record']\n",
      "I0604 08:58:52.826949 139685712938816 dataset_builder.py:162] Reading unweighted datasets: ['/root/train1/data/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['/root/train1/data/train.record']\n",
      "I0604 08:58:52.827469 139685712938816 dataset_builder.py:79] Reading record datasets for input file: ['/root/train1/data/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0604 08:58:52.827621 139685712938816 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0604 08:58:52.827728 139685712938816 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0604 08:58:52.832054 139685712938816 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0604 08:58:52.854770 139685712938816 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0604 08:58:59.720139 139685712938816 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0604 08:59:02.672403 139685712938816 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0604 08:59:04.185138 139685712938816 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0604 08:59:07.080723 139643009890048 deprecation.py:554] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "/usr/local/lib/python3.8/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "2022-06-04 09:00:38.175243: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-06-04 09:00:40.380783: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "INFO:tensorflow:Step 10100 per-step time 1.658s\n",
      "I0604 09:01:52.695780 139685712938816 model_lib_v2.py:705] Step 10100 per-step time 1.658s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.18163054,\n",
      " 'Loss/localization_loss': 0.1427092,\n",
      " 'Loss/regularization_loss': 0.12568246,\n",
      " 'Loss/total_loss': 0.45002222,\n",
      " 'learning_rate': 0.07338293}\n",
      "I0604 09:01:52.696089 139685712938816 model_lib_v2.py:708] {'Loss/classification_loss': 0.18163054,\n",
      " 'Loss/localization_loss': 0.1427092,\n",
      " 'Loss/regularization_loss': 0.12568246,\n",
      " 'Loss/total_loss': 0.45002222,\n",
      " 'learning_rate': 0.07338293}\n",
      "INFO:tensorflow:Step 10200 per-step time 0.699s\n",
      "I0604 09:03:02.405614 139685712938816 model_lib_v2.py:705] Step 10200 per-step time 0.699s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16065615,\n",
      " 'Loss/localization_loss': 0.10436859,\n",
      " 'Loss/regularization_loss': 0.12539515,\n",
      " 'Loss/total_loss': 0.3904199,\n",
      " 'learning_rate': 0.073240966}\n",
      "I0604 09:03:02.405875 139685712938816 model_lib_v2.py:708] {'Loss/classification_loss': 0.16065615,\n",
      " 'Loss/localization_loss': 0.10436859,\n",
      " 'Loss/regularization_loss': 0.12539515,\n",
      " 'Loss/total_loss': 0.3904199,\n",
      " 'learning_rate': 0.073240966}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 10300 per-step time 0.699s\n",
      "I0604 09:04:12.304435 139685712938816 model_lib_v2.py:705] Step 10300 per-step time 0.699s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16598654,\n",
      " 'Loss/localization_loss': 0.121635675,\n",
      " 'Loss/regularization_loss': 0.12521978,\n",
      " 'Loss/total_loss': 0.41284198,\n",
      " 'learning_rate': 0.07309763}\n",
      "I0604 09:04:12.304675 139685712938816 model_lib_v2.py:708] {'Loss/classification_loss': 0.16598654,\n",
      " 'Loss/localization_loss': 0.121635675,\n",
      " 'Loss/regularization_loss': 0.12521978,\n",
      " 'Loss/total_loss': 0.41284198,\n",
      " 'learning_rate': 0.07309763}\n",
      "INFO:tensorflow:Step 10400 per-step time 0.699s\n",
      "I0604 09:05:22.211722 139685712938816 model_lib_v2.py:705] Step 10400 per-step time 0.699s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16049474,\n",
      " 'Loss/localization_loss': 0.10185771,\n",
      " 'Loss/regularization_loss': 0.124973714,\n",
      " 'Loss/total_loss': 0.38732618,\n",
      " 'learning_rate': 0.07295293}\n",
      "I0604 09:05:22.211970 139685712938816 model_lib_v2.py:708] {'Loss/classification_loss': 0.16049474,\n",
      " 'Loss/localization_loss': 0.10185771,\n",
      " 'Loss/regularization_loss': 0.124973714,\n",
      " 'Loss/total_loss': 0.38732618,\n",
      " 'learning_rate': 0.07295293}\n",
      "INFO:tensorflow:Step 10500 per-step time 0.700s\n",
      "I0604 09:06:32.228470 139685712938816 model_lib_v2.py:705] Step 10500 per-step time 0.700s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16776647,\n",
      " 'Loss/localization_loss': 0.13438061,\n",
      " 'Loss/regularization_loss': 0.124673694,\n",
      " 'Loss/total_loss': 0.42682078,\n",
      " 'learning_rate': 0.07280689}\n",
      "I0604 09:06:32.228718 139685712938816 model_lib_v2.py:708] {'Loss/classification_loss': 0.16776647,\n",
      " 'Loss/localization_loss': 0.13438061,\n",
      " 'Loss/regularization_loss': 0.124673694,\n",
      " 'Loss/total_loss': 0.42682078,\n",
      " 'learning_rate': 0.07280689}\n",
      "INFO:tensorflow:Step 10600 per-step time 0.699s\n",
      "I0604 09:07:42.151052 139685712938816 model_lib_v2.py:705] Step 10600 per-step time 0.699s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1482868,\n",
      " 'Loss/localization_loss': 0.113265686,\n",
      " 'Loss/regularization_loss': 0.124565154,\n",
      " 'Loss/total_loss': 0.38611764,\n",
      " 'learning_rate': 0.07265949}\n",
      "I0604 09:07:42.151332 139685712938816 model_lib_v2.py:708] {'Loss/classification_loss': 0.1482868,\n",
      " 'Loss/localization_loss': 0.113265686,\n",
      " 'Loss/regularization_loss': 0.124565154,\n",
      " 'Loss/total_loss': 0.38611764,\n",
      " 'learning_rate': 0.07265949}\n",
      "INFO:tensorflow:Step 10700 per-step time 0.701s\n",
      "I0604 09:08:52.298901 139685712938816 model_lib_v2.py:705] Step 10700 per-step time 0.701s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.18175888,\n",
      " 'Loss/localization_loss': 0.13536575,\n",
      " 'Loss/regularization_loss': 0.12419887,\n",
      " 'Loss/total_loss': 0.44132352,\n",
      " 'learning_rate': 0.07251076}\n",
      "I0604 09:08:52.299137 139685712938816 model_lib_v2.py:708] {'Loss/classification_loss': 0.18175888,\n",
      " 'Loss/localization_loss': 0.13536575,\n",
      " 'Loss/regularization_loss': 0.12419887,\n",
      " 'Loss/total_loss': 0.44132352,\n",
      " 'learning_rate': 0.07251076}\n",
      "INFO:tensorflow:Step 10800 per-step time 0.699s\n",
      "I0604 09:10:02.204333 139685712938816 model_lib_v2.py:705] Step 10800 per-step time 0.699s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1876261,\n",
      " 'Loss/localization_loss': 0.1787114,\n",
      " 'Loss/regularization_loss': 0.12394324,\n",
      " 'Loss/total_loss': 0.49028072,\n",
      " 'learning_rate': 0.07236068}\n",
      "I0604 09:10:02.204590 139685712938816 model_lib_v2.py:708] {'Loss/classification_loss': 0.1876261,\n",
      " 'Loss/localization_loss': 0.1787114,\n",
      " 'Loss/regularization_loss': 0.12394324,\n",
      " 'Loss/total_loss': 0.49028072,\n",
      " 'learning_rate': 0.07236068}\n",
      "INFO:tensorflow:Step 10900 per-step time 0.699s\n",
      "I0604 09:11:12.134013 139685712938816 model_lib_v2.py:705] Step 10900 per-step time 0.699s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16473511,\n",
      " 'Loss/localization_loss': 0.13225468,\n",
      " 'Loss/regularization_loss': 0.12369014,\n",
      " 'Loss/total_loss': 0.42067993,\n",
      " 'learning_rate': 0.07220927}\n",
      "I0604 09:11:12.134287 139685712938816 model_lib_v2.py:708] {'Loss/classification_loss': 0.16473511,\n",
      " 'Loss/localization_loss': 0.13225468,\n",
      " 'Loss/regularization_loss': 0.12369014,\n",
      " 'Loss/total_loss': 0.42067993,\n",
      " 'learning_rate': 0.07220927}\n",
      "INFO:tensorflow:Step 11000 per-step time 0.699s\n",
      "I0604 09:12:22.021365 139685712938816 model_lib_v2.py:705] Step 11000 per-step time 0.699s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1677623,\n",
      " 'Loss/localization_loss': 0.1386304,\n",
      " 'Loss/regularization_loss': 0.12340133,\n",
      " 'Loss/total_loss': 0.429794,\n",
      " 'learning_rate': 0.07205655}\n",
      "I0604 09:12:22.021595 139685712938816 model_lib_v2.py:708] {'Loss/classification_loss': 0.1677623,\n",
      " 'Loss/localization_loss': 0.1386304,\n",
      " 'Loss/regularization_loss': 0.12340133,\n",
      " 'Loss/total_loss': 0.429794,\n",
      " 'learning_rate': 0.07205655}\n",
      "INFO:tensorflow:Step 11200 per-step time 0.700s\n",
      "I0604 09:14:42.419228 139685712938816 model_lib_v2.py:705] Step 11200 per-step time 0.700s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14786027,\n",
      " 'Loss/localization_loss': 0.098179035,\n",
      " 'Loss/regularization_loss': 0.1231897,\n",
      " 'Loss/total_loss': 0.36922902,\n",
      " 'learning_rate': 0.07174714}\n",
      "I0604 09:14:42.419472 139685712938816 model_lib_v2.py:708] {'Loss/classification_loss': 0.14786027,\n",
      " 'Loss/localization_loss': 0.098179035,\n",
      " 'Loss/regularization_loss': 0.1231897,\n",
      " 'Loss/total_loss': 0.36922902,\n",
      " 'learning_rate': 0.07174714}\n",
      "INFO:tensorflow:Step 11300 per-step time 0.700s\n",
      "I0604 09:15:52.436535 139685712938816 model_lib_v2.py:705] Step 11300 per-step time 0.700s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.17740317,\n",
      " 'Loss/localization_loss': 0.17997412,\n",
      " 'Loss/regularization_loss': 0.12298668,\n",
      " 'Loss/total_loss': 0.48036397,\n",
      " 'learning_rate': 0.071590476}\n",
      "I0604 09:15:52.436764 139685712938816 model_lib_v2.py:708] {'Loss/classification_loss': 0.17740317,\n",
      " 'Loss/localization_loss': 0.17997412,\n",
      " 'Loss/regularization_loss': 0.12298668,\n",
      " 'Loss/total_loss': 0.48036397,\n",
      " 'learning_rate': 0.071590476}\n",
      "INFO:tensorflow:Step 11400 per-step time 0.700s\n",
      "I0604 09:17:02.431358 139685712938816 model_lib_v2.py:705] Step 11400 per-step time 0.700s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15532382,\n",
      " 'Loss/localization_loss': 0.11098343,\n",
      " 'Loss/regularization_loss': 0.122847274,\n",
      " 'Loss/total_loss': 0.3891545,\n",
      " 'learning_rate': 0.071432516}\n",
      "I0604 09:17:02.431632 139685712938816 model_lib_v2.py:708] {'Loss/classification_loss': 0.15532382,\n",
      " 'Loss/localization_loss': 0.11098343,\n",
      " 'Loss/regularization_loss': 0.122847274,\n",
      " 'Loss/total_loss': 0.3891545,\n",
      " 'learning_rate': 0.071432516}\n",
      "INFO:tensorflow:Step 11500 per-step time 0.700s\n",
      "I0604 09:18:12.433064 139685712938816 model_lib_v2.py:705] Step 11500 per-step time 0.700s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.19396105,\n",
      " 'Loss/localization_loss': 0.14643806,\n",
      " 'Loss/regularization_loss': 0.12259041,\n",
      " 'Loss/total_loss': 0.4629895,\n",
      " 'learning_rate': 0.07127326}\n",
      "I0604 09:18:12.433335 139685712938816 model_lib_v2.py:708] {'Loss/classification_loss': 0.19396105,\n",
      " 'Loss/localization_loss': 0.14643806,\n",
      " 'Loss/regularization_loss': 0.12259041,\n",
      " 'Loss/total_loss': 0.4629895,\n",
      " 'learning_rate': 0.07127326}\n",
      "INFO:tensorflow:Step 11600 per-step time 0.699s\n",
      "I0604 09:19:22.378759 139685712938816 model_lib_v2.py:705] Step 11600 per-step time 0.699s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16364348,\n",
      " 'Loss/localization_loss': 0.12128788,\n",
      " 'Loss/regularization_loss': 0.12245133,\n",
      " 'Loss/total_loss': 0.4073827,\n",
      " 'learning_rate': 0.071112715}\n",
      "I0604 09:19:22.379020 139685712938816 model_lib_v2.py:708] {'Loss/classification_loss': 0.16364348,\n",
      " 'Loss/localization_loss': 0.12128788,\n",
      " 'Loss/regularization_loss': 0.12245133,\n",
      " 'Loss/total_loss': 0.4073827,\n",
      " 'learning_rate': 0.071112715}\n",
      "INFO:tensorflow:Step 11700 per-step time 0.700s\n",
      "I0604 09:20:32.344531 139685712938816 model_lib_v2.py:705] Step 11700 per-step time 0.700s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.17046043,\n",
      " 'Loss/localization_loss': 0.14413455,\n",
      " 'Loss/regularization_loss': 0.12212577,\n",
      " 'Loss/total_loss': 0.43672076,\n",
      " 'learning_rate': 0.070950896}\n",
      "I0604 09:20:32.344791 139685712938816 model_lib_v2.py:708] {'Loss/classification_loss': 0.17046043,\n",
      " 'Loss/localization_loss': 0.14413455,\n",
      " 'Loss/regularization_loss': 0.12212577,\n",
      " 'Loss/total_loss': 0.43672076,\n",
      " 'learning_rate': 0.070950896}\n"
     ]
    }
   ],
   "source": [
    "# (For cont')\n",
    "\n",
    "%cd {MAIN_PATH}/models/research/object_detection\n",
    "\n",
    "!python model_main_tf2.py \\\n",
    "--pipeline_config_path={CONFIG_PATH} \\\n",
    "--model_dir={TRAINING_PATH} \\\n",
    "--alsologtostderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cvPZMyPiZFFO"
   },
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0eK0oTxsNcCK",
    "outputId": "710b71d9-24e7-40d2-a205-31b2961c967e"
   },
   "outputs": [],
   "source": [
    "!python model_main_tf2.py \\\n",
    "--model_dir={TRAINING_PATH} \\\n",
    "--pipeline_config_path={CONFIG_PATH} \\\n",
    "--checkpoint_dir={TRAINING_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWIDrr3ZQjj6"
   },
   "source": [
    "## Inference/Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 951,
     "status": "ok",
     "timestamp": 1654190006848,
     "user": {
      "displayName": "Ahmad Nurokhim M2269J2329",
      "userId": "00215007788620369802"
     },
     "user_tz": -480
    },
    "id": "Ezl_U9UpT2Kd",
    "outputId": "cc9248b5-a4d5-4e17-d2e8-ef85fad4ee42"
   },
   "outputs": [],
   "source": [
    "!python exporter_main_v2.py \\\n",
    "--trained_checkpoint_dir={TRAINING_PATH} \\\n",
    "--pipeline_config_path={CONFIG_PATH} \\\n",
    "--output_directory {DATA_PATH}/inference_graph"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNZfYiFeNihRAo+EdSsnJrM",
   "collapsed_sections": [],
   "name": "MyModel.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "71824dd40866df3d2aa82f78c70152c0d364eafa49dfb98f28d6e83617cc2488"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
